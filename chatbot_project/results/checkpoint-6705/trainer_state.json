{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 6705,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0044742729306487695,
      "grad_norm": 12.071759223937988,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.3969,
      "step": 10
    },
    {
      "epoch": 0.008948545861297539,
      "grad_norm": 7.400786876678467,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.2923,
      "step": 20
    },
    {
      "epoch": 0.013422818791946308,
      "grad_norm": 6.1811981201171875,
      "learning_rate": 1.8e-06,
      "loss": 0.2271,
      "step": 30
    },
    {
      "epoch": 0.017897091722595078,
      "grad_norm": 3.703284502029419,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.1576,
      "step": 40
    },
    {
      "epoch": 0.02237136465324385,
      "grad_norm": 2.9715569019317627,
      "learning_rate": 3e-06,
      "loss": 0.1031,
      "step": 50
    },
    {
      "epoch": 0.026845637583892617,
      "grad_norm": 2.2632088661193848,
      "learning_rate": 3.6e-06,
      "loss": 0.077,
      "step": 60
    },
    {
      "epoch": 0.03131991051454139,
      "grad_norm": 1.4130065441131592,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0587,
      "step": 70
    },
    {
      "epoch": 0.035794183445190156,
      "grad_norm": 1.0080305337905884,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0383,
      "step": 80
    },
    {
      "epoch": 0.040268456375838924,
      "grad_norm": 0.5105994343757629,
      "learning_rate": 5.4e-06,
      "loss": 0.0247,
      "step": 90
    },
    {
      "epoch": 0.0447427293064877,
      "grad_norm": 0.3673621118068695,
      "learning_rate": 6e-06,
      "loss": 0.0159,
      "step": 100
    },
    {
      "epoch": 0.049217002237136466,
      "grad_norm": 0.26003867387771606,
      "learning_rate": 6.6e-06,
      "loss": 0.0113,
      "step": 110
    },
    {
      "epoch": 0.053691275167785234,
      "grad_norm": 0.20921026170253754,
      "learning_rate": 7.2e-06,
      "loss": 0.0084,
      "step": 120
    },
    {
      "epoch": 0.058165548098434,
      "grad_norm": 0.15089121460914612,
      "learning_rate": 7.8e-06,
      "loss": 0.0064,
      "step": 130
    },
    {
      "epoch": 0.06263982102908278,
      "grad_norm": 0.14350752532482147,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0052,
      "step": 140
    },
    {
      "epoch": 0.06711409395973154,
      "grad_norm": 0.0970875695347786,
      "learning_rate": 9e-06,
      "loss": 0.004,
      "step": 150
    },
    {
      "epoch": 0.07158836689038031,
      "grad_norm": 0.09535584598779678,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0034,
      "step": 160
    },
    {
      "epoch": 0.07606263982102908,
      "grad_norm": 0.06954609602689743,
      "learning_rate": 1.02e-05,
      "loss": 0.0027,
      "step": 170
    },
    {
      "epoch": 0.08053691275167785,
      "grad_norm": 0.04804590344429016,
      "learning_rate": 1.08e-05,
      "loss": 0.0021,
      "step": 180
    },
    {
      "epoch": 0.08501118568232663,
      "grad_norm": 0.07347375154495239,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0017,
      "step": 190
    },
    {
      "epoch": 0.0894854586129754,
      "grad_norm": 0.03651093319058418,
      "learning_rate": 1.2e-05,
      "loss": 0.0014,
      "step": 200
    },
    {
      "epoch": 0.09395973154362416,
      "grad_norm": 0.03307497873902321,
      "learning_rate": 1.26e-05,
      "loss": 0.0011,
      "step": 210
    },
    {
      "epoch": 0.09843400447427293,
      "grad_norm": 0.029455110430717468,
      "learning_rate": 1.32e-05,
      "loss": 0.0009,
      "step": 220
    },
    {
      "epoch": 0.1029082774049217,
      "grad_norm": 0.023082677274942398,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.0008,
      "step": 230
    },
    {
      "epoch": 0.10738255033557047,
      "grad_norm": 0.012425755150616169,
      "learning_rate": 1.44e-05,
      "loss": 0.0006,
      "step": 240
    },
    {
      "epoch": 0.11185682326621924,
      "grad_norm": 0.013961085118353367,
      "learning_rate": 1.5e-05,
      "loss": 0.0005,
      "step": 250
    },
    {
      "epoch": 0.116331096196868,
      "grad_norm": 0.026998795568943024,
      "learning_rate": 1.56e-05,
      "loss": 0.0005,
      "step": 260
    },
    {
      "epoch": 0.12080536912751678,
      "grad_norm": 0.010209965519607067,
      "learning_rate": 1.62e-05,
      "loss": 0.0004,
      "step": 270
    },
    {
      "epoch": 0.12527964205816555,
      "grad_norm": 0.00942286103963852,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0004,
      "step": 280
    },
    {
      "epoch": 0.1297539149888143,
      "grad_norm": 0.008219215087592602,
      "learning_rate": 1.74e-05,
      "loss": 0.0003,
      "step": 290
    },
    {
      "epoch": 0.1342281879194631,
      "grad_norm": 0.009651800617575645,
      "learning_rate": 1.8e-05,
      "loss": 0.0003,
      "step": 300
    },
    {
      "epoch": 0.13870246085011187,
      "grad_norm": 0.005622431635856628,
      "learning_rate": 1.86e-05,
      "loss": 0.0002,
      "step": 310
    },
    {
      "epoch": 0.14317673378076062,
      "grad_norm": 0.004629957489669323,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0002,
      "step": 320
    },
    {
      "epoch": 0.1476510067114094,
      "grad_norm": 0.005124228540807962,
      "learning_rate": 1.98e-05,
      "loss": 0.0002,
      "step": 330
    },
    {
      "epoch": 0.15212527964205816,
      "grad_norm": 0.003950634505599737,
      "learning_rate": 2.04e-05,
      "loss": 0.0002,
      "step": 340
    },
    {
      "epoch": 0.15659955257270694,
      "grad_norm": 0.0069806319661438465,
      "learning_rate": 2.1e-05,
      "loss": 0.0002,
      "step": 350
    },
    {
      "epoch": 0.1610738255033557,
      "grad_norm": 0.005973746534436941,
      "learning_rate": 2.16e-05,
      "loss": 0.0002,
      "step": 360
    },
    {
      "epoch": 0.16554809843400448,
      "grad_norm": 0.005066705867648125,
      "learning_rate": 2.22e-05,
      "loss": 0.0001,
      "step": 370
    },
    {
      "epoch": 0.17002237136465326,
      "grad_norm": 0.002836836501955986,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0001,
      "step": 380
    },
    {
      "epoch": 0.174496644295302,
      "grad_norm": 0.0031823390163481236,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.0001,
      "step": 390
    },
    {
      "epoch": 0.1789709172259508,
      "grad_norm": 0.0046761492267251015,
      "learning_rate": 2.4e-05,
      "loss": 0.0001,
      "step": 400
    },
    {
      "epoch": 0.18344519015659955,
      "grad_norm": 0.0037022996693849564,
      "learning_rate": 2.4599999999999998e-05,
      "loss": 0.0001,
      "step": 410
    },
    {
      "epoch": 0.18791946308724833,
      "grad_norm": 0.002594876568764448,
      "learning_rate": 2.52e-05,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 0.19239373601789708,
      "grad_norm": 0.0020187655463814735,
      "learning_rate": 2.58e-05,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 0.19686800894854586,
      "grad_norm": 0.0026374375447630882,
      "learning_rate": 2.64e-05,
      "loss": 0.0001,
      "step": 440
    },
    {
      "epoch": 0.20134228187919462,
      "grad_norm": 0.002170023275539279,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0001,
      "step": 450
    },
    {
      "epoch": 0.2058165548098434,
      "grad_norm": 0.0022013105917721987,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0001,
      "step": 460
    },
    {
      "epoch": 0.21029082774049218,
      "grad_norm": 0.0020081079564988613,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0001,
      "step": 470
    },
    {
      "epoch": 0.21476510067114093,
      "grad_norm": 0.0021096114069223404,
      "learning_rate": 2.88e-05,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 0.21923937360178972,
      "grad_norm": 0.0016993603203445673,
      "learning_rate": 2.94e-05,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 0.22371364653243847,
      "grad_norm": 0.0018818385433405638,
      "learning_rate": 3e-05,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 0.22818791946308725,
      "grad_norm": 0.002912768628448248,
      "learning_rate": 2.9951651893634168e-05,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 0.232662192393736,
      "grad_norm": 0.001944424700923264,
      "learning_rate": 2.9903303787268332e-05,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 0.2371364653243848,
      "grad_norm": 0.002266183728352189,
      "learning_rate": 2.98549556809025e-05,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 0.24161073825503357,
      "grad_norm": 0.0015080482698976994,
      "learning_rate": 2.9806607574536664e-05,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 0.24608501118568232,
      "grad_norm": 0.001670360448770225,
      "learning_rate": 2.975825946817083e-05,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 0.2505592841163311,
      "grad_norm": 0.001485722721554339,
      "learning_rate": 2.9709911361804996e-05,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 0.2550335570469799,
      "grad_norm": 0.0016801230376586318,
      "learning_rate": 2.9661563255439163e-05,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 0.2595078299776286,
      "grad_norm": 0.0012952574761584401,
      "learning_rate": 2.9613215149073327e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 0.2639821029082774,
      "grad_norm": 0.0015596654266119003,
      "learning_rate": 2.9564867042707498e-05,
      "loss": 0.0001,
      "step": 590
    },
    {
      "epoch": 0.2684563758389262,
      "grad_norm": 0.0012224669335409999,
      "learning_rate": 2.9516518936341662e-05,
      "loss": 0.0001,
      "step": 600
    },
    {
      "epoch": 0.27293064876957496,
      "grad_norm": 0.0017200136790052056,
      "learning_rate": 2.946817082997583e-05,
      "loss": 0.0001,
      "step": 610
    },
    {
      "epoch": 0.27740492170022374,
      "grad_norm": 0.001378723420202732,
      "learning_rate": 2.9419822723609994e-05,
      "loss": 0.0,
      "step": 620
    },
    {
      "epoch": 0.28187919463087246,
      "grad_norm": 0.0011947210878133774,
      "learning_rate": 2.937147461724416e-05,
      "loss": 0.0,
      "step": 630
    },
    {
      "epoch": 0.28635346756152125,
      "grad_norm": 0.0011344137601554394,
      "learning_rate": 2.9323126510878325e-05,
      "loss": 0.0,
      "step": 640
    },
    {
      "epoch": 0.29082774049217003,
      "grad_norm": 0.0010671054478734732,
      "learning_rate": 2.9274778404512493e-05,
      "loss": 0.0,
      "step": 650
    },
    {
      "epoch": 0.2953020134228188,
      "grad_norm": 0.0012619333574548364,
      "learning_rate": 2.9226430298146657e-05,
      "loss": 0.0,
      "step": 660
    },
    {
      "epoch": 0.29977628635346754,
      "grad_norm": 0.0011816227342933416,
      "learning_rate": 2.9178082191780824e-05,
      "loss": 0.0,
      "step": 670
    },
    {
      "epoch": 0.3042505592841163,
      "grad_norm": 0.0010277775581926107,
      "learning_rate": 2.912973408541499e-05,
      "loss": 0.0,
      "step": 680
    },
    {
      "epoch": 0.3087248322147651,
      "grad_norm": 0.0009415302774868906,
      "learning_rate": 2.9081385979049156e-05,
      "loss": 0.0,
      "step": 690
    },
    {
      "epoch": 0.3131991051454139,
      "grad_norm": 0.0010258342372253537,
      "learning_rate": 2.903303787268332e-05,
      "loss": 0.0,
      "step": 700
    },
    {
      "epoch": 0.31767337807606266,
      "grad_norm": 0.0011118112597614527,
      "learning_rate": 2.8984689766317487e-05,
      "loss": 0.0,
      "step": 710
    },
    {
      "epoch": 0.3221476510067114,
      "grad_norm": 0.001033182255923748,
      "learning_rate": 2.893634165995165e-05,
      "loss": 0.0,
      "step": 720
    },
    {
      "epoch": 0.32662192393736017,
      "grad_norm": 0.0009056706330738962,
      "learning_rate": 2.888799355358582e-05,
      "loss": 0.0,
      "step": 730
    },
    {
      "epoch": 0.33109619686800895,
      "grad_norm": 0.0012678306084126234,
      "learning_rate": 2.8839645447219983e-05,
      "loss": 0.0,
      "step": 740
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 0.0009654589230194688,
      "learning_rate": 2.879129734085415e-05,
      "loss": 0.0,
      "step": 750
    },
    {
      "epoch": 0.3400447427293065,
      "grad_norm": 0.0008374561439268291,
      "learning_rate": 2.8742949234488318e-05,
      "loss": 0.0,
      "step": 760
    },
    {
      "epoch": 0.34451901565995524,
      "grad_norm": 0.0009254113538190722,
      "learning_rate": 2.8694601128122486e-05,
      "loss": 0.0,
      "step": 770
    },
    {
      "epoch": 0.348993288590604,
      "grad_norm": 0.0010835569119080901,
      "learning_rate": 2.864625302175665e-05,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 0.3534675615212528,
      "grad_norm": 0.0008407254936173558,
      "learning_rate": 2.8597904915390817e-05,
      "loss": 0.0,
      "step": 790
    },
    {
      "epoch": 0.3579418344519016,
      "grad_norm": 0.0009063278557732701,
      "learning_rate": 2.854955680902498e-05,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 0.3624161073825503,
      "grad_norm": 0.0007514436729252338,
      "learning_rate": 2.850120870265915e-05,
      "loss": 0.0,
      "step": 810
    },
    {
      "epoch": 0.3668903803131991,
      "grad_norm": 0.0008455814095214009,
      "learning_rate": 2.8452860596293313e-05,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 0.3713646532438479,
      "grad_norm": 0.0007000010227784514,
      "learning_rate": 2.840451248992748e-05,
      "loss": 0.0,
      "step": 830
    },
    {
      "epoch": 0.37583892617449666,
      "grad_norm": 0.0007423670613206923,
      "learning_rate": 2.8356164383561644e-05,
      "loss": 0.0,
      "step": 840
    },
    {
      "epoch": 0.38031319910514544,
      "grad_norm": 0.0007249058107845485,
      "learning_rate": 2.8307816277195812e-05,
      "loss": 0.0,
      "step": 850
    },
    {
      "epoch": 0.38478747203579416,
      "grad_norm": 0.0007599596865475178,
      "learning_rate": 2.8259468170829976e-05,
      "loss": 0.0,
      "step": 860
    },
    {
      "epoch": 0.38926174496644295,
      "grad_norm": 0.0006698344950564206,
      "learning_rate": 2.8211120064464143e-05,
      "loss": 0.0,
      "step": 870
    },
    {
      "epoch": 0.39373601789709173,
      "grad_norm": 0.0006531727267429233,
      "learning_rate": 2.8162771958098308e-05,
      "loss": 0.0,
      "step": 880
    },
    {
      "epoch": 0.3982102908277405,
      "grad_norm": 0.000756798661313951,
      "learning_rate": 2.8114423851732475e-05,
      "loss": 0.0,
      "step": 890
    },
    {
      "epoch": 0.40268456375838924,
      "grad_norm": 0.0006284569972194731,
      "learning_rate": 2.806607574536664e-05,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.407158836689038,
      "grad_norm": 0.0006198921473696828,
      "learning_rate": 2.8017727639000807e-05,
      "loss": 0.0,
      "step": 910
    },
    {
      "epoch": 0.4116331096196868,
      "grad_norm": 0.0006247701239772141,
      "learning_rate": 2.796937953263497e-05,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 0.4161073825503356,
      "grad_norm": 0.0006479083676822484,
      "learning_rate": 2.7921031426269138e-05,
      "loss": 0.0,
      "step": 930
    },
    {
      "epoch": 0.42058165548098436,
      "grad_norm": 0.0007310403743758798,
      "learning_rate": 2.7872683319903306e-05,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 0.4250559284116331,
      "grad_norm": 0.0006028881762176752,
      "learning_rate": 2.7824335213537473e-05,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 0.42953020134228187,
      "grad_norm": 0.000645857653580606,
      "learning_rate": 2.7775987107171637e-05,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 0.43400447427293065,
      "grad_norm": 0.0006158612668514252,
      "learning_rate": 2.7727639000805805e-05,
      "loss": 0.0,
      "step": 970
    },
    {
      "epoch": 0.43847874720357943,
      "grad_norm": 0.0005897611263208091,
      "learning_rate": 2.767929089443997e-05,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 0.4429530201342282,
      "grad_norm": 0.0007404974894598126,
      "learning_rate": 2.7630942788074136e-05,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 0.44742729306487694,
      "grad_norm": 0.0005606844206340611,
      "learning_rate": 2.75825946817083e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.44742729306487694,
      "eval_loss": 1.5477418855880387e-05,
      "eval_runtime": 96.3484,
      "eval_samples_per_second": 10.379,
      "eval_steps_per_second": 1.297,
      "step": 1000
    },
    {
      "epoch": 0.4519015659955257,
      "grad_norm": 0.0005555915995500982,
      "learning_rate": 2.7534246575342468e-05,
      "loss": 0.0,
      "step": 1010
    },
    {
      "epoch": 0.4563758389261745,
      "grad_norm": 0.0005294865695759654,
      "learning_rate": 2.7485898468976632e-05,
      "loss": 0.0,
      "step": 1020
    },
    {
      "epoch": 0.4608501118568233,
      "grad_norm": 0.0005942403222434223,
      "learning_rate": 2.74375503626108e-05,
      "loss": 0.0,
      "step": 1030
    },
    {
      "epoch": 0.465324384787472,
      "grad_norm": 0.0005265736836008728,
      "learning_rate": 2.7389202256244964e-05,
      "loss": 0.0,
      "step": 1040
    },
    {
      "epoch": 0.4697986577181208,
      "grad_norm": 0.0005186544149182737,
      "learning_rate": 2.734085414987913e-05,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 0.4742729306487696,
      "grad_norm": 0.0004936525947414339,
      "learning_rate": 2.7292506043513295e-05,
      "loss": 0.0,
      "step": 1060
    },
    {
      "epoch": 0.47874720357941836,
      "grad_norm": 0.0005681775510311127,
      "learning_rate": 2.7244157937147463e-05,
      "loss": 0.0,
      "step": 1070
    },
    {
      "epoch": 0.48322147651006714,
      "grad_norm": 0.000514174229465425,
      "learning_rate": 2.7195809830781627e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 0.48769574944071586,
      "grad_norm": 0.0005062976269982755,
      "learning_rate": 2.7147461724415794e-05,
      "loss": 0.0,
      "step": 1090
    },
    {
      "epoch": 0.49217002237136465,
      "grad_norm": 0.0005167517228983343,
      "learning_rate": 2.709911361804996e-05,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.4966442953020134,
      "grad_norm": 0.00045350793516263366,
      "learning_rate": 2.705076551168413e-05,
      "loss": 0.0,
      "step": 1110
    },
    {
      "epoch": 0.5011185682326622,
      "grad_norm": 0.00046777166426181793,
      "learning_rate": 2.7002417405318293e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 0.5055928411633109,
      "grad_norm": 0.0005144806345924735,
      "learning_rate": 2.695406929895246e-05,
      "loss": 0.0,
      "step": 1130
    },
    {
      "epoch": 0.5100671140939598,
      "grad_norm": 0.0004518226778600365,
      "learning_rate": 2.6905721192586625e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 0.5145413870246085,
      "grad_norm": 0.0005004130653105676,
      "learning_rate": 2.6857373086220792e-05,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.5190156599552572,
      "grad_norm": 0.0004990132874809206,
      "learning_rate": 2.6809024979854956e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 0.5234899328859061,
      "grad_norm": 0.00047338628792203963,
      "learning_rate": 2.6760676873489124e-05,
      "loss": 0.0,
      "step": 1170
    },
    {
      "epoch": 0.5279642058165548,
      "grad_norm": 0.0004581733082886785,
      "learning_rate": 2.6712328767123288e-05,
      "loss": 0.0,
      "step": 1180
    },
    {
      "epoch": 0.5324384787472036,
      "grad_norm": 0.0005356917972676456,
      "learning_rate": 2.6663980660757456e-05,
      "loss": 0.0,
      "step": 1190
    },
    {
      "epoch": 0.5369127516778524,
      "grad_norm": 0.00048723327927291393,
      "learning_rate": 2.661563255439162e-05,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.5413870246085011,
      "grad_norm": 0.0005236612050794065,
      "learning_rate": 2.6567284448025787e-05,
      "loss": 0.0,
      "step": 1210
    },
    {
      "epoch": 0.5458612975391499,
      "grad_norm": 0.00045983740710653365,
      "learning_rate": 2.651893634165995e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 0.5503355704697986,
      "grad_norm": 0.0004970331792719662,
      "learning_rate": 2.647058823529412e-05,
      "loss": 0.0,
      "step": 1230
    },
    {
      "epoch": 0.5548098434004475,
      "grad_norm": 0.000387277890695259,
      "learning_rate": 2.6422240128928283e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 0.5592841163310962,
      "grad_norm": 0.0004393946146592498,
      "learning_rate": 2.637389202256245e-05,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 0.5637583892617449,
      "grad_norm": 0.0004780451417900622,
      "learning_rate": 2.6325543916196614e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 0.5682326621923938,
      "grad_norm": 0.00045910599874332547,
      "learning_rate": 2.6277195809830782e-05,
      "loss": 0.0,
      "step": 1270
    },
    {
      "epoch": 0.5727069351230425,
      "grad_norm": 0.0004208622267469764,
      "learning_rate": 2.622884770346495e-05,
      "loss": 0.0,
      "step": 1280
    },
    {
      "epoch": 0.5771812080536913,
      "grad_norm": 0.0003640058566816151,
      "learning_rate": 2.6180499597099117e-05,
      "loss": 0.0,
      "step": 1290
    },
    {
      "epoch": 0.5816554809843401,
      "grad_norm": 0.00047070885193534195,
      "learning_rate": 2.613215149073328e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.5861297539149888,
      "grad_norm": 0.0003582114295568317,
      "learning_rate": 2.608380338436745e-05,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 0.5906040268456376,
      "grad_norm": 0.0003909160732291639,
      "learning_rate": 2.6035455278001613e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.5950782997762863,
      "grad_norm": 0.00042118574492633343,
      "learning_rate": 2.598710717163578e-05,
      "loss": 0.0,
      "step": 1330
    },
    {
      "epoch": 0.5995525727069351,
      "grad_norm": 0.00043939470197074115,
      "learning_rate": 2.5938759065269944e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.6040268456375839,
      "grad_norm": 0.0003596386522985995,
      "learning_rate": 2.589041095890411e-05,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 0.6085011185682326,
      "grad_norm": 0.00036077527329325676,
      "learning_rate": 2.5842062852538276e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 0.6129753914988815,
      "grad_norm": 0.0003809856716543436,
      "learning_rate": 2.5793714746172443e-05,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 0.6174496644295302,
      "grad_norm": 0.0004136499192100018,
      "learning_rate": 2.5745366639806607e-05,
      "loss": 0.0,
      "step": 1380
    },
    {
      "epoch": 0.6219239373601789,
      "grad_norm": 0.00035203975858166814,
      "learning_rate": 2.5697018533440775e-05,
      "loss": 0.0,
      "step": 1390
    },
    {
      "epoch": 0.6263982102908278,
      "grad_norm": 0.00035164938890375197,
      "learning_rate": 2.564867042707494e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.6308724832214765,
      "grad_norm": 0.00037903900374658406,
      "learning_rate": 2.5600322320709106e-05,
      "loss": 0.0,
      "step": 1410
    },
    {
      "epoch": 0.6353467561521253,
      "grad_norm": 0.00038596728700213134,
      "learning_rate": 2.555197421434327e-05,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 0.639821029082774,
      "grad_norm": 0.0003490533563308418,
      "learning_rate": 2.5503626107977438e-05,
      "loss": 0.0,
      "step": 1430
    },
    {
      "epoch": 0.6442953020134228,
      "grad_norm": 0.000426718732342124,
      "learning_rate": 2.5455278001611602e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.6487695749440716,
      "grad_norm": 0.00035464984830468893,
      "learning_rate": 2.5406929895245773e-05,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 0.6532438478747203,
      "grad_norm": 0.0003331129555590451,
      "learning_rate": 2.5358581788879937e-05,
      "loss": 0.0,
      "step": 1460
    },
    {
      "epoch": 0.6577181208053692,
      "grad_norm": 0.0003756998630706221,
      "learning_rate": 2.5310233682514104e-05,
      "loss": 0.0,
      "step": 1470
    },
    {
      "epoch": 0.6621923937360179,
      "grad_norm": 0.0003149838885292411,
      "learning_rate": 2.526188557614827e-05,
      "loss": 0.0,
      "step": 1480
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.0003396474348846823,
      "learning_rate": 2.5213537469782436e-05,
      "loss": 0.0,
      "step": 1490
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 0.0003306497528683394,
      "learning_rate": 2.51651893634166e-05,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 0.6756152125279642,
      "grad_norm": 0.0003048338112421334,
      "learning_rate": 2.5116841257050768e-05,
      "loss": 0.0,
      "step": 1510
    },
    {
      "epoch": 0.680089485458613,
      "grad_norm": 0.0003269249282311648,
      "learning_rate": 2.5068493150684932e-05,
      "loss": 0.0,
      "step": 1520
    },
    {
      "epoch": 0.6845637583892618,
      "grad_norm": 0.00032094286871142685,
      "learning_rate": 2.50201450443191e-05,
      "loss": 0.0,
      "step": 1530
    },
    {
      "epoch": 0.6890380313199105,
      "grad_norm": 0.0002939318073913455,
      "learning_rate": 2.4971796937953263e-05,
      "loss": 0.0,
      "step": 1540
    },
    {
      "epoch": 0.6935123042505593,
      "grad_norm": 0.0003062653122469783,
      "learning_rate": 2.492344883158743e-05,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 0.697986577181208,
      "grad_norm": 0.00027762618265114725,
      "learning_rate": 2.4875100725221595e-05,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 0.7024608501118568,
      "grad_norm": 0.00034649393637664616,
      "learning_rate": 2.4826752618855762e-05,
      "loss": 0.0,
      "step": 1570
    },
    {
      "epoch": 0.7069351230425056,
      "grad_norm": 0.00028125065728090703,
      "learning_rate": 2.4778404512489926e-05,
      "loss": 0.0,
      "step": 1580
    },
    {
      "epoch": 0.7114093959731543,
      "grad_norm": 0.00035019920323975384,
      "learning_rate": 2.4730056406124094e-05,
      "loss": 0.0,
      "step": 1590
    },
    {
      "epoch": 0.7158836689038032,
      "grad_norm": 0.0002921980922110379,
      "learning_rate": 2.4681708299758258e-05,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 0.7203579418344519,
      "grad_norm": 0.0003214155731257051,
      "learning_rate": 2.4633360193392426e-05,
      "loss": 0.0,
      "step": 1610
    },
    {
      "epoch": 0.7248322147651006,
      "grad_norm": 0.0002901047409977764,
      "learning_rate": 2.458501208702659e-05,
      "loss": 0.0,
      "step": 1620
    },
    {
      "epoch": 0.7293064876957495,
      "grad_norm": 0.00029343320056796074,
      "learning_rate": 2.453666398066076e-05,
      "loss": 0.0,
      "step": 1630
    },
    {
      "epoch": 0.7337807606263982,
      "grad_norm": 0.0002825057308655232,
      "learning_rate": 2.4488315874294925e-05,
      "loss": 0.0,
      "step": 1640
    },
    {
      "epoch": 0.738255033557047,
      "grad_norm": 0.00031020608730614185,
      "learning_rate": 2.4439967767929092e-05,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 0.7427293064876958,
      "grad_norm": 0.0002768517006188631,
      "learning_rate": 2.4391619661563256e-05,
      "loss": 0.0,
      "step": 1660
    },
    {
      "epoch": 0.7472035794183445,
      "grad_norm": 0.0002740826166700572,
      "learning_rate": 2.4343271555197424e-05,
      "loss": 0.0,
      "step": 1670
    },
    {
      "epoch": 0.7516778523489933,
      "grad_norm": 0.0003563088830560446,
      "learning_rate": 2.4294923448831588e-05,
      "loss": 0.0,
      "step": 1680
    },
    {
      "epoch": 0.756152125279642,
      "grad_norm": 0.0003013179521076381,
      "learning_rate": 2.4246575342465755e-05,
      "loss": 0.0,
      "step": 1690
    },
    {
      "epoch": 0.7606263982102909,
      "grad_norm": 0.0003636396140791476,
      "learning_rate": 2.419822723609992e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.7651006711409396,
      "grad_norm": 0.00025227118749171495,
      "learning_rate": 2.4149879129734087e-05,
      "loss": 0.0,
      "step": 1710
    },
    {
      "epoch": 0.7695749440715883,
      "grad_norm": 0.00024195753212552518,
      "learning_rate": 2.410153102336825e-05,
      "loss": 0.0,
      "step": 1720
    },
    {
      "epoch": 0.7740492170022372,
      "grad_norm": 0.0002995267859660089,
      "learning_rate": 2.405318291700242e-05,
      "loss": 0.0,
      "step": 1730
    },
    {
      "epoch": 0.7785234899328859,
      "grad_norm": 0.0002876802464015782,
      "learning_rate": 2.4004834810636583e-05,
      "loss": 0.0,
      "step": 1740
    },
    {
      "epoch": 0.7829977628635347,
      "grad_norm": 0.0002837378706317395,
      "learning_rate": 2.395648670427075e-05,
      "loss": 0.0,
      "step": 1750
    },
    {
      "epoch": 0.7874720357941835,
      "grad_norm": 0.0002627832582220435,
      "learning_rate": 2.3908138597904914e-05,
      "loss": 0.0,
      "step": 1760
    },
    {
      "epoch": 0.7919463087248322,
      "grad_norm": 0.00023991141642909497,
      "learning_rate": 2.385979049153908e-05,
      "loss": 0.0,
      "step": 1770
    },
    {
      "epoch": 0.796420581655481,
      "grad_norm": 0.00024937561829574406,
      "learning_rate": 2.3811442385173246e-05,
      "loss": 0.0,
      "step": 1780
    },
    {
      "epoch": 0.8008948545861297,
      "grad_norm": 0.00026796181919053197,
      "learning_rate": 2.3763094278807413e-05,
      "loss": 0.0,
      "step": 1790
    },
    {
      "epoch": 0.8053691275167785,
      "grad_norm": 0.0002780933282338083,
      "learning_rate": 2.371474617244158e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.8098434004474273,
      "grad_norm": 0.00022815064585302025,
      "learning_rate": 2.3666398066075748e-05,
      "loss": 0.0,
      "step": 1810
    },
    {
      "epoch": 0.814317673378076,
      "grad_norm": 0.00021588322124443948,
      "learning_rate": 2.3618049959709912e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 0.8187919463087249,
      "grad_norm": 0.0003144334186799824,
      "learning_rate": 2.356970185334408e-05,
      "loss": 0.0,
      "step": 1830
    },
    {
      "epoch": 0.8232662192393736,
      "grad_norm": 0.00025688784080557525,
      "learning_rate": 2.3521353746978244e-05,
      "loss": 0.0,
      "step": 1840
    },
    {
      "epoch": 0.8277404921700223,
      "grad_norm": 0.00023699425219092518,
      "learning_rate": 2.347300564061241e-05,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 0.8322147651006712,
      "grad_norm": 0.0002603889734018594,
      "learning_rate": 2.3424657534246575e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 0.8366890380313199,
      "grad_norm": 0.0002354562602704391,
      "learning_rate": 2.3376309427880743e-05,
      "loss": 0.0,
      "step": 1870
    },
    {
      "epoch": 0.8411633109619687,
      "grad_norm": 0.00025606685085222125,
      "learning_rate": 2.3327961321514907e-05,
      "loss": 0.0,
      "step": 1880
    },
    {
      "epoch": 0.8456375838926175,
      "grad_norm": 0.000254131096880883,
      "learning_rate": 2.3279613215149074e-05,
      "loss": 0.0,
      "step": 1890
    },
    {
      "epoch": 0.8501118568232662,
      "grad_norm": 0.00022598486975766718,
      "learning_rate": 2.323126510878324e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.854586129753915,
      "grad_norm": 0.00024300192308146507,
      "learning_rate": 2.3182917002417406e-05,
      "loss": 0.0,
      "step": 1910
    },
    {
      "epoch": 0.8590604026845637,
      "grad_norm": 0.00023645561304874718,
      "learning_rate": 2.313456889605157e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 0.8635346756152126,
      "grad_norm": 0.00022163998801261187,
      "learning_rate": 2.3086220789685738e-05,
      "loss": 0.0,
      "step": 1930
    },
    {
      "epoch": 0.8680089485458613,
      "grad_norm": 0.00021013410878367722,
      "learning_rate": 2.3037872683319902e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 0.87248322147651,
      "grad_norm": 0.00021840918634552509,
      "learning_rate": 2.298952457695407e-05,
      "loss": 0.0,
      "step": 1950
    },
    {
      "epoch": 0.8769574944071589,
      "grad_norm": 0.0002438415540382266,
      "learning_rate": 2.2941176470588233e-05,
      "loss": 0.0,
      "step": 1960
    },
    {
      "epoch": 0.8814317673378076,
      "grad_norm": 0.00022639264352619648,
      "learning_rate": 2.2892828364222404e-05,
      "loss": 0.0,
      "step": 1970
    },
    {
      "epoch": 0.8859060402684564,
      "grad_norm": 0.00022413223632611334,
      "learning_rate": 2.2844480257856568e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 0.8903803131991052,
      "grad_norm": 0.00023196010442916304,
      "learning_rate": 2.2796132151490736e-05,
      "loss": 0.0,
      "step": 1990
    },
    {
      "epoch": 0.8948545861297539,
      "grad_norm": 0.00022271770285442472,
      "learning_rate": 2.27477840451249e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.8948545861297539,
      "eval_loss": 5.905730631639017e-06,
      "eval_runtime": 102.4939,
      "eval_samples_per_second": 9.757,
      "eval_steps_per_second": 1.22,
      "step": 2000
    },
    {
      "epoch": 0.8993288590604027,
      "grad_norm": 0.00023967449669726193,
      "learning_rate": 2.2699435938759067e-05,
      "loss": 0.0,
      "step": 2010
    },
    {
      "epoch": 0.9038031319910514,
      "grad_norm": 0.0002116975374519825,
      "learning_rate": 2.265108783239323e-05,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.9082774049217002,
      "grad_norm": 0.00021473980450537056,
      "learning_rate": 2.26027397260274e-05,
      "loss": 0.0,
      "step": 2030
    },
    {
      "epoch": 0.912751677852349,
      "grad_norm": 0.0001926383702084422,
      "learning_rate": 2.2554391619661563e-05,
      "loss": 0.0,
      "step": 2040
    },
    {
      "epoch": 0.9172259507829977,
      "grad_norm": 0.0002537535910960287,
      "learning_rate": 2.250604351329573e-05,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 0.9217002237136466,
      "grad_norm": 0.00023643196618650109,
      "learning_rate": 2.2457695406929895e-05,
      "loss": 0.0,
      "step": 2060
    },
    {
      "epoch": 0.9261744966442953,
      "grad_norm": 0.0002074067306239158,
      "learning_rate": 2.2409347300564062e-05,
      "loss": 0.0,
      "step": 2070
    },
    {
      "epoch": 0.930648769574944,
      "grad_norm": 0.00019263001740910113,
      "learning_rate": 2.2360999194198226e-05,
      "loss": 0.0,
      "step": 2080
    },
    {
      "epoch": 0.9351230425055929,
      "grad_norm": 0.00019870916730724275,
      "learning_rate": 2.2312651087832394e-05,
      "loss": 0.0,
      "step": 2090
    },
    {
      "epoch": 0.9395973154362416,
      "grad_norm": 0.00021391482732724398,
      "learning_rate": 2.2264302981466558e-05,
      "loss": 0.0,
      "step": 2100
    },
    {
      "epoch": 0.9440715883668904,
      "grad_norm": 0.00021799748355988413,
      "learning_rate": 2.2215954875100725e-05,
      "loss": 0.0,
      "step": 2110
    },
    {
      "epoch": 0.9485458612975392,
      "grad_norm": 0.00020158507686574012,
      "learning_rate": 2.216760676873489e-05,
      "loss": 0.0,
      "step": 2120
    },
    {
      "epoch": 0.9530201342281879,
      "grad_norm": 0.00021834154904354364,
      "learning_rate": 2.2119258662369057e-05,
      "loss": 0.0,
      "step": 2130
    },
    {
      "epoch": 0.9574944071588367,
      "grad_norm": 0.0002033151249634102,
      "learning_rate": 2.2070910556003224e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 0.9619686800894854,
      "grad_norm": 0.00019925969536416233,
      "learning_rate": 2.2022562449637392e-05,
      "loss": 0.0,
      "step": 2150
    },
    {
      "epoch": 0.9664429530201343,
      "grad_norm": 0.00019623943080659956,
      "learning_rate": 2.1974214343271556e-05,
      "loss": 0.0,
      "step": 2160
    },
    {
      "epoch": 0.970917225950783,
      "grad_norm": 0.00021705082326661795,
      "learning_rate": 2.1925866236905723e-05,
      "loss": 0.0,
      "step": 2170
    },
    {
      "epoch": 0.9753914988814317,
      "grad_norm": 0.00019756765686906874,
      "learning_rate": 2.1877518130539887e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 0.9798657718120806,
      "grad_norm": 0.00022244526189751923,
      "learning_rate": 2.1829170024174055e-05,
      "loss": 0.0,
      "step": 2190
    },
    {
      "epoch": 0.9843400447427293,
      "grad_norm": 0.0002044097927864641,
      "learning_rate": 2.178082191780822e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.9888143176733781,
      "grad_norm": 0.0001882636424852535,
      "learning_rate": 2.1732473811442387e-05,
      "loss": 0.0,
      "step": 2210
    },
    {
      "epoch": 0.9932885906040269,
      "grad_norm": 0.00020384436356835067,
      "learning_rate": 2.168412570507655e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 0.9977628635346756,
      "grad_norm": 0.00022945154341869056,
      "learning_rate": 2.1635777598710718e-05,
      "loss": 0.0,
      "step": 2230
    },
    {
      "epoch": 1.0022371364653244,
      "grad_norm": 0.00017813629528973252,
      "learning_rate": 2.1587429492344882e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 0.00019139534560963511,
      "learning_rate": 2.153908138597905e-05,
      "loss": 0.0,
      "step": 2250
    },
    {
      "epoch": 1.0111856823266219,
      "grad_norm": 0.0002033807832049206,
      "learning_rate": 2.1490733279613214e-05,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 1.0156599552572707,
      "grad_norm": 0.00019975776376668364,
      "learning_rate": 2.144238517324738e-05,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 1.0201342281879195,
      "grad_norm": 0.00022650076425634325,
      "learning_rate": 2.1394037066881545e-05,
      "loss": 0.0,
      "step": 2280
    },
    {
      "epoch": 1.0246085011185682,
      "grad_norm": 0.0002058861864497885,
      "learning_rate": 2.1345688960515713e-05,
      "loss": 0.0,
      "step": 2290
    },
    {
      "epoch": 1.029082774049217,
      "grad_norm": 0.00018193275900557637,
      "learning_rate": 2.1297340854149877e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 1.0335570469798658,
      "grad_norm": 0.00017556232342030853,
      "learning_rate": 2.1248992747784048e-05,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 1.0380313199105144,
      "grad_norm": 0.00019562942907214165,
      "learning_rate": 2.1200644641418212e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 1.0425055928411633,
      "grad_norm": 0.00018416102102492005,
      "learning_rate": 2.115229653505238e-05,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 1.0469798657718121,
      "grad_norm": 0.00019744223391171545,
      "learning_rate": 2.1103948428686543e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 1.0514541387024607,
      "grad_norm": 0.00016269877960439771,
      "learning_rate": 2.105560032232071e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 1.0559284116331096,
      "grad_norm": 0.00017233143444173038,
      "learning_rate": 2.1007252215954875e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 1.0604026845637584,
      "grad_norm": 0.0002179886505473405,
      "learning_rate": 2.0958904109589043e-05,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 1.0648769574944073,
      "grad_norm": 0.0001897291949717328,
      "learning_rate": 2.0910556003223207e-05,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 1.0693512304250559,
      "grad_norm": 0.0001913203886942938,
      "learning_rate": 2.0862207896857374e-05,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 1.0738255033557047,
      "grad_norm": 0.00017235055565834045,
      "learning_rate": 2.0813859790491538e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 1.0782997762863535,
      "grad_norm": 0.00014680517779197544,
      "learning_rate": 2.0765511684125706e-05,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 1.0827740492170022,
      "grad_norm": 0.00016566486738156527,
      "learning_rate": 2.071716357775987e-05,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 1.087248322147651,
      "grad_norm": 0.00016860135656315833,
      "learning_rate": 2.0668815471394037e-05,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 1.0917225950782998,
      "grad_norm": 0.00017679110169410706,
      "learning_rate": 2.06204673650282e-05,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 1.0961968680089484,
      "grad_norm": 0.00016588174912612885,
      "learning_rate": 2.057211925866237e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 1.1006711409395973,
      "grad_norm": 0.0001592787739355117,
      "learning_rate": 2.0523771152296533e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 1.1051454138702461,
      "grad_norm": 0.00017087365267798305,
      "learning_rate": 2.04754230459307e-05,
      "loss": 0.0,
      "step": 2470
    },
    {
      "epoch": 1.109619686800895,
      "grad_norm": 0.0001581790274940431,
      "learning_rate": 2.0427074939564865e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 1.1140939597315436,
      "grad_norm": 0.000150687774294056,
      "learning_rate": 2.0378726833199035e-05,
      "loss": 0.0,
      "step": 2490
    },
    {
      "epoch": 1.1185682326621924,
      "grad_norm": 0.00015774069470353425,
      "learning_rate": 2.03303787268332e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 1.1230425055928412,
      "grad_norm": 0.00017681506869848818,
      "learning_rate": 2.0282030620467367e-05,
      "loss": 0.0,
      "step": 2510
    },
    {
      "epoch": 1.1275167785234899,
      "grad_norm": 0.00016360239533241838,
      "learning_rate": 2.023368251410153e-05,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 1.1319910514541387,
      "grad_norm": 0.00017297269369009882,
      "learning_rate": 2.01853344077357e-05,
      "loss": 0.0,
      "step": 2530
    },
    {
      "epoch": 1.1364653243847875,
      "grad_norm": 0.00015791783516760916,
      "learning_rate": 2.0136986301369863e-05,
      "loss": 0.0,
      "step": 2540
    },
    {
      "epoch": 1.1409395973154361,
      "grad_norm": 0.00014988421753514558,
      "learning_rate": 2.008863819500403e-05,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 1.145413870246085,
      "grad_norm": 0.00016483888612128794,
      "learning_rate": 2.0040290088638194e-05,
      "loss": 0.0,
      "step": 2560
    },
    {
      "epoch": 1.1498881431767338,
      "grad_norm": 0.0001831581466831267,
      "learning_rate": 1.9991941982272362e-05,
      "loss": 0.0,
      "step": 2570
    },
    {
      "epoch": 1.1543624161073827,
      "grad_norm": 0.00017835336620919406,
      "learning_rate": 1.9943593875906526e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 1.1588366890380313,
      "grad_norm": 0.0001645859592827037,
      "learning_rate": 1.9895245769540693e-05,
      "loss": 0.0,
      "step": 2590
    },
    {
      "epoch": 1.1633109619686801,
      "grad_norm": 0.0001466777321184054,
      "learning_rate": 1.9846897663174857e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 1.167785234899329,
      "grad_norm": 0.00016504761879332364,
      "learning_rate": 1.9798549556809025e-05,
      "loss": 0.0,
      "step": 2610
    },
    {
      "epoch": 1.1722595078299776,
      "grad_norm": 0.00014955711958464235,
      "learning_rate": 1.975020145044319e-05,
      "loss": 0.0,
      "step": 2620
    },
    {
      "epoch": 1.1767337807606264,
      "grad_norm": 0.00016786681953817606,
      "learning_rate": 1.9701853344077356e-05,
      "loss": 0.0,
      "step": 2630
    },
    {
      "epoch": 1.1812080536912752,
      "grad_norm": 0.00016753454110585153,
      "learning_rate": 1.965350523771152e-05,
      "loss": 0.0,
      "step": 2640
    },
    {
      "epoch": 1.1856823266219239,
      "grad_norm": 0.00013987395504955202,
      "learning_rate": 1.9605157131345688e-05,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 1.1901565995525727,
      "grad_norm": 0.00018228341650683433,
      "learning_rate": 1.9556809024979856e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 1.1946308724832215,
      "grad_norm": 0.00013869433314539492,
      "learning_rate": 1.9508460918614023e-05,
      "loss": 0.0,
      "step": 2670
    },
    {
      "epoch": 1.1991051454138701,
      "grad_norm": 0.00015375585644505918,
      "learning_rate": 1.9460112812248187e-05,
      "loss": 0.0,
      "step": 2680
    },
    {
      "epoch": 1.203579418344519,
      "grad_norm": 0.00014564783487003297,
      "learning_rate": 1.9411764705882355e-05,
      "loss": 0.0,
      "step": 2690
    },
    {
      "epoch": 1.2080536912751678,
      "grad_norm": 0.00016992009477689862,
      "learning_rate": 1.936341659951652e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 1.2125279642058167,
      "grad_norm": 0.00014535566151607782,
      "learning_rate": 1.9315068493150686e-05,
      "loss": 0.0,
      "step": 2710
    },
    {
      "epoch": 1.2170022371364653,
      "grad_norm": 0.00013646010484080762,
      "learning_rate": 1.926672038678485e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 1.221476510067114,
      "grad_norm": 0.00014275249850470573,
      "learning_rate": 1.9218372280419018e-05,
      "loss": 0.0,
      "step": 2730
    },
    {
      "epoch": 1.225950782997763,
      "grad_norm": 0.00013911275891587138,
      "learning_rate": 1.9170024174053182e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 1.2304250559284116,
      "grad_norm": 0.00014676382124889642,
      "learning_rate": 1.912167606768735e-05,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 1.2348993288590604,
      "grad_norm": 0.00015880826686043292,
      "learning_rate": 1.9073327961321513e-05,
      "loss": 0.0,
      "step": 2760
    },
    {
      "epoch": 1.2393736017897092,
      "grad_norm": 0.00014181228470988572,
      "learning_rate": 1.902497985495568e-05,
      "loss": 0.0,
      "step": 2770
    },
    {
      "epoch": 1.2438478747203578,
      "grad_norm": 0.0001586807193234563,
      "learning_rate": 1.8976631748589845e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 1.2483221476510067,
      "grad_norm": 0.00014681961329188198,
      "learning_rate": 1.8928283642224013e-05,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 1.2527964205816555,
      "grad_norm": 0.00014501382247544825,
      "learning_rate": 1.8879935535858177e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 1.2572706935123041,
      "grad_norm": 0.00014664221089333296,
      "learning_rate": 1.8831587429492344e-05,
      "loss": 0.0,
      "step": 2810
    },
    {
      "epoch": 1.261744966442953,
      "grad_norm": 0.0001601797412149608,
      "learning_rate": 1.8783239323126508e-05,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 1.2662192393736018,
      "grad_norm": 0.00014857371570542455,
      "learning_rate": 1.873489121676068e-05,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 1.2706935123042506,
      "grad_norm": 0.0001340123126283288,
      "learning_rate": 1.8686543110394843e-05,
      "loss": 0.0,
      "step": 2840
    },
    {
      "epoch": 1.2751677852348993,
      "grad_norm": 0.0001316237758146599,
      "learning_rate": 1.863819500402901e-05,
      "loss": 0.0,
      "step": 2850
    },
    {
      "epoch": 1.279642058165548,
      "grad_norm": 0.0001386870862916112,
      "learning_rate": 1.8589846897663175e-05,
      "loss": 0.0,
      "step": 2860
    },
    {
      "epoch": 1.284116331096197,
      "grad_norm": 0.00014489050954580307,
      "learning_rate": 1.8541498791297342e-05,
      "loss": 0.0,
      "step": 2870
    },
    {
      "epoch": 1.2885906040268456,
      "grad_norm": 0.00012809361214749515,
      "learning_rate": 1.8493150684931506e-05,
      "loss": 0.0,
      "step": 2880
    },
    {
      "epoch": 1.2930648769574944,
      "grad_norm": 0.0001290090731345117,
      "learning_rate": 1.8444802578565674e-05,
      "loss": 0.0,
      "step": 2890
    },
    {
      "epoch": 1.2975391498881432,
      "grad_norm": 0.00012588010577019304,
      "learning_rate": 1.8396454472199838e-05,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 1.302013422818792,
      "grad_norm": 0.00012921806774102151,
      "learning_rate": 1.8348106365834005e-05,
      "loss": 0.0,
      "step": 2910
    },
    {
      "epoch": 1.3064876957494407,
      "grad_norm": 0.00015073412214405835,
      "learning_rate": 1.829975825946817e-05,
      "loss": 0.0,
      "step": 2920
    },
    {
      "epoch": 1.3109619686800895,
      "grad_norm": 0.00013639470853377134,
      "learning_rate": 1.8251410153102337e-05,
      "loss": 0.0,
      "step": 2930
    },
    {
      "epoch": 1.3154362416107381,
      "grad_norm": 0.0001393476704834029,
      "learning_rate": 1.82030620467365e-05,
      "loss": 0.0,
      "step": 2940
    },
    {
      "epoch": 1.319910514541387,
      "grad_norm": 0.00014840411313343793,
      "learning_rate": 1.815471394037067e-05,
      "loss": 0.0,
      "step": 2950
    },
    {
      "epoch": 1.3243847874720358,
      "grad_norm": 0.00012574918218888342,
      "learning_rate": 1.8106365834004836e-05,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 1.3288590604026846,
      "grad_norm": 0.00012481964949984103,
      "learning_rate": 1.8058017727639e-05,
      "loss": 0.0,
      "step": 2970
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.0001238901895703748,
      "learning_rate": 1.8009669621273168e-05,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 1.337807606263982,
      "grad_norm": 0.0001221096608787775,
      "learning_rate": 1.7961321514907332e-05,
      "loss": 0.0,
      "step": 2990
    },
    {
      "epoch": 1.342281879194631,
      "grad_norm": 0.00017275832942686975,
      "learning_rate": 1.79129734085415e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 1.342281879194631,
      "eval_loss": 3.2951770663203206e-06,
      "eval_runtime": 107.1093,
      "eval_samples_per_second": 9.336,
      "eval_steps_per_second": 1.167,
      "step": 3000
    },
    {
      "epoch": 1.3467561521252795,
      "grad_norm": 0.00014414377801585943,
      "learning_rate": 1.7864625302175667e-05,
      "loss": 0.0,
      "step": 3010
    },
    {
      "epoch": 1.3512304250559284,
      "grad_norm": 0.00013759432476945221,
      "learning_rate": 1.7816277195809834e-05,
      "loss": 0.0,
      "step": 3020
    },
    {
      "epoch": 1.3557046979865772,
      "grad_norm": 0.00013701408170163631,
      "learning_rate": 1.7767929089443998e-05,
      "loss": 0.0,
      "step": 3030
    },
    {
      "epoch": 1.360178970917226,
      "grad_norm": 0.00012318638619035482,
      "learning_rate": 1.7719580983078166e-05,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 1.3646532438478747,
      "grad_norm": 0.0001255770621355623,
      "learning_rate": 1.767123287671233e-05,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 1.3691275167785235,
      "grad_norm": 0.0001222767459694296,
      "learning_rate": 1.7622884770346497e-05,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 1.3736017897091721,
      "grad_norm": 0.00012041219451930374,
      "learning_rate": 1.757453666398066e-05,
      "loss": 0.0,
      "step": 3070
    },
    {
      "epoch": 1.378076062639821,
      "grad_norm": 0.00012078125291736796,
      "learning_rate": 1.752618855761483e-05,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 1.3825503355704698,
      "grad_norm": 0.00012791604967787862,
      "learning_rate": 1.7477840451248993e-05,
      "loss": 0.0,
      "step": 3090
    },
    {
      "epoch": 1.3870246085011186,
      "grad_norm": 0.00012521937605924904,
      "learning_rate": 1.742949234488316e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 1.3914988814317675,
      "grad_norm": 0.00012560094182845205,
      "learning_rate": 1.7381144238517325e-05,
      "loss": 0.0,
      "step": 3110
    },
    {
      "epoch": 1.395973154362416,
      "grad_norm": 0.00012173948925919831,
      "learning_rate": 1.7332796132151492e-05,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 1.400447427293065,
      "grad_norm": 0.00012944488844368607,
      "learning_rate": 1.7284448025785656e-05,
      "loss": 0.0,
      "step": 3130
    },
    {
      "epoch": 1.4049217002237135,
      "grad_norm": 0.00011866407294292003,
      "learning_rate": 1.7236099919419824e-05,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 1.4093959731543624,
      "grad_norm": 0.00012358733511064202,
      "learning_rate": 1.7187751813053988e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 1.4138702460850112,
      "grad_norm": 0.0001286460756091401,
      "learning_rate": 1.7139403706688155e-05,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 1.41834451901566,
      "grad_norm": 0.00011908346641575918,
      "learning_rate": 1.709105560032232e-05,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 1.4228187919463087,
      "grad_norm": 0.00011459802044555545,
      "learning_rate": 1.704270749395649e-05,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 1.4272930648769575,
      "grad_norm": 0.00011666367936413735,
      "learning_rate": 1.6994359387590654e-05,
      "loss": 0.0,
      "step": 3190
    },
    {
      "epoch": 1.4317673378076063,
      "grad_norm": 0.00011338140757288784,
      "learning_rate": 1.6946011281224822e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 1.436241610738255,
      "grad_norm": 0.00011556853860383853,
      "learning_rate": 1.6897663174858986e-05,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 1.4407158836689038,
      "grad_norm": 0.00011700497998390347,
      "learning_rate": 1.6849315068493153e-05,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 1.4451901565995526,
      "grad_norm": 0.00011149956844747066,
      "learning_rate": 1.6800966962127317e-05,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 1.4496644295302015,
      "grad_norm": 0.0001272336667170748,
      "learning_rate": 1.6752618855761485e-05,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 1.45413870246085,
      "grad_norm": 0.00012037497072014958,
      "learning_rate": 1.670427074939565e-05,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 1.458612975391499,
      "grad_norm": 0.00011982811702182516,
      "learning_rate": 1.6655922643029817e-05,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 1.4630872483221475,
      "grad_norm": 0.00011521232227096334,
      "learning_rate": 1.660757453666398e-05,
      "loss": 0.0,
      "step": 3270
    },
    {
      "epoch": 1.4675615212527964,
      "grad_norm": 0.00010604986891848966,
      "learning_rate": 1.6559226430298148e-05,
      "loss": 0.0,
      "step": 3280
    },
    {
      "epoch": 1.4720357941834452,
      "grad_norm": 0.00011488021118566394,
      "learning_rate": 1.6510878323932312e-05,
      "loss": 0.0,
      "step": 3290
    },
    {
      "epoch": 1.476510067114094,
      "grad_norm": 0.00011669157538563013,
      "learning_rate": 1.646253021756648e-05,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 1.4809843400447427,
      "grad_norm": 0.00011919098324142396,
      "learning_rate": 1.6414182111200644e-05,
      "loss": 0.0,
      "step": 3310
    },
    {
      "epoch": 1.4854586129753915,
      "grad_norm": 0.00011824620742117986,
      "learning_rate": 1.636583400483481e-05,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 1.4899328859060403,
      "grad_norm": 0.00012125765351811424,
      "learning_rate": 1.6317485898468975e-05,
      "loss": 0.0,
      "step": 3330
    },
    {
      "epoch": 1.494407158836689,
      "grad_norm": 0.00011564719170564786,
      "learning_rate": 1.6269137792103143e-05,
      "loss": 0.0,
      "step": 3340
    },
    {
      "epoch": 1.4988814317673378,
      "grad_norm": 0.00011157657718285918,
      "learning_rate": 1.622078968573731e-05,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 1.5033557046979866,
      "grad_norm": 9.533250704407692e-05,
      "learning_rate": 1.6172441579371478e-05,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 1.5078299776286355,
      "grad_norm": 0.00012560772302094847,
      "learning_rate": 1.6124093473005642e-05,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 1.512304250559284,
      "grad_norm": 0.00010850893886527047,
      "learning_rate": 1.607574536663981e-05,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 1.516778523489933,
      "grad_norm": 9.444231545785442e-05,
      "learning_rate": 1.6027397260273974e-05,
      "loss": 0.0,
      "step": 3390
    },
    {
      "epoch": 1.5212527964205815,
      "grad_norm": 0.0001178030070150271,
      "learning_rate": 1.597904915390814e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 1.5257270693512304,
      "grad_norm": 0.0001241271966136992,
      "learning_rate": 1.5930701047542305e-05,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 1.5302013422818792,
      "grad_norm": 0.00011345907114446163,
      "learning_rate": 1.5882352941176473e-05,
      "loss": 0.0,
      "step": 3420
    },
    {
      "epoch": 1.534675615212528,
      "grad_norm": 9.758686064742506e-05,
      "learning_rate": 1.5834004834810637e-05,
      "loss": 0.0,
      "step": 3430
    },
    {
      "epoch": 1.5391498881431769,
      "grad_norm": 0.00010626500443322584,
      "learning_rate": 1.5785656728444804e-05,
      "loss": 0.0,
      "step": 3440
    },
    {
      "epoch": 1.5436241610738255,
      "grad_norm": 0.00010111070878338069,
      "learning_rate": 1.5737308622078968e-05,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 1.548098434004474,
      "grad_norm": 9.656260226620361e-05,
      "learning_rate": 1.5688960515713136e-05,
      "loss": 0.0,
      "step": 3460
    },
    {
      "epoch": 1.552572706935123,
      "grad_norm": 0.00011956900561926886,
      "learning_rate": 1.56406124093473e-05,
      "loss": 0.0,
      "step": 3470
    },
    {
      "epoch": 1.5570469798657718,
      "grad_norm": 0.0001050736682373099,
      "learning_rate": 1.5592264302981467e-05,
      "loss": 0.0,
      "step": 3480
    },
    {
      "epoch": 1.5615212527964206,
      "grad_norm": 0.00010000366455642506,
      "learning_rate": 1.554391619661563e-05,
      "loss": 0.0,
      "step": 3490
    },
    {
      "epoch": 1.5659955257270695,
      "grad_norm": 0.00011140451533719897,
      "learning_rate": 1.54955680902498e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 1.570469798657718,
      "grad_norm": 0.0001025660676532425,
      "learning_rate": 1.5447219983883963e-05,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 1.574944071588367,
      "grad_norm": 0.00011112099309684709,
      "learning_rate": 1.5398871877518134e-05,
      "loss": 0.0,
      "step": 3520
    },
    {
      "epoch": 1.5794183445190155,
      "grad_norm": 0.00011321491911076009,
      "learning_rate": 1.5350523771152298e-05,
      "loss": 0.0,
      "step": 3530
    },
    {
      "epoch": 1.5838926174496644,
      "grad_norm": 0.00010857205052161589,
      "learning_rate": 1.5302175664786465e-05,
      "loss": 0.0,
      "step": 3540
    },
    {
      "epoch": 1.5883668903803132,
      "grad_norm": 9.724737901706249e-05,
      "learning_rate": 1.525382755842063e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 1.592841163310962,
      "grad_norm": 9.80269251158461e-05,
      "learning_rate": 1.5205479452054795e-05,
      "loss": 0.0,
      "step": 3560
    },
    {
      "epoch": 1.5973154362416109,
      "grad_norm": 9.236693585989997e-05,
      "learning_rate": 1.5157131345688961e-05,
      "loss": 0.0,
      "step": 3570
    },
    {
      "epoch": 1.6017897091722595,
      "grad_norm": 0.00010012532584369183,
      "learning_rate": 1.5108783239323127e-05,
      "loss": 0.0,
      "step": 3580
    },
    {
      "epoch": 1.6062639821029083,
      "grad_norm": 0.0001000053744064644,
      "learning_rate": 1.5060435132957293e-05,
      "loss": 0.0,
      "step": 3590
    },
    {
      "epoch": 1.610738255033557,
      "grad_norm": 0.00010614405618980527,
      "learning_rate": 1.5012087026591459e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 1.6152125279642058,
      "grad_norm": 0.0001065488177118823,
      "learning_rate": 1.4963738920225624e-05,
      "loss": 0.0,
      "step": 3610
    },
    {
      "epoch": 1.6196868008948546,
      "grad_norm": 0.00010934408055618405,
      "learning_rate": 1.491539081385979e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 1.6241610738255035,
      "grad_norm": 0.00010717973782448098,
      "learning_rate": 1.4867042707493956e-05,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 1.6286353467561523,
      "grad_norm": 0.00010548338468652219,
      "learning_rate": 1.4818694601128122e-05,
      "loss": 0.0,
      "step": 3640
    },
    {
      "epoch": 1.633109619686801,
      "grad_norm": 0.00010440542973810807,
      "learning_rate": 1.477034649476229e-05,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 1.6375838926174495,
      "grad_norm": 9.492291428614408e-05,
      "learning_rate": 1.4721998388396455e-05,
      "loss": 0.0,
      "step": 3660
    },
    {
      "epoch": 1.6420581655480984,
      "grad_norm": 9.54743882175535e-05,
      "learning_rate": 1.467365028203062e-05,
      "loss": 0.0,
      "step": 3670
    },
    {
      "epoch": 1.6465324384787472,
      "grad_norm": 0.00010775322880363092,
      "learning_rate": 1.4625302175664787e-05,
      "loss": 0.0,
      "step": 3680
    },
    {
      "epoch": 1.651006711409396,
      "grad_norm": 8.84628898347728e-05,
      "learning_rate": 1.4576954069298952e-05,
      "loss": 0.0,
      "step": 3690
    },
    {
      "epoch": 1.6554809843400449,
      "grad_norm": 0.00010643066343618557,
      "learning_rate": 1.4528605962933118e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 1.6599552572706935,
      "grad_norm": 0.00010247505269944668,
      "learning_rate": 1.4480257856567284e-05,
      "loss": 0.0,
      "step": 3710
    },
    {
      "epoch": 1.6644295302013423,
      "grad_norm": 9.982267511077225e-05,
      "learning_rate": 1.443190975020145e-05,
      "loss": 0.0,
      "step": 3720
    },
    {
      "epoch": 1.668903803131991,
      "grad_norm": 0.00010383158951299265,
      "learning_rate": 1.4383561643835615e-05,
      "loss": 0.0,
      "step": 3730
    },
    {
      "epoch": 1.6733780760626398,
      "grad_norm": 0.00010786996426759288,
      "learning_rate": 1.4335213537469783e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 1.6778523489932886,
      "grad_norm": 9.619931370252743e-05,
      "learning_rate": 1.4286865431103949e-05,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 1.6823266219239374,
      "grad_norm": 0.00010100077633978799,
      "learning_rate": 1.4238517324738115e-05,
      "loss": 0.0,
      "step": 3760
    },
    {
      "epoch": 1.6868008948545863,
      "grad_norm": 8.410027658101171e-05,
      "learning_rate": 1.419016921837228e-05,
      "loss": 0.0,
      "step": 3770
    },
    {
      "epoch": 1.691275167785235,
      "grad_norm": 0.00010841168113984168,
      "learning_rate": 1.4141821112006446e-05,
      "loss": 0.0,
      "step": 3780
    },
    {
      "epoch": 1.6957494407158835,
      "grad_norm": 9.143349598161876e-05,
      "learning_rate": 1.4093473005640612e-05,
      "loss": 0.0,
      "step": 3790
    },
    {
      "epoch": 1.7002237136465324,
      "grad_norm": 9.41208636504598e-05,
      "learning_rate": 1.4045124899274778e-05,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 1.7046979865771812,
      "grad_norm": 8.582763985032216e-05,
      "learning_rate": 1.3996776792908943e-05,
      "loss": 0.0,
      "step": 3810
    },
    {
      "epoch": 1.70917225950783,
      "grad_norm": 0.0001033892622217536,
      "learning_rate": 1.3948428686543111e-05,
      "loss": 0.0,
      "step": 3820
    },
    {
      "epoch": 1.7136465324384789,
      "grad_norm": 9.185547969536856e-05,
      "learning_rate": 1.3900080580177277e-05,
      "loss": 0.0,
      "step": 3830
    },
    {
      "epoch": 1.7181208053691275,
      "grad_norm": 8.373600576305762e-05,
      "learning_rate": 1.3851732473811443e-05,
      "loss": 0.0,
      "step": 3840
    },
    {
      "epoch": 1.7225950782997763,
      "grad_norm": 0.00010206433216808364,
      "learning_rate": 1.3803384367445608e-05,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 1.727069351230425,
      "grad_norm": 9.795770893106237e-05,
      "learning_rate": 1.3755036261079774e-05,
      "loss": 0.0,
      "step": 3860
    },
    {
      "epoch": 1.7315436241610738,
      "grad_norm": 8.995817916002125e-05,
      "learning_rate": 1.370668815471394e-05,
      "loss": 0.0,
      "step": 3870
    },
    {
      "epoch": 1.7360178970917226,
      "grad_norm": 0.00010274029045831412,
      "learning_rate": 1.3658340048348106e-05,
      "loss": 0.0,
      "step": 3880
    },
    {
      "epoch": 1.7404921700223714,
      "grad_norm": 8.023723785299808e-05,
      "learning_rate": 1.3609991941982272e-05,
      "loss": 0.0,
      "step": 3890
    },
    {
      "epoch": 1.7449664429530203,
      "grad_norm": 8.898742089513689e-05,
      "learning_rate": 1.3561643835616437e-05,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 1.749440715883669,
      "grad_norm": 9.481659071752802e-05,
      "learning_rate": 1.3513295729250605e-05,
      "loss": 0.0,
      "step": 3910
    },
    {
      "epoch": 1.7539149888143175,
      "grad_norm": 9.211539872922003e-05,
      "learning_rate": 1.346494762288477e-05,
      "loss": 0.0,
      "step": 3920
    },
    {
      "epoch": 1.7583892617449663,
      "grad_norm": 9.353717177873477e-05,
      "learning_rate": 1.3416599516518936e-05,
      "loss": 0.0,
      "step": 3930
    },
    {
      "epoch": 1.7628635346756152,
      "grad_norm": 8.687430818099529e-05,
      "learning_rate": 1.3368251410153102e-05,
      "loss": 0.0,
      "step": 3940
    },
    {
      "epoch": 1.767337807606264,
      "grad_norm": 9.102396870730445e-05,
      "learning_rate": 1.3319903303787268e-05,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 1.7718120805369129,
      "grad_norm": 8.376577170565724e-05,
      "learning_rate": 1.3271555197421434e-05,
      "loss": 0.0,
      "step": 3960
    },
    {
      "epoch": 1.7762863534675615,
      "grad_norm": 0.00010025011579273269,
      "learning_rate": 1.32232070910556e-05,
      "loss": 0.0,
      "step": 3970
    },
    {
      "epoch": 1.7807606263982103,
      "grad_norm": 8.674951095599681e-05,
      "learning_rate": 1.3174858984689765e-05,
      "loss": 0.0,
      "step": 3980
    },
    {
      "epoch": 1.785234899328859,
      "grad_norm": 8.879317465471104e-05,
      "learning_rate": 1.3126510878323931e-05,
      "loss": 0.0,
      "step": 3990
    },
    {
      "epoch": 1.7897091722595078,
      "grad_norm": 7.509357237722725e-05,
      "learning_rate": 1.3078162771958099e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 1.7897091722595078,
      "eval_loss": 2.1845078208571067e-06,
      "eval_runtime": 107.1143,
      "eval_samples_per_second": 9.336,
      "eval_steps_per_second": 1.167,
      "step": 4000
    },
    {
      "epoch": 1.7941834451901566,
      "grad_norm": 8.275360596599057e-05,
      "learning_rate": 1.3029814665592264e-05,
      "loss": 0.0,
      "step": 4010
    },
    {
      "epoch": 1.7986577181208054,
      "grad_norm": 0.00010366120841354132,
      "learning_rate": 1.298146655922643e-05,
      "loss": 0.0,
      "step": 4020
    },
    {
      "epoch": 1.8031319910514543,
      "grad_norm": 7.754972466500476e-05,
      "learning_rate": 1.2933118452860596e-05,
      "loss": 0.0,
      "step": 4030
    },
    {
      "epoch": 1.807606263982103,
      "grad_norm": 9.08493748283945e-05,
      "learning_rate": 1.2884770346494762e-05,
      "loss": 0.0,
      "step": 4040
    },
    {
      "epoch": 1.8120805369127517,
      "grad_norm": 8.567328768549487e-05,
      "learning_rate": 1.2836422240128928e-05,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 1.8165548098434003,
      "grad_norm": 8.874906779965386e-05,
      "learning_rate": 1.2788074133763093e-05,
      "loss": 0.0,
      "step": 4060
    },
    {
      "epoch": 1.8210290827740492,
      "grad_norm": 8.330748096341267e-05,
      "learning_rate": 1.2739726027397259e-05,
      "loss": 0.0,
      "step": 4070
    },
    {
      "epoch": 1.825503355704698,
      "grad_norm": 7.778086001053452e-05,
      "learning_rate": 1.2691377921031427e-05,
      "loss": 0.0,
      "step": 4080
    },
    {
      "epoch": 1.8299776286353469,
      "grad_norm": 8.886786963557824e-05,
      "learning_rate": 1.2643029814665592e-05,
      "loss": 0.0,
      "step": 4090
    },
    {
      "epoch": 1.8344519015659957,
      "grad_norm": 8.994893141789362e-05,
      "learning_rate": 1.2594681708299758e-05,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 1.8389261744966443,
      "grad_norm": 8.568318298785016e-05,
      "learning_rate": 1.2546333601933924e-05,
      "loss": 0.0,
      "step": 4110
    },
    {
      "epoch": 1.843400447427293,
      "grad_norm": 7.721594738541171e-05,
      "learning_rate": 1.249798549556809e-05,
      "loss": 0.0,
      "step": 4120
    },
    {
      "epoch": 1.8478747203579418,
      "grad_norm": 8.938937389757484e-05,
      "learning_rate": 1.2449637389202256e-05,
      "loss": 0.0,
      "step": 4130
    },
    {
      "epoch": 1.8523489932885906,
      "grad_norm": 8.34574966575019e-05,
      "learning_rate": 1.2401289282836421e-05,
      "loss": 0.0,
      "step": 4140
    },
    {
      "epoch": 1.8568232662192394,
      "grad_norm": 8.807366975815967e-05,
      "learning_rate": 1.2352941176470587e-05,
      "loss": 0.0,
      "step": 4150
    },
    {
      "epoch": 1.8612975391498883,
      "grad_norm": 0.00010168196604354307,
      "learning_rate": 1.2304593070104753e-05,
      "loss": 0.0,
      "step": 4160
    },
    {
      "epoch": 1.8657718120805369,
      "grad_norm": 8.032174810068682e-05,
      "learning_rate": 1.225624496373892e-05,
      "loss": 0.0,
      "step": 4170
    },
    {
      "epoch": 1.8702460850111857,
      "grad_norm": 9.69652392086573e-05,
      "learning_rate": 1.2207896857373086e-05,
      "loss": 0.0,
      "step": 4180
    },
    {
      "epoch": 1.8747203579418343,
      "grad_norm": 7.377692963927984e-05,
      "learning_rate": 1.2159548751007252e-05,
      "loss": 0.0,
      "step": 4190
    },
    {
      "epoch": 1.8791946308724832,
      "grad_norm": 6.804839358665049e-05,
      "learning_rate": 1.2111200644641418e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 1.883668903803132,
      "grad_norm": 8.052912016864866e-05,
      "learning_rate": 1.2062852538275584e-05,
      "loss": 0.0,
      "step": 4210
    },
    {
      "epoch": 1.8881431767337808,
      "grad_norm": 7.085492688929662e-05,
      "learning_rate": 1.2014504431909751e-05,
      "loss": 0.0,
      "step": 4220
    },
    {
      "epoch": 1.8926174496644297,
      "grad_norm": 7.698180706938729e-05,
      "learning_rate": 1.1966156325543917e-05,
      "loss": 0.0,
      "step": 4230
    },
    {
      "epoch": 1.8970917225950783,
      "grad_norm": 8.544344018446282e-05,
      "learning_rate": 1.1917808219178083e-05,
      "loss": 0.0,
      "step": 4240
    },
    {
      "epoch": 1.901565995525727,
      "grad_norm": 7.78926769271493e-05,
      "learning_rate": 1.186946011281225e-05,
      "loss": 0.0,
      "step": 4250
    },
    {
      "epoch": 1.9060402684563758,
      "grad_norm": 7.648627070011571e-05,
      "learning_rate": 1.1821112006446416e-05,
      "loss": 0.0,
      "step": 4260
    },
    {
      "epoch": 1.9105145413870246,
      "grad_norm": 7.625004218425602e-05,
      "learning_rate": 1.1772763900080582e-05,
      "loss": 0.0,
      "step": 4270
    },
    {
      "epoch": 1.9149888143176734,
      "grad_norm": 8.44569003675133e-05,
      "learning_rate": 1.1724415793714748e-05,
      "loss": 0.0,
      "step": 4280
    },
    {
      "epoch": 1.9194630872483223,
      "grad_norm": 0.00010211772314505652,
      "learning_rate": 1.1676067687348913e-05,
      "loss": 0.0,
      "step": 4290
    },
    {
      "epoch": 1.9239373601789709,
      "grad_norm": 8.261726179625839e-05,
      "learning_rate": 1.1627719580983079e-05,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 1.9284116331096197,
      "grad_norm": 7.913326408015564e-05,
      "learning_rate": 1.1579371474617245e-05,
      "loss": 0.0,
      "step": 4310
    },
    {
      "epoch": 1.9328859060402683,
      "grad_norm": 7.489490235457197e-05,
      "learning_rate": 1.153102336825141e-05,
      "loss": 0.0,
      "step": 4320
    },
    {
      "epoch": 1.9373601789709172,
      "grad_norm": 8.183554746210575e-05,
      "learning_rate": 1.1482675261885576e-05,
      "loss": 0.0,
      "step": 4330
    },
    {
      "epoch": 1.941834451901566,
      "grad_norm": 7.04815101926215e-05,
      "learning_rate": 1.1434327155519744e-05,
      "loss": 0.0,
      "step": 4340
    },
    {
      "epoch": 1.9463087248322148,
      "grad_norm": 7.86558011895977e-05,
      "learning_rate": 1.138597904915391e-05,
      "loss": 0.0,
      "step": 4350
    },
    {
      "epoch": 1.9507829977628637,
      "grad_norm": 8.041155524551868e-05,
      "learning_rate": 1.1337630942788076e-05,
      "loss": 0.0,
      "step": 4360
    },
    {
      "epoch": 1.9552572706935123,
      "grad_norm": 7.743849710095674e-05,
      "learning_rate": 1.1289282836422241e-05,
      "loss": 0.0,
      "step": 4370
    },
    {
      "epoch": 1.959731543624161,
      "grad_norm": 7.531357550760731e-05,
      "learning_rate": 1.1240934730056407e-05,
      "loss": 0.0,
      "step": 4380
    },
    {
      "epoch": 1.9642058165548097,
      "grad_norm": 7.388072117464617e-05,
      "learning_rate": 1.1192586623690573e-05,
      "loss": 0.0,
      "step": 4390
    },
    {
      "epoch": 1.9686800894854586,
      "grad_norm": 7.737279520370066e-05,
      "learning_rate": 1.1144238517324739e-05,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 1.9731543624161074,
      "grad_norm": 7.580172677990049e-05,
      "learning_rate": 1.1095890410958904e-05,
      "loss": 0.0,
      "step": 4410
    },
    {
      "epoch": 1.9776286353467563,
      "grad_norm": 7.5818708864972e-05,
      "learning_rate": 1.104754230459307e-05,
      "loss": 0.0,
      "step": 4420
    },
    {
      "epoch": 1.9821029082774049,
      "grad_norm": 8.10212513897568e-05,
      "learning_rate": 1.0999194198227238e-05,
      "loss": 0.0,
      "step": 4430
    },
    {
      "epoch": 1.9865771812080537,
      "grad_norm": 7.216980884550139e-05,
      "learning_rate": 1.0950846091861404e-05,
      "loss": 0.0,
      "step": 4440
    },
    {
      "epoch": 1.9910514541387023,
      "grad_norm": 7.72021958255209e-05,
      "learning_rate": 1.090249798549557e-05,
      "loss": 0.0,
      "step": 4450
    },
    {
      "epoch": 1.9955257270693512,
      "grad_norm": 7.291998917935416e-05,
      "learning_rate": 1.0854149879129735e-05,
      "loss": 0.0,
      "step": 4460
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.933402230264619e-05,
      "learning_rate": 1.0805801772763901e-05,
      "loss": 0.0,
      "step": 4470
    },
    {
      "epoch": 2.004474272930649,
      "grad_norm": 6.979099271120504e-05,
      "learning_rate": 1.0757453666398067e-05,
      "loss": 0.0,
      "step": 4480
    },
    {
      "epoch": 2.0089485458612977,
      "grad_norm": 7.478983752662316e-05,
      "learning_rate": 1.0709105560032233e-05,
      "loss": 0.0,
      "step": 4490
    },
    {
      "epoch": 2.0134228187919465,
      "grad_norm": 7.209294562926516e-05,
      "learning_rate": 1.0660757453666398e-05,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 2.017897091722595,
      "grad_norm": 6.841503636678681e-05,
      "learning_rate": 1.0612409347300566e-05,
      "loss": 0.0,
      "step": 4510
    },
    {
      "epoch": 2.0223713646532437,
      "grad_norm": 8.43791349325329e-05,
      "learning_rate": 1.0564061240934732e-05,
      "loss": 0.0,
      "step": 4520
    },
    {
      "epoch": 2.0268456375838926,
      "grad_norm": 6.736759678460658e-05,
      "learning_rate": 1.0515713134568897e-05,
      "loss": 0.0,
      "step": 4530
    },
    {
      "epoch": 2.0313199105145414,
      "grad_norm": 7.221198757179081e-05,
      "learning_rate": 1.0467365028203063e-05,
      "loss": 0.0,
      "step": 4540
    },
    {
      "epoch": 2.0357941834451903,
      "grad_norm": 7.522479427279904e-05,
      "learning_rate": 1.0419016921837229e-05,
      "loss": 0.0,
      "step": 4550
    },
    {
      "epoch": 2.040268456375839,
      "grad_norm": 9.283739927923307e-05,
      "learning_rate": 1.0370668815471395e-05,
      "loss": 0.0,
      "step": 4560
    },
    {
      "epoch": 2.0447427293064875,
      "grad_norm": 7.302933227038011e-05,
      "learning_rate": 1.032232070910556e-05,
      "loss": 0.0,
      "step": 4570
    },
    {
      "epoch": 2.0492170022371363,
      "grad_norm": 8.403590618399903e-05,
      "learning_rate": 1.0273972602739726e-05,
      "loss": 0.0,
      "step": 4580
    },
    {
      "epoch": 2.053691275167785,
      "grad_norm": 6.992131238803267e-05,
      "learning_rate": 1.0225624496373892e-05,
      "loss": 0.0,
      "step": 4590
    },
    {
      "epoch": 2.058165548098434,
      "grad_norm": 6.699895311612636e-05,
      "learning_rate": 1.017727639000806e-05,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 2.062639821029083,
      "grad_norm": 7.783484034007415e-05,
      "learning_rate": 1.0128928283642225e-05,
      "loss": 0.0,
      "step": 4610
    },
    {
      "epoch": 2.0671140939597317,
      "grad_norm": 7.761768938507885e-05,
      "learning_rate": 1.0080580177276391e-05,
      "loss": 0.0,
      "step": 4620
    },
    {
      "epoch": 2.0715883668903805,
      "grad_norm": 7.226282468764111e-05,
      "learning_rate": 1.0032232070910557e-05,
      "loss": 0.0,
      "step": 4630
    },
    {
      "epoch": 2.076062639821029,
      "grad_norm": 6.413782830350101e-05,
      "learning_rate": 9.983883964544723e-06,
      "loss": 0.0,
      "step": 4640
    },
    {
      "epoch": 2.0805369127516777,
      "grad_norm": 6.447083433158696e-05,
      "learning_rate": 9.935535858178889e-06,
      "loss": 0.0,
      "step": 4650
    },
    {
      "epoch": 2.0850111856823266,
      "grad_norm": 6.518526060972363e-05,
      "learning_rate": 9.887187751813054e-06,
      "loss": 0.0,
      "step": 4660
    },
    {
      "epoch": 2.0894854586129754,
      "grad_norm": 7.261034625116736e-05,
      "learning_rate": 9.83883964544722e-06,
      "loss": 0.0,
      "step": 4670
    },
    {
      "epoch": 2.0939597315436242,
      "grad_norm": 7.221476698759943e-05,
      "learning_rate": 9.790491539081388e-06,
      "loss": 0.0,
      "step": 4680
    },
    {
      "epoch": 2.098434004474273,
      "grad_norm": 7.196755177574232e-05,
      "learning_rate": 9.742143432715553e-06,
      "loss": 0.0,
      "step": 4690
    },
    {
      "epoch": 2.1029082774049215,
      "grad_norm": 6.969943933654577e-05,
      "learning_rate": 9.69379532634972e-06,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 2.1073825503355703,
      "grad_norm": 6.671150913462043e-05,
      "learning_rate": 9.645447219983885e-06,
      "loss": 0.0,
      "step": 4710
    },
    {
      "epoch": 2.111856823266219,
      "grad_norm": 7.400041067739949e-05,
      "learning_rate": 9.59709911361805e-06,
      "loss": 0.0,
      "step": 4720
    },
    {
      "epoch": 2.116331096196868,
      "grad_norm": 6.607895193155855e-05,
      "learning_rate": 9.548751007252217e-06,
      "loss": 0.0,
      "step": 4730
    },
    {
      "epoch": 2.120805369127517,
      "grad_norm": 7.485934474971145e-05,
      "learning_rate": 9.500402900886382e-06,
      "loss": 0.0,
      "step": 4740
    },
    {
      "epoch": 2.1252796420581657,
      "grad_norm": 8.22740767034702e-05,
      "learning_rate": 9.452054794520548e-06,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 2.1297539149888145,
      "grad_norm": 6.453491369029507e-05,
      "learning_rate": 9.403706688154714e-06,
      "loss": 0.0,
      "step": 4760
    },
    {
      "epoch": 2.134228187919463,
      "grad_norm": 7.241140701808035e-05,
      "learning_rate": 9.355358581788881e-06,
      "loss": 0.0,
      "step": 4770
    },
    {
      "epoch": 2.1387024608501117,
      "grad_norm": 6.85122431605123e-05,
      "learning_rate": 9.307010475423047e-06,
      "loss": 0.0,
      "step": 4780
    },
    {
      "epoch": 2.1431767337807606,
      "grad_norm": 7.057845505187288e-05,
      "learning_rate": 9.258662369057213e-06,
      "loss": 0.0,
      "step": 4790
    },
    {
      "epoch": 2.1476510067114094,
      "grad_norm": 7.711292710155249e-05,
      "learning_rate": 9.210314262691379e-06,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 2.1521252796420582,
      "grad_norm": 6.710386514896527e-05,
      "learning_rate": 9.161966156325545e-06,
      "loss": 0.0,
      "step": 4810
    },
    {
      "epoch": 2.156599552572707,
      "grad_norm": 5.771407450083643e-05,
      "learning_rate": 9.11361804995971e-06,
      "loss": 0.0,
      "step": 4820
    },
    {
      "epoch": 2.1610738255033555,
      "grad_norm": 6.106172077124938e-05,
      "learning_rate": 9.065269943593876e-06,
      "loss": 0.0,
      "step": 4830
    },
    {
      "epoch": 2.1655480984340043,
      "grad_norm": 6.970715912757441e-05,
      "learning_rate": 9.016921837228042e-06,
      "loss": 0.0,
      "step": 4840
    },
    {
      "epoch": 2.170022371364653,
      "grad_norm": 6.428392953239381e-05,
      "learning_rate": 8.968573730862208e-06,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 2.174496644295302,
      "grad_norm": 5.726353629142977e-05,
      "learning_rate": 8.920225624496375e-06,
      "loss": 0.0,
      "step": 4860
    },
    {
      "epoch": 2.178970917225951,
      "grad_norm": 6.990128895267844e-05,
      "learning_rate": 8.871877518130541e-06,
      "loss": 0.0,
      "step": 4870
    },
    {
      "epoch": 2.1834451901565997,
      "grad_norm": 6.318025407381356e-05,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.0,
      "step": 4880
    },
    {
      "epoch": 2.1879194630872485,
      "grad_norm": 6.984650099184364e-05,
      "learning_rate": 8.775181305398873e-06,
      "loss": 0.0,
      "step": 4890
    },
    {
      "epoch": 2.192393736017897,
      "grad_norm": 6.891650991747156e-05,
      "learning_rate": 8.726833199033038e-06,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 2.1968680089485457,
      "grad_norm": 6.227003177627921e-05,
      "learning_rate": 8.678485092667204e-06,
      "loss": 0.0,
      "step": 4910
    },
    {
      "epoch": 2.2013422818791946,
      "grad_norm": 7.57350426283665e-05,
      "learning_rate": 8.63013698630137e-06,
      "loss": 0.0,
      "step": 4920
    },
    {
      "epoch": 2.2058165548098434,
      "grad_norm": 5.7153542002197355e-05,
      "learning_rate": 8.581788879935536e-06,
      "loss": 0.0,
      "step": 4930
    },
    {
      "epoch": 2.2102908277404922,
      "grad_norm": 6.973122799536213e-05,
      "learning_rate": 8.533440773569703e-06,
      "loss": 0.0,
      "step": 4940
    },
    {
      "epoch": 2.214765100671141,
      "grad_norm": 6.70124136377126e-05,
      "learning_rate": 8.485092667203869e-06,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 2.21923937360179,
      "grad_norm": 6.218396447366104e-05,
      "learning_rate": 8.436744560838035e-06,
      "loss": 0.0,
      "step": 4960
    },
    {
      "epoch": 2.2237136465324383,
      "grad_norm": 6.19826969341375e-05,
      "learning_rate": 8.3883964544722e-06,
      "loss": 0.0,
      "step": 4970
    },
    {
      "epoch": 2.228187919463087,
      "grad_norm": 7.311449735425413e-05,
      "learning_rate": 8.340048348106366e-06,
      "loss": 0.0,
      "step": 4980
    },
    {
      "epoch": 2.232662192393736,
      "grad_norm": 6.590365956071764e-05,
      "learning_rate": 8.291700241740532e-06,
      "loss": 0.0,
      "step": 4990
    },
    {
      "epoch": 2.237136465324385,
      "grad_norm": 6.79990480421111e-05,
      "learning_rate": 8.243352135374698e-06,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 2.237136465324385,
      "eval_loss": 1.6474707535962807e-06,
      "eval_runtime": 109.349,
      "eval_samples_per_second": 9.145,
      "eval_steps_per_second": 1.143,
      "step": 5000
    },
    {
      "epoch": 2.2416107382550337,
      "grad_norm": 6.20161445112899e-05,
      "learning_rate": 8.195004029008864e-06,
      "loss": 0.0,
      "step": 5010
    },
    {
      "epoch": 2.2460850111856825,
      "grad_norm": 6.64306353428401e-05,
      "learning_rate": 8.14665592264303e-06,
      "loss": 0.0,
      "step": 5020
    },
    {
      "epoch": 2.2505592841163313,
      "grad_norm": 6.674498581560329e-05,
      "learning_rate": 8.098307816277197e-06,
      "loss": 0.0,
      "step": 5030
    },
    {
      "epoch": 2.2550335570469797,
      "grad_norm": 6.993253919063136e-05,
      "learning_rate": 8.049959709911363e-06,
      "loss": 0.0,
      "step": 5040
    },
    {
      "epoch": 2.2595078299776286,
      "grad_norm": 6.115538417361677e-05,
      "learning_rate": 8.001611603545529e-06,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 2.2639821029082774,
      "grad_norm": 6.655066681560129e-05,
      "learning_rate": 7.953263497179694e-06,
      "loss": 0.0,
      "step": 5060
    },
    {
      "epoch": 2.2684563758389262,
      "grad_norm": 5.9710735513363034e-05,
      "learning_rate": 7.90491539081386e-06,
      "loss": 0.0,
      "step": 5070
    },
    {
      "epoch": 2.272930648769575,
      "grad_norm": 5.813548341393471e-05,
      "learning_rate": 7.856567284448026e-06,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 2.277404921700224,
      "grad_norm": 6.21680956101045e-05,
      "learning_rate": 7.808219178082192e-06,
      "loss": 0.0,
      "step": 5090
    },
    {
      "epoch": 2.2818791946308723,
      "grad_norm": 6.656994810327888e-05,
      "learning_rate": 7.759871071716358e-06,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 2.286353467561521,
      "grad_norm": 7.059442577883601e-05,
      "learning_rate": 7.711522965350523e-06,
      "loss": 0.0,
      "step": 5110
    },
    {
      "epoch": 2.29082774049217,
      "grad_norm": 5.5686949053779244e-05,
      "learning_rate": 7.663174858984691e-06,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 2.295302013422819,
      "grad_norm": 6.011162986396812e-05,
      "learning_rate": 7.614826752618857e-06,
      "loss": 0.0,
      "step": 5130
    },
    {
      "epoch": 2.2997762863534676,
      "grad_norm": 5.800020880997181e-05,
      "learning_rate": 7.5664786462530224e-06,
      "loss": 0.0,
      "step": 5140
    },
    {
      "epoch": 2.3042505592841165,
      "grad_norm": 7.121578528312966e-05,
      "learning_rate": 7.518130539887188e-06,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 2.3087248322147653,
      "grad_norm": 6.78018041071482e-05,
      "learning_rate": 7.469782433521354e-06,
      "loss": 0.0,
      "step": 5160
    },
    {
      "epoch": 2.3131991051454137,
      "grad_norm": 6.931454117875546e-05,
      "learning_rate": 7.42143432715552e-06,
      "loss": 0.0,
      "step": 5170
    },
    {
      "epoch": 2.3176733780760626,
      "grad_norm": 6.268285505939275e-05,
      "learning_rate": 7.3730862207896864e-06,
      "loss": 0.0,
      "step": 5180
    },
    {
      "epoch": 2.3221476510067114,
      "grad_norm": 7.161561370594427e-05,
      "learning_rate": 7.324738114423852e-06,
      "loss": 0.0,
      "step": 5190
    },
    {
      "epoch": 2.3266219239373602,
      "grad_norm": 6.297670188359916e-05,
      "learning_rate": 7.276390008058018e-06,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 2.331096196868009,
      "grad_norm": 6.261009548325092e-05,
      "learning_rate": 7.228041901692184e-06,
      "loss": 0.0,
      "step": 5210
    },
    {
      "epoch": 2.335570469798658,
      "grad_norm": 6.720477540511638e-05,
      "learning_rate": 7.1796937953263505e-06,
      "loss": 0.0,
      "step": 5220
    },
    {
      "epoch": 2.3400447427293063,
      "grad_norm": 5.594129834207706e-05,
      "learning_rate": 7.131345688960516e-06,
      "loss": 0.0,
      "step": 5230
    },
    {
      "epoch": 2.344519015659955,
      "grad_norm": 5.776978287030943e-05,
      "learning_rate": 7.082997582594682e-06,
      "loss": 0.0,
      "step": 5240
    },
    {
      "epoch": 2.348993288590604,
      "grad_norm": 6.854120147181675e-05,
      "learning_rate": 7.034649476228848e-06,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 2.353467561521253,
      "grad_norm": 6.790276529500261e-05,
      "learning_rate": 6.986301369863014e-06,
      "loss": 0.0,
      "step": 5260
    },
    {
      "epoch": 2.3579418344519016,
      "grad_norm": 6.300103268586099e-05,
      "learning_rate": 6.93795326349718e-06,
      "loss": 0.0,
      "step": 5270
    },
    {
      "epoch": 2.3624161073825505,
      "grad_norm": 6.707688589813188e-05,
      "learning_rate": 6.889605157131346e-06,
      "loss": 0.0,
      "step": 5280
    },
    {
      "epoch": 2.3668903803131993,
      "grad_norm": 6.708092405460775e-05,
      "learning_rate": 6.841257050765512e-06,
      "loss": 0.0,
      "step": 5290
    },
    {
      "epoch": 2.3713646532438477,
      "grad_norm": 5.688915553037077e-05,
      "learning_rate": 6.792908944399678e-06,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 2.3758389261744965,
      "grad_norm": 5.921287811361253e-05,
      "learning_rate": 6.744560838033844e-06,
      "loss": 0.0,
      "step": 5310
    },
    {
      "epoch": 2.3803131991051454,
      "grad_norm": 6.371553899953142e-05,
      "learning_rate": 6.69621273166801e-06,
      "loss": 0.0,
      "step": 5320
    },
    {
      "epoch": 2.384787472035794,
      "grad_norm": 5.9506473917281255e-05,
      "learning_rate": 6.647864625302176e-06,
      "loss": 0.0,
      "step": 5330
    },
    {
      "epoch": 2.389261744966443,
      "grad_norm": 5.7158769777743146e-05,
      "learning_rate": 6.599516518936342e-06,
      "loss": 0.0,
      "step": 5340
    },
    {
      "epoch": 2.393736017897092,
      "grad_norm": 6.0518301324918866e-05,
      "learning_rate": 6.551168412570508e-06,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 2.3982102908277403,
      "grad_norm": 5.8773595810635015e-05,
      "learning_rate": 6.502820306204674e-06,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 2.402684563758389,
      "grad_norm": 6.39380159555003e-05,
      "learning_rate": 6.45447219983884e-06,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 2.407158836689038,
      "grad_norm": 5.440252789412625e-05,
      "learning_rate": 6.406124093473006e-06,
      "loss": 0.0,
      "step": 5380
    },
    {
      "epoch": 2.411633109619687,
      "grad_norm": 6.348672468448058e-05,
      "learning_rate": 6.3577759871071714e-06,
      "loss": 0.0,
      "step": 5390
    },
    {
      "epoch": 2.4161073825503356,
      "grad_norm": 5.849563603987917e-05,
      "learning_rate": 6.309427880741338e-06,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 2.4205816554809845,
      "grad_norm": 5.5582371714990586e-05,
      "learning_rate": 6.261079774375504e-06,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 2.4250559284116333,
      "grad_norm": 5.7571767683839425e-05,
      "learning_rate": 6.21273166800967e-06,
      "loss": 0.0,
      "step": 5420
    },
    {
      "epoch": 2.4295302013422817,
      "grad_norm": 5.583086749538779e-05,
      "learning_rate": 6.1643835616438354e-06,
      "loss": 0.0,
      "step": 5430
    },
    {
      "epoch": 2.4340044742729305,
      "grad_norm": 6.086582288844511e-05,
      "learning_rate": 6.116035455278002e-06,
      "loss": 0.0,
      "step": 5440
    },
    {
      "epoch": 2.4384787472035794,
      "grad_norm": 6.144435610622168e-05,
      "learning_rate": 6.067687348912168e-06,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 2.442953020134228,
      "grad_norm": 6.484325422206894e-05,
      "learning_rate": 6.019339242546334e-06,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 2.447427293064877,
      "grad_norm": 6.796528032282367e-05,
      "learning_rate": 5.9709911361804995e-06,
      "loss": 0.0,
      "step": 5470
    },
    {
      "epoch": 2.451901565995526,
      "grad_norm": 6.396701064659283e-05,
      "learning_rate": 5.922643029814666e-06,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 2.4563758389261743,
      "grad_norm": 5.994315870339051e-05,
      "learning_rate": 5.874294923448832e-06,
      "loss": 0.0,
      "step": 5490
    },
    {
      "epoch": 2.460850111856823,
      "grad_norm": 5.60426342417486e-05,
      "learning_rate": 5.825946817082998e-06,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 2.465324384787472,
      "grad_norm": 5.25009490957018e-05,
      "learning_rate": 5.7775987107171635e-06,
      "loss": 0.0,
      "step": 5510
    },
    {
      "epoch": 2.469798657718121,
      "grad_norm": 5.859194789081812e-05,
      "learning_rate": 5.729250604351329e-06,
      "loss": 0.0,
      "step": 5520
    },
    {
      "epoch": 2.4742729306487696,
      "grad_norm": 5.462387343868613e-05,
      "learning_rate": 5.680902497985496e-06,
      "loss": 0.0,
      "step": 5530
    },
    {
      "epoch": 2.4787472035794185,
      "grad_norm": 5.966493336018175e-05,
      "learning_rate": 5.632554391619662e-06,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 2.4832214765100673,
      "grad_norm": 5.247404260444455e-05,
      "learning_rate": 5.5842062852538275e-06,
      "loss": 0.0,
      "step": 5550
    },
    {
      "epoch": 2.4876957494407157,
      "grad_norm": 6.43045932520181e-05,
      "learning_rate": 5.535858178887993e-06,
      "loss": 0.0,
      "step": 5560
    },
    {
      "epoch": 2.4921700223713645,
      "grad_norm": 6.154394941404462e-05,
      "learning_rate": 5.48751007252216e-06,
      "loss": 0.0,
      "step": 5570
    },
    {
      "epoch": 2.4966442953020134,
      "grad_norm": 6.25266766292043e-05,
      "learning_rate": 5.439161966156326e-06,
      "loss": 0.0,
      "step": 5580
    },
    {
      "epoch": 2.501118568232662,
      "grad_norm": 5.6132907047867775e-05,
      "learning_rate": 5.3908138597904915e-06,
      "loss": 0.0,
      "step": 5590
    },
    {
      "epoch": 2.505592841163311,
      "grad_norm": 7.215578079922125e-05,
      "learning_rate": 5.342465753424657e-06,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 2.51006711409396,
      "grad_norm": 5.934899309067987e-05,
      "learning_rate": 5.294117647058824e-06,
      "loss": 0.0,
      "step": 5610
    },
    {
      "epoch": 2.5145413870246083,
      "grad_norm": 6.351349293254316e-05,
      "learning_rate": 5.24576954069299e-06,
      "loss": 0.0,
      "step": 5620
    },
    {
      "epoch": 2.519015659955257,
      "grad_norm": 5.672117549693212e-05,
      "learning_rate": 5.1974214343271555e-06,
      "loss": 0.0,
      "step": 5630
    },
    {
      "epoch": 2.523489932885906,
      "grad_norm": 5.772104850620963e-05,
      "learning_rate": 5.149073327961321e-06,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 2.527964205816555,
      "grad_norm": 5.590070577454753e-05,
      "learning_rate": 5.100725221595488e-06,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 2.5324384787472036,
      "grad_norm": 5.676484579453245e-05,
      "learning_rate": 5.052377115229654e-06,
      "loss": 0.0,
      "step": 5660
    },
    {
      "epoch": 2.5369127516778525,
      "grad_norm": 5.7418281357968226e-05,
      "learning_rate": 5.0040290088638195e-06,
      "loss": 0.0,
      "step": 5670
    },
    {
      "epoch": 2.5413870246085013,
      "grad_norm": 5.912146298214793e-05,
      "learning_rate": 4.955680902497985e-06,
      "loss": 0.0,
      "step": 5680
    },
    {
      "epoch": 2.54586129753915,
      "grad_norm": 6.135553121566772e-05,
      "learning_rate": 4.907332796132151e-06,
      "loss": 0.0,
      "step": 5690
    },
    {
      "epoch": 2.5503355704697985,
      "grad_norm": 6.1018326960038394e-05,
      "learning_rate": 4.858984689766318e-06,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 2.5548098434004474,
      "grad_norm": 5.592121306108311e-05,
      "learning_rate": 4.8106365834004835e-06,
      "loss": 0.0,
      "step": 5710
    },
    {
      "epoch": 2.559284116331096,
      "grad_norm": 6.215352186700329e-05,
      "learning_rate": 4.762288477034649e-06,
      "loss": 0.0,
      "step": 5720
    },
    {
      "epoch": 2.563758389261745,
      "grad_norm": 5.3188687161309645e-05,
      "learning_rate": 4.713940370668815e-06,
      "loss": 0.0,
      "step": 5730
    },
    {
      "epoch": 2.568232662192394,
      "grad_norm": 6.0761416534660384e-05,
      "learning_rate": 4.665592264302982e-06,
      "loss": 0.0,
      "step": 5740
    },
    {
      "epoch": 2.5727069351230423,
      "grad_norm": 5.6379310990450904e-05,
      "learning_rate": 4.6172441579371475e-06,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 2.577181208053691,
      "grad_norm": 5.6238033721456304e-05,
      "learning_rate": 4.568896051571313e-06,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 2.58165548098434,
      "grad_norm": 6.163157377159223e-05,
      "learning_rate": 4.520547945205479e-06,
      "loss": 0.0,
      "step": 5770
    },
    {
      "epoch": 2.586129753914989,
      "grad_norm": 6.228760321391746e-05,
      "learning_rate": 4.472199838839646e-06,
      "loss": 0.0,
      "step": 5780
    },
    {
      "epoch": 2.5906040268456376,
      "grad_norm": 6.229481368791312e-05,
      "learning_rate": 4.4238517324738115e-06,
      "loss": 0.0,
      "step": 5790
    },
    {
      "epoch": 2.5950782997762865,
      "grad_norm": 5.282026540953666e-05,
      "learning_rate": 4.375503626107977e-06,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 2.5995525727069353,
      "grad_norm": 6.665389082627371e-05,
      "learning_rate": 4.327155519742143e-06,
      "loss": 0.0,
      "step": 5810
    },
    {
      "epoch": 2.604026845637584,
      "grad_norm": 5.341880751075223e-05,
      "learning_rate": 4.278807413376309e-06,
      "loss": 0.0,
      "step": 5820
    },
    {
      "epoch": 2.6085011185682325,
      "grad_norm": 5.769580093328841e-05,
      "learning_rate": 4.2304593070104755e-06,
      "loss": 0.0,
      "step": 5830
    },
    {
      "epoch": 2.6129753914988814,
      "grad_norm": 5.444334601634182e-05,
      "learning_rate": 4.182111200644641e-06,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 2.61744966442953,
      "grad_norm": 5.311588756740093e-05,
      "learning_rate": 4.133763094278807e-06,
      "loss": 0.0,
      "step": 5850
    },
    {
      "epoch": 2.621923937360179,
      "grad_norm": 5.270099427434616e-05,
      "learning_rate": 4.085414987912973e-06,
      "loss": 0.0,
      "step": 5860
    },
    {
      "epoch": 2.626398210290828,
      "grad_norm": 5.530261842068285e-05,
      "learning_rate": 4.0370668815471395e-06,
      "loss": 0.0,
      "step": 5870
    },
    {
      "epoch": 2.6308724832214763,
      "grad_norm": 5.640710151055828e-05,
      "learning_rate": 3.988718775181305e-06,
      "loss": 0.0,
      "step": 5880
    },
    {
      "epoch": 2.635346756152125,
      "grad_norm": 6.168110849102959e-05,
      "learning_rate": 3.940370668815471e-06,
      "loss": 0.0,
      "step": 5890
    },
    {
      "epoch": 2.639821029082774,
      "grad_norm": 5.82052962272428e-05,
      "learning_rate": 3.892022562449637e-06,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 2.6442953020134228,
      "grad_norm": 5.778139166068286e-05,
      "learning_rate": 3.8436744560838036e-06,
      "loss": 0.0,
      "step": 5910
    },
    {
      "epoch": 2.6487695749440716,
      "grad_norm": 5.5797554523451254e-05,
      "learning_rate": 3.7953263497179698e-06,
      "loss": 0.0,
      "step": 5920
    },
    {
      "epoch": 2.6532438478747205,
      "grad_norm": 5.051809421274811e-05,
      "learning_rate": 3.7469782433521356e-06,
      "loss": 0.0,
      "step": 5930
    },
    {
      "epoch": 2.6577181208053693,
      "grad_norm": 5.209941809880547e-05,
      "learning_rate": 3.6986301369863014e-06,
      "loss": 0.0,
      "step": 5940
    },
    {
      "epoch": 2.662192393736018,
      "grad_norm": 5.394661275204271e-05,
      "learning_rate": 3.6502820306204676e-06,
      "loss": 0.0,
      "step": 5950
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 5.323876757756807e-05,
      "learning_rate": 3.6019339242546334e-06,
      "loss": 0.0,
      "step": 5960
    },
    {
      "epoch": 2.6711409395973154,
      "grad_norm": 5.129974306328222e-05,
      "learning_rate": 3.5535858178887996e-06,
      "loss": 0.0,
      "step": 5970
    },
    {
      "epoch": 2.675615212527964,
      "grad_norm": 5.5248670832952484e-05,
      "learning_rate": 3.5052377115229654e-06,
      "loss": 0.0,
      "step": 5980
    },
    {
      "epoch": 2.680089485458613,
      "grad_norm": 6.198066694196314e-05,
      "learning_rate": 3.4568896051571316e-06,
      "loss": 0.0,
      "step": 5990
    },
    {
      "epoch": 2.684563758389262,
      "grad_norm": 5.4892327170819044e-05,
      "learning_rate": 3.4085414987912974e-06,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 2.684563758389262,
      "eval_loss": 1.319765374319104e-06,
      "eval_runtime": 119.9233,
      "eval_samples_per_second": 8.339,
      "eval_steps_per_second": 1.042,
      "step": 6000
    },
    {
      "epoch": 2.6890380313199103,
      "grad_norm": 5.4420761443907395e-05,
      "learning_rate": 3.3601933924254636e-06,
      "loss": 0.0,
      "step": 6010
    },
    {
      "epoch": 2.693512304250559,
      "grad_norm": 5.13121449330356e-05,
      "learning_rate": 3.3118452860596294e-06,
      "loss": 0.0,
      "step": 6020
    },
    {
      "epoch": 2.697986577181208,
      "grad_norm": 5.9982943639624864e-05,
      "learning_rate": 3.2634971796937956e-06,
      "loss": 0.0,
      "step": 6030
    },
    {
      "epoch": 2.7024608501118568,
      "grad_norm": 4.868829273618758e-05,
      "learning_rate": 3.2151490733279614e-06,
      "loss": 0.0,
      "step": 6040
    },
    {
      "epoch": 2.7069351230425056,
      "grad_norm": 5.783689266536385e-05,
      "learning_rate": 3.1668009669621276e-06,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 2.7114093959731544,
      "grad_norm": 5.6831861002137884e-05,
      "learning_rate": 3.1184528605962934e-06,
      "loss": 0.0,
      "step": 6060
    },
    {
      "epoch": 2.7158836689038033,
      "grad_norm": 5.92119395150803e-05,
      "learning_rate": 3.0701047542304596e-06,
      "loss": 0.0,
      "step": 6070
    },
    {
      "epoch": 2.720357941834452,
      "grad_norm": 5.927386519033462e-05,
      "learning_rate": 3.0217566478646254e-06,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 2.7248322147651005,
      "grad_norm": 5.957824760116637e-05,
      "learning_rate": 2.973408541498791e-06,
      "loss": 0.0,
      "step": 6090
    },
    {
      "epoch": 2.7293064876957494,
      "grad_norm": 5.250642425380647e-05,
      "learning_rate": 2.9250604351329574e-06,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 2.733780760626398,
      "grad_norm": 5.1943290600320324e-05,
      "learning_rate": 2.876712328767123e-06,
      "loss": 0.0,
      "step": 6110
    },
    {
      "epoch": 2.738255033557047,
      "grad_norm": 4.854617145610973e-05,
      "learning_rate": 2.8283642224012894e-06,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 2.742729306487696,
      "grad_norm": 5.588799103861675e-05,
      "learning_rate": 2.780016116035455e-06,
      "loss": 0.0,
      "step": 6130
    },
    {
      "epoch": 2.7472035794183443,
      "grad_norm": 4.691759750130586e-05,
      "learning_rate": 2.7316680096696214e-06,
      "loss": 0.0,
      "step": 6140
    },
    {
      "epoch": 2.751677852348993,
      "grad_norm": 5.506330853677355e-05,
      "learning_rate": 2.683319903303787e-06,
      "loss": 0.0,
      "step": 6150
    },
    {
      "epoch": 2.756152125279642,
      "grad_norm": 5.909427272854373e-05,
      "learning_rate": 2.6349717969379534e-06,
      "loss": 0.0,
      "step": 6160
    },
    {
      "epoch": 2.7606263982102908,
      "grad_norm": 5.5099426390370354e-05,
      "learning_rate": 2.586623690572119e-06,
      "loss": 0.0,
      "step": 6170
    },
    {
      "epoch": 2.7651006711409396,
      "grad_norm": 4.836525840801187e-05,
      "learning_rate": 2.5382755842062854e-06,
      "loss": 0.0,
      "step": 6180
    },
    {
      "epoch": 2.7695749440715884,
      "grad_norm": 4.9547525122761726e-05,
      "learning_rate": 2.489927477840451e-06,
      "loss": 0.0,
      "step": 6190
    },
    {
      "epoch": 2.7740492170022373,
      "grad_norm": 5.4760304919909686e-05,
      "learning_rate": 2.4415793714746174e-06,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 2.778523489932886,
      "grad_norm": 5.2781542763113976e-05,
      "learning_rate": 2.393231265108783e-06,
      "loss": 0.0,
      "step": 6210
    },
    {
      "epoch": 2.782997762863535,
      "grad_norm": 4.724856626125984e-05,
      "learning_rate": 2.344883158742949e-06,
      "loss": 0.0,
      "step": 6220
    },
    {
      "epoch": 2.7874720357941833,
      "grad_norm": 5.4079464462120086e-05,
      "learning_rate": 2.296535052377115e-06,
      "loss": 0.0,
      "step": 6230
    },
    {
      "epoch": 2.791946308724832,
      "grad_norm": 5.268285167403519e-05,
      "learning_rate": 2.248186946011281e-06,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 2.796420581655481,
      "grad_norm": 6.198445771588013e-05,
      "learning_rate": 2.1998388396454472e-06,
      "loss": 0.0,
      "step": 6250
    },
    {
      "epoch": 2.80089485458613,
      "grad_norm": 5.918180613662116e-05,
      "learning_rate": 2.151490733279613e-06,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 2.8053691275167782,
      "grad_norm": 5.389785656007007e-05,
      "learning_rate": 2.1031426269137792e-06,
      "loss": 0.0,
      "step": 6270
    },
    {
      "epoch": 2.809843400447427,
      "grad_norm": 5.149361095391214e-05,
      "learning_rate": 2.054794520547945e-06,
      "loss": 0.0,
      "step": 6280
    },
    {
      "epoch": 2.814317673378076,
      "grad_norm": 5.256853182800114e-05,
      "learning_rate": 2.0064464141821112e-06,
      "loss": 0.0,
      "step": 6290
    },
    {
      "epoch": 2.8187919463087248,
      "grad_norm": 5.8088353398488835e-05,
      "learning_rate": 1.958098307816277e-06,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 2.8232662192393736,
      "grad_norm": 5.228121517575346e-05,
      "learning_rate": 1.9097502014504432e-06,
      "loss": 0.0,
      "step": 6310
    },
    {
      "epoch": 2.8277404921700224,
      "grad_norm": 5.6324042816413566e-05,
      "learning_rate": 1.8614020950846092e-06,
      "loss": 0.0,
      "step": 6320
    },
    {
      "epoch": 2.8322147651006713,
      "grad_norm": 5.381883602240123e-05,
      "learning_rate": 1.8130539887187752e-06,
      "loss": 0.0,
      "step": 6330
    },
    {
      "epoch": 2.83668903803132,
      "grad_norm": 5.76499842281919e-05,
      "learning_rate": 1.7647058823529412e-06,
      "loss": 0.0,
      "step": 6340
    },
    {
      "epoch": 2.841163310961969,
      "grad_norm": 4.6787699830019847e-05,
      "learning_rate": 1.7163577759871072e-06,
      "loss": 0.0,
      "step": 6350
    },
    {
      "epoch": 2.8456375838926173,
      "grad_norm": 6.162500358186662e-05,
      "learning_rate": 1.6680096696212732e-06,
      "loss": 0.0,
      "step": 6360
    },
    {
      "epoch": 2.850111856823266,
      "grad_norm": 5.245725697022863e-05,
      "learning_rate": 1.6196615632554392e-06,
      "loss": 0.0,
      "step": 6370
    },
    {
      "epoch": 2.854586129753915,
      "grad_norm": 5.4457148507935926e-05,
      "learning_rate": 1.5713134568896052e-06,
      "loss": 0.0,
      "step": 6380
    },
    {
      "epoch": 2.859060402684564,
      "grad_norm": 5.562319347518496e-05,
      "learning_rate": 1.5229653505237712e-06,
      "loss": 0.0,
      "step": 6390
    },
    {
      "epoch": 2.8635346756152127,
      "grad_norm": 5.057498856331222e-05,
      "learning_rate": 1.4746172441579372e-06,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 2.868008948545861,
      "grad_norm": 5.316637907526456e-05,
      "learning_rate": 1.4262691377921032e-06,
      "loss": 0.0,
      "step": 6410
    },
    {
      "epoch": 2.87248322147651,
      "grad_norm": 5.4019095841795206e-05,
      "learning_rate": 1.3779210314262693e-06,
      "loss": 0.0,
      "step": 6420
    },
    {
      "epoch": 2.8769574944071588,
      "grad_norm": 5.039793541072868e-05,
      "learning_rate": 1.329572925060435e-06,
      "loss": 0.0,
      "step": 6430
    },
    {
      "epoch": 2.8814317673378076,
      "grad_norm": 4.892220385954715e-05,
      "learning_rate": 1.281224818694601e-06,
      "loss": 0.0,
      "step": 6440
    },
    {
      "epoch": 2.8859060402684564,
      "grad_norm": 6.41315127722919e-05,
      "learning_rate": 1.232876712328767e-06,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 2.8903803131991053,
      "grad_norm": 5.8971065300283954e-05,
      "learning_rate": 1.184528605962933e-06,
      "loss": 0.0,
      "step": 6460
    },
    {
      "epoch": 2.894854586129754,
      "grad_norm": 5.150408105691895e-05,
      "learning_rate": 1.136180499597099e-06,
      "loss": 0.0,
      "step": 6470
    },
    {
      "epoch": 2.899328859060403,
      "grad_norm": 5.277317177387886e-05,
      "learning_rate": 1.087832393231265e-06,
      "loss": 0.0,
      "step": 6480
    },
    {
      "epoch": 2.9038031319910513,
      "grad_norm": 5.376513581722975e-05,
      "learning_rate": 1.039484286865431e-06,
      "loss": 0.0,
      "step": 6490
    },
    {
      "epoch": 2.9082774049217,
      "grad_norm": 5.610953667201102e-05,
      "learning_rate": 9.91136180499597e-07,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 2.912751677852349,
      "grad_norm": 6.19741331320256e-05,
      "learning_rate": 9.427880741337632e-07,
      "loss": 0.0,
      "step": 6510
    },
    {
      "epoch": 2.917225950782998,
      "grad_norm": 5.6074579333653674e-05,
      "learning_rate": 8.944399677679292e-07,
      "loss": 0.0,
      "step": 6520
    },
    {
      "epoch": 2.9217002237136467,
      "grad_norm": 4.4395041186362505e-05,
      "learning_rate": 8.460918614020952e-07,
      "loss": 0.0,
      "step": 6530
    },
    {
      "epoch": 2.926174496644295,
      "grad_norm": 4.648517642635852e-05,
      "learning_rate": 7.977437550362611e-07,
      "loss": 0.0,
      "step": 6540
    },
    {
      "epoch": 2.930648769574944,
      "grad_norm": 5.418795262812637e-05,
      "learning_rate": 7.493956486704271e-07,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 2.9351230425055927,
      "grad_norm": 4.8075427912408486e-05,
      "learning_rate": 7.010475423045931e-07,
      "loss": 0.0,
      "step": 6560
    },
    {
      "epoch": 2.9395973154362416,
      "grad_norm": 5.099886766402051e-05,
      "learning_rate": 6.526994359387591e-07,
      "loss": 0.0,
      "step": 6570
    },
    {
      "epoch": 2.9440715883668904,
      "grad_norm": 5.049570245319046e-05,
      "learning_rate": 6.043513295729251e-07,
      "loss": 0.0,
      "step": 6580
    },
    {
      "epoch": 2.9485458612975393,
      "grad_norm": 4.726982660940848e-05,
      "learning_rate": 5.560032232070911e-07,
      "loss": 0.0,
      "step": 6590
    },
    {
      "epoch": 2.953020134228188,
      "grad_norm": 5.1892802730435506e-05,
      "learning_rate": 5.076551168412571e-07,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 2.957494407158837,
      "grad_norm": 5.4444641136797145e-05,
      "learning_rate": 4.593070104754231e-07,
      "loss": 0.0,
      "step": 6610
    },
    {
      "epoch": 2.9619686800894853,
      "grad_norm": 5.112089274916798e-05,
      "learning_rate": 4.1095890410958903e-07,
      "loss": 0.0,
      "step": 6620
    },
    {
      "epoch": 2.966442953020134,
      "grad_norm": 5.322278957464732e-05,
      "learning_rate": 3.6261079774375504e-07,
      "loss": 0.0,
      "step": 6630
    },
    {
      "epoch": 2.970917225950783,
      "grad_norm": 4.444950900506228e-05,
      "learning_rate": 3.1426269137792104e-07,
      "loss": 0.0,
      "step": 6640
    },
    {
      "epoch": 2.975391498881432,
      "grad_norm": 5.2941009926144034e-05,
      "learning_rate": 2.6591458501208704e-07,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 2.9798657718120807,
      "grad_norm": 5.2321538532851264e-05,
      "learning_rate": 2.1756647864625304e-07,
      "loss": 0.0,
      "step": 6660
    },
    {
      "epoch": 2.984340044742729,
      "grad_norm": 5.1516031817300245e-05,
      "learning_rate": 1.6921837228041902e-07,
      "loss": 0.0,
      "step": 6670
    },
    {
      "epoch": 2.988814317673378,
      "grad_norm": 5.224644337431528e-05,
      "learning_rate": 1.20870265914585e-07,
      "loss": 0.0,
      "step": 6680
    },
    {
      "epoch": 2.9932885906040267,
      "grad_norm": 4.385632564662956e-05,
      "learning_rate": 7.252215954875101e-08,
      "loss": 0.0,
      "step": 6690
    },
    {
      "epoch": 2.9977628635346756,
      "grad_norm": 5.199772567721084e-05,
      "learning_rate": 2.4174053182917002e-08,
      "loss": 0.0,
      "step": 6700
    }
  ],
  "logging_steps": 10,
  "max_steps": 6705,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.411169834317824e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
