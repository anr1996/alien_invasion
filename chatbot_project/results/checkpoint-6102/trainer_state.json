{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6102,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032776138970829235,
      "grad_norm": 81.52855682373047,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 13.561,
      "step": 10
    },
    {
      "epoch": 0.006555227794165847,
      "grad_norm": 123.1466293334961,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 13.6046,
      "step": 20
    },
    {
      "epoch": 0.00983284169124877,
      "grad_norm": 71.67417907714844,
      "learning_rate": 3e-06,
      "loss": 13.4157,
      "step": 30
    },
    {
      "epoch": 0.013110455588331694,
      "grad_norm": 111.05933380126953,
      "learning_rate": 4.000000000000001e-06,
      "loss": 12.1179,
      "step": 40
    },
    {
      "epoch": 0.01638806948541462,
      "grad_norm": 81.98760223388672,
      "learning_rate": 5e-06,
      "loss": 12.7912,
      "step": 50
    },
    {
      "epoch": 0.01966568338249754,
      "grad_norm": 55.653480529785156,
      "learning_rate": 6e-06,
      "loss": 11.6546,
      "step": 60
    },
    {
      "epoch": 0.022943297279580464,
      "grad_norm": 68.79994201660156,
      "learning_rate": 7.000000000000001e-06,
      "loss": 11.1783,
      "step": 70
    },
    {
      "epoch": 0.02622091117666339,
      "grad_norm": 158.2885284423828,
      "learning_rate": 8.000000000000001e-06,
      "loss": 11.091,
      "step": 80
    },
    {
      "epoch": 0.029498525073746312,
      "grad_norm": 73.52661895751953,
      "learning_rate": 9e-06,
      "loss": 10.3002,
      "step": 90
    },
    {
      "epoch": 0.03277613897082924,
      "grad_norm": 72.48474884033203,
      "learning_rate": 1e-05,
      "loss": 7.8223,
      "step": 100
    },
    {
      "epoch": 0.03605375286791216,
      "grad_norm": 69.1353988647461,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 6.9371,
      "step": 110
    },
    {
      "epoch": 0.03933136676499508,
      "grad_norm": 65.17180633544922,
      "learning_rate": 1.2e-05,
      "loss": 7.8429,
      "step": 120
    },
    {
      "epoch": 0.04260898066207801,
      "grad_norm": 54.335506439208984,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 5.159,
      "step": 130
    },
    {
      "epoch": 0.04588659455916093,
      "grad_norm": 939.254638671875,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 4.3086,
      "step": 140
    },
    {
      "epoch": 0.049164208456243856,
      "grad_norm": 54.345314025878906,
      "learning_rate": 1.5e-05,
      "loss": 3.9955,
      "step": 150
    },
    {
      "epoch": 0.05244182235332678,
      "grad_norm": 28.840248107910156,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.8378,
      "step": 160
    },
    {
      "epoch": 0.055719436250409704,
      "grad_norm": 36.13197326660156,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 2.5663,
      "step": 170
    },
    {
      "epoch": 0.058997050147492625,
      "grad_norm": 33.642356872558594,
      "learning_rate": 1.8e-05,
      "loss": 2.8804,
      "step": 180
    },
    {
      "epoch": 0.06227466404457555,
      "grad_norm": 23.867290496826172,
      "learning_rate": 1.9e-05,
      "loss": 2.6528,
      "step": 190
    },
    {
      "epoch": 0.06555227794165848,
      "grad_norm": 186.1111602783203,
      "learning_rate": 2e-05,
      "loss": 1.6227,
      "step": 200
    },
    {
      "epoch": 0.0688298918387414,
      "grad_norm": 3.146367073059082,
      "learning_rate": 2.1e-05,
      "loss": 1.6817,
      "step": 210
    },
    {
      "epoch": 0.07210750573582432,
      "grad_norm": 5.743037223815918,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.6112,
      "step": 220
    },
    {
      "epoch": 0.07538511963290724,
      "grad_norm": 39.725101470947266,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.4395,
      "step": 230
    },
    {
      "epoch": 0.07866273352999016,
      "grad_norm": 4.2667155265808105,
      "learning_rate": 2.4e-05,
      "loss": 0.8063,
      "step": 240
    },
    {
      "epoch": 0.0819403474270731,
      "grad_norm": 13.886727333068848,
      "learning_rate": 2.5e-05,
      "loss": 0.734,
      "step": 250
    },
    {
      "epoch": 0.08521796132415602,
      "grad_norm": 0.9426736235618591,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.4074,
      "step": 260
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 3.3075063228607178,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.3431,
      "step": 270
    },
    {
      "epoch": 0.09177318911832186,
      "grad_norm": 0.8403653502464294,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.3715,
      "step": 280
    },
    {
      "epoch": 0.09505080301540479,
      "grad_norm": 0.8598021864891052,
      "learning_rate": 2.9e-05,
      "loss": 0.2204,
      "step": 290
    },
    {
      "epoch": 0.09832841691248771,
      "grad_norm": 6.54477071762085,
      "learning_rate": 3e-05,
      "loss": 0.1194,
      "step": 300
    },
    {
      "epoch": 0.10160603080957063,
      "grad_norm": 0.5754486918449402,
      "learning_rate": 3.1e-05,
      "loss": 0.1252,
      "step": 310
    },
    {
      "epoch": 0.10488364470665355,
      "grad_norm": 8.225384712219238,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.1348,
      "step": 320
    },
    {
      "epoch": 0.10816125860373647,
      "grad_norm": 0.2810431718826294,
      "learning_rate": 3.3e-05,
      "loss": 0.086,
      "step": 330
    },
    {
      "epoch": 0.11143887250081941,
      "grad_norm": 0.6607207655906677,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0717,
      "step": 340
    },
    {
      "epoch": 0.11471648639790233,
      "grad_norm": 0.8555145263671875,
      "learning_rate": 3.5e-05,
      "loss": 0.0595,
      "step": 350
    },
    {
      "epoch": 0.11799410029498525,
      "grad_norm": 1.0839085578918457,
      "learning_rate": 3.6e-05,
      "loss": 0.0689,
      "step": 360
    },
    {
      "epoch": 0.12127171419206817,
      "grad_norm": 0.3515036106109619,
      "learning_rate": 3.7e-05,
      "loss": 0.0609,
      "step": 370
    },
    {
      "epoch": 0.1245493280891511,
      "grad_norm": 2.2972843647003174,
      "learning_rate": 3.8e-05,
      "loss": 0.0723,
      "step": 380
    },
    {
      "epoch": 0.127826941986234,
      "grad_norm": 0.1784002184867859,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0555,
      "step": 390
    },
    {
      "epoch": 0.13110455588331696,
      "grad_norm": 0.20907002687454224,
      "learning_rate": 4e-05,
      "loss": 0.045,
      "step": 400
    },
    {
      "epoch": 0.13438216978039988,
      "grad_norm": 1.9385838508605957,
      "learning_rate": 4.1e-05,
      "loss": 0.0453,
      "step": 410
    },
    {
      "epoch": 0.1376597836774828,
      "grad_norm": 0.18365083634853363,
      "learning_rate": 4.2e-05,
      "loss": 0.0436,
      "step": 420
    },
    {
      "epoch": 0.14093739757456572,
      "grad_norm": 0.5624284148216248,
      "learning_rate": 4.3e-05,
      "loss": 0.0399,
      "step": 430
    },
    {
      "epoch": 0.14421501147164864,
      "grad_norm": 0.16593874990940094,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0347,
      "step": 440
    },
    {
      "epoch": 0.14749262536873156,
      "grad_norm": 0.24072347581386566,
      "learning_rate": 4.5e-05,
      "loss": 0.0361,
      "step": 450
    },
    {
      "epoch": 0.15077023926581448,
      "grad_norm": 0.1839401125907898,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.031,
      "step": 460
    },
    {
      "epoch": 0.1540478531628974,
      "grad_norm": 0.1428147852420807,
      "learning_rate": 4.7e-05,
      "loss": 0.0296,
      "step": 470
    },
    {
      "epoch": 0.15732546705998032,
      "grad_norm": 0.12946875393390656,
      "learning_rate": 4.8e-05,
      "loss": 0.0299,
      "step": 480
    },
    {
      "epoch": 0.16060308095706327,
      "grad_norm": 0.25445473194122314,
      "learning_rate": 4.9e-05,
      "loss": 0.027,
      "step": 490
    },
    {
      "epoch": 0.1638806948541462,
      "grad_norm": 0.277042031288147,
      "learning_rate": 5e-05,
      "loss": 0.0265,
      "step": 500
    },
    {
      "epoch": 0.1671583087512291,
      "grad_norm": 0.21949568390846252,
      "learning_rate": 4.991074616208497e-05,
      "loss": 0.0225,
      "step": 510
    },
    {
      "epoch": 0.17043592264831203,
      "grad_norm": 0.5405534505844116,
      "learning_rate": 4.9821492324169946e-05,
      "loss": 0.0202,
      "step": 520
    },
    {
      "epoch": 0.17371353654539495,
      "grad_norm": 0.32507985830307007,
      "learning_rate": 4.973223848625491e-05,
      "loss": 0.0191,
      "step": 530
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 0.21352331340312958,
      "learning_rate": 4.964298464833988e-05,
      "loss": 0.0152,
      "step": 540
    },
    {
      "epoch": 0.1802687643395608,
      "grad_norm": 0.0708722472190857,
      "learning_rate": 4.9553730810424856e-05,
      "loss": 0.0143,
      "step": 550
    },
    {
      "epoch": 0.18354637823664371,
      "grad_norm": 0.0973355621099472,
      "learning_rate": 4.946447697250982e-05,
      "loss": 0.0121,
      "step": 560
    },
    {
      "epoch": 0.18682399213372664,
      "grad_norm": 0.13207238912582397,
      "learning_rate": 4.9375223134594786e-05,
      "loss": 0.0159,
      "step": 570
    },
    {
      "epoch": 0.19010160603080958,
      "grad_norm": 0.07778406888246536,
      "learning_rate": 4.928596929667976e-05,
      "loss": 0.0114,
      "step": 580
    },
    {
      "epoch": 0.1933792199278925,
      "grad_norm": 0.12481919676065445,
      "learning_rate": 4.919671545876473e-05,
      "loss": 0.0113,
      "step": 590
    },
    {
      "epoch": 0.19665683382497542,
      "grad_norm": 0.2729295492172241,
      "learning_rate": 4.9107461620849696e-05,
      "loss": 0.011,
      "step": 600
    },
    {
      "epoch": 0.19993444772205834,
      "grad_norm": 0.07235042750835419,
      "learning_rate": 4.901820778293467e-05,
      "loss": 0.0089,
      "step": 610
    },
    {
      "epoch": 0.20321206161914127,
      "grad_norm": 0.4194739758968353,
      "learning_rate": 4.892895394501964e-05,
      "loss": 0.007,
      "step": 620
    },
    {
      "epoch": 0.20648967551622419,
      "grad_norm": 0.15294738113880157,
      "learning_rate": 4.8839700107104605e-05,
      "loss": 0.0065,
      "step": 630
    },
    {
      "epoch": 0.2097672894133071,
      "grad_norm": 0.40930095314979553,
      "learning_rate": 4.875044626918958e-05,
      "loss": 0.0082,
      "step": 640
    },
    {
      "epoch": 0.21304490331039003,
      "grad_norm": 0.1641254425048828,
      "learning_rate": 4.866119243127455e-05,
      "loss": 0.0049,
      "step": 650
    },
    {
      "epoch": 0.21632251720747295,
      "grad_norm": 0.3582115173339844,
      "learning_rate": 4.8571938593359514e-05,
      "loss": 0.0083,
      "step": 660
    },
    {
      "epoch": 0.2196001311045559,
      "grad_norm": 0.1275981217622757,
      "learning_rate": 4.8482684755444486e-05,
      "loss": 0.0068,
      "step": 670
    },
    {
      "epoch": 0.22287774500163882,
      "grad_norm": 0.07080506533384323,
      "learning_rate": 4.839343091752946e-05,
      "loss": 0.0086,
      "step": 680
    },
    {
      "epoch": 0.22615535889872174,
      "grad_norm": 0.16398514807224274,
      "learning_rate": 4.8304177079614424e-05,
      "loss": 0.0052,
      "step": 690
    },
    {
      "epoch": 0.22943297279580466,
      "grad_norm": 0.295640766620636,
      "learning_rate": 4.8214923241699396e-05,
      "loss": 0.0052,
      "step": 700
    },
    {
      "epoch": 0.23271058669288758,
      "grad_norm": 0.009320130571722984,
      "learning_rate": 4.812566940378436e-05,
      "loss": 0.0027,
      "step": 710
    },
    {
      "epoch": 0.2359882005899705,
      "grad_norm": 0.01604711264371872,
      "learning_rate": 4.803641556586933e-05,
      "loss": 0.0042,
      "step": 720
    },
    {
      "epoch": 0.23926581448705342,
      "grad_norm": 0.22504392266273499,
      "learning_rate": 4.7947161727954305e-05,
      "loss": 0.0052,
      "step": 730
    },
    {
      "epoch": 0.24254342838413634,
      "grad_norm": 0.19651436805725098,
      "learning_rate": 4.785790789003927e-05,
      "loss": 0.0064,
      "step": 740
    },
    {
      "epoch": 0.24582104228121926,
      "grad_norm": 0.20591160655021667,
      "learning_rate": 4.776865405212424e-05,
      "loss": 0.0039,
      "step": 750
    },
    {
      "epoch": 0.2490986561783022,
      "grad_norm": 15.003389358520508,
      "learning_rate": 4.7679400214209214e-05,
      "loss": 0.004,
      "step": 760
    },
    {
      "epoch": 0.2523762700753851,
      "grad_norm": 0.05498078837990761,
      "learning_rate": 4.759014637629418e-05,
      "loss": 0.0058,
      "step": 770
    },
    {
      "epoch": 0.255653883972468,
      "grad_norm": 0.0056060561910271645,
      "learning_rate": 4.750089253837915e-05,
      "loss": 0.0061,
      "step": 780
    },
    {
      "epoch": 0.25893149786955094,
      "grad_norm": 0.2727658748626709,
      "learning_rate": 4.7411638700464124e-05,
      "loss": 0.0051,
      "step": 790
    },
    {
      "epoch": 0.2622091117666339,
      "grad_norm": 0.12125666439533234,
      "learning_rate": 4.732238486254909e-05,
      "loss": 0.0028,
      "step": 800
    },
    {
      "epoch": 0.26548672566371684,
      "grad_norm": 0.1107458546757698,
      "learning_rate": 4.723313102463406e-05,
      "loss": 0.0036,
      "step": 810
    },
    {
      "epoch": 0.26876433956079976,
      "grad_norm": 0.041389402002096176,
      "learning_rate": 4.714387718671903e-05,
      "loss": 0.0034,
      "step": 820
    },
    {
      "epoch": 0.2720419534578827,
      "grad_norm": 0.007003230508416891,
      "learning_rate": 4.7054623348804e-05,
      "loss": 0.0022,
      "step": 830
    },
    {
      "epoch": 0.2753195673549656,
      "grad_norm": 0.008552401326596737,
      "learning_rate": 4.696536951088897e-05,
      "loss": 0.0041,
      "step": 840
    },
    {
      "epoch": 0.2785971812520485,
      "grad_norm": 0.1507079005241394,
      "learning_rate": 4.687611567297394e-05,
      "loss": 0.0038,
      "step": 850
    },
    {
      "epoch": 0.28187479514913144,
      "grad_norm": 0.013981346040964127,
      "learning_rate": 4.678686183505891e-05,
      "loss": 0.0015,
      "step": 860
    },
    {
      "epoch": 0.28515240904621436,
      "grad_norm": 0.17366604506969452,
      "learning_rate": 4.669760799714388e-05,
      "loss": 0.003,
      "step": 870
    },
    {
      "epoch": 0.2884300229432973,
      "grad_norm": 0.083049476146698,
      "learning_rate": 4.660835415922885e-05,
      "loss": 0.0013,
      "step": 880
    },
    {
      "epoch": 0.2917076368403802,
      "grad_norm": 0.005685991607606411,
      "learning_rate": 4.651910032131382e-05,
      "loss": 0.0027,
      "step": 890
    },
    {
      "epoch": 0.2949852507374631,
      "grad_norm": 0.06970315426588058,
      "learning_rate": 4.642984648339879e-05,
      "loss": 0.0023,
      "step": 900
    },
    {
      "epoch": 0.29826286463454604,
      "grad_norm": 0.20937789976596832,
      "learning_rate": 4.634059264548376e-05,
      "loss": 0.0027,
      "step": 910
    },
    {
      "epoch": 0.30154047853162896,
      "grad_norm": 0.1124529093503952,
      "learning_rate": 4.6251338807568726e-05,
      "loss": 0.0023,
      "step": 920
    },
    {
      "epoch": 0.3048180924287119,
      "grad_norm": 0.07775048911571503,
      "learning_rate": 4.61620849696537e-05,
      "loss": 0.0017,
      "step": 930
    },
    {
      "epoch": 0.3080957063257948,
      "grad_norm": 0.2142573893070221,
      "learning_rate": 4.607283113173867e-05,
      "loss": 0.0032,
      "step": 940
    },
    {
      "epoch": 0.3113733202228777,
      "grad_norm": 0.23700517416000366,
      "learning_rate": 4.5983577293823636e-05,
      "loss": 0.0022,
      "step": 950
    },
    {
      "epoch": 0.31465093411996065,
      "grad_norm": 0.12824583053588867,
      "learning_rate": 4.589432345590861e-05,
      "loss": 0.0017,
      "step": 960
    },
    {
      "epoch": 0.31792854801704357,
      "grad_norm": 0.00464973459020257,
      "learning_rate": 4.580506961799357e-05,
      "loss": 0.0029,
      "step": 970
    },
    {
      "epoch": 0.32120616191412654,
      "grad_norm": 0.02818932570517063,
      "learning_rate": 4.5715815780078545e-05,
      "loss": 0.003,
      "step": 980
    },
    {
      "epoch": 0.32448377581120946,
      "grad_norm": 0.05079466849565506,
      "learning_rate": 4.562656194216352e-05,
      "loss": 0.0016,
      "step": 990
    },
    {
      "epoch": 0.3277613897082924,
      "grad_norm": 0.12464684247970581,
      "learning_rate": 4.553730810424848e-05,
      "loss": 0.0021,
      "step": 1000
    },
    {
      "epoch": 0.3310390036053753,
      "grad_norm": 0.04873824492096901,
      "learning_rate": 4.5448054266333454e-05,
      "loss": 0.0013,
      "step": 1010
    },
    {
      "epoch": 0.3343166175024582,
      "grad_norm": 0.004412754438817501,
      "learning_rate": 4.5358800428418426e-05,
      "loss": 0.0026,
      "step": 1020
    },
    {
      "epoch": 0.33759423139954114,
      "grad_norm": 0.0018278597854077816,
      "learning_rate": 4.526954659050339e-05,
      "loss": 0.0016,
      "step": 1030
    },
    {
      "epoch": 0.34087184529662407,
      "grad_norm": 0.09465900808572769,
      "learning_rate": 4.5180292752588364e-05,
      "loss": 0.0014,
      "step": 1040
    },
    {
      "epoch": 0.344149459193707,
      "grad_norm": 0.047296278178691864,
      "learning_rate": 4.5091038914673336e-05,
      "loss": 0.0009,
      "step": 1050
    },
    {
      "epoch": 0.3474270730907899,
      "grad_norm": 0.019063329324126244,
      "learning_rate": 4.50017850767583e-05,
      "loss": 0.0023,
      "step": 1060
    },
    {
      "epoch": 0.3507046869878728,
      "grad_norm": 0.001920834882184863,
      "learning_rate": 4.491253123884327e-05,
      "loss": 0.0011,
      "step": 1070
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 0.05184418708086014,
      "learning_rate": 4.4823277400928245e-05,
      "loss": 0.0024,
      "step": 1080
    },
    {
      "epoch": 0.35725991478203867,
      "grad_norm": 0.0038239536806941032,
      "learning_rate": 4.473402356301321e-05,
      "loss": 0.003,
      "step": 1090
    },
    {
      "epoch": 0.3605375286791216,
      "grad_norm": 0.07833243906497955,
      "learning_rate": 4.464476972509818e-05,
      "loss": 0.001,
      "step": 1100
    },
    {
      "epoch": 0.3638151425762045,
      "grad_norm": 0.0025061173364520073,
      "learning_rate": 4.4555515887183154e-05,
      "loss": 0.0013,
      "step": 1110
    },
    {
      "epoch": 0.36709275647328743,
      "grad_norm": 0.04084055498242378,
      "learning_rate": 4.446626204926812e-05,
      "loss": 0.0023,
      "step": 1120
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.05919264256954193,
      "learning_rate": 4.437700821135309e-05,
      "loss": 0.0023,
      "step": 1130
    },
    {
      "epoch": 0.37364798426745327,
      "grad_norm": 0.004727164749056101,
      "learning_rate": 4.4287754373438064e-05,
      "loss": 0.0009,
      "step": 1140
    },
    {
      "epoch": 0.3769255981645362,
      "grad_norm": 0.0033543105237185955,
      "learning_rate": 4.419850053552303e-05,
      "loss": 0.002,
      "step": 1150
    },
    {
      "epoch": 0.38020321206161917,
      "grad_norm": 0.02688409574329853,
      "learning_rate": 4.4109246697608e-05,
      "loss": 0.0012,
      "step": 1160
    },
    {
      "epoch": 0.3834808259587021,
      "grad_norm": 0.014855084009468555,
      "learning_rate": 4.401999285969297e-05,
      "loss": 0.0031,
      "step": 1170
    },
    {
      "epoch": 0.386758439855785,
      "grad_norm": 0.1115117073059082,
      "learning_rate": 4.393073902177794e-05,
      "loss": 0.0019,
      "step": 1180
    },
    {
      "epoch": 0.39003605375286793,
      "grad_norm": 0.0014067854499444366,
      "learning_rate": 4.384148518386291e-05,
      "loss": 0.001,
      "step": 1190
    },
    {
      "epoch": 0.39331366764995085,
      "grad_norm": 0.003245183965191245,
      "learning_rate": 4.375223134594788e-05,
      "loss": 0.0015,
      "step": 1200
    },
    {
      "epoch": 0.39659128154703377,
      "grad_norm": 0.026514440774917603,
      "learning_rate": 4.366297750803285e-05,
      "loss": 0.0022,
      "step": 1210
    },
    {
      "epoch": 0.3998688954441167,
      "grad_norm": 0.025822263211011887,
      "learning_rate": 4.357372367011782e-05,
      "loss": 0.0029,
      "step": 1220
    },
    {
      "epoch": 0.4031465093411996,
      "grad_norm": 0.002280130749568343,
      "learning_rate": 4.3484469832202785e-05,
      "loss": 0.0015,
      "step": 1230
    },
    {
      "epoch": 0.40642412323828253,
      "grad_norm": 0.015226693823933601,
      "learning_rate": 4.339521599428776e-05,
      "loss": 0.0016,
      "step": 1240
    },
    {
      "epoch": 0.40970173713536545,
      "grad_norm": 0.04561562463641167,
      "learning_rate": 4.330596215637273e-05,
      "loss": 0.0012,
      "step": 1250
    },
    {
      "epoch": 0.41297935103244837,
      "grad_norm": 0.08753059804439545,
      "learning_rate": 4.3216708318457694e-05,
      "loss": 0.0009,
      "step": 1260
    },
    {
      "epoch": 0.4162569649295313,
      "grad_norm": 0.03896458446979523,
      "learning_rate": 4.3127454480542666e-05,
      "loss": 0.001,
      "step": 1270
    },
    {
      "epoch": 0.4195345788266142,
      "grad_norm": 0.0013169976882636547,
      "learning_rate": 4.303820064262764e-05,
      "loss": 0.0022,
      "step": 1280
    },
    {
      "epoch": 0.42281219272369713,
      "grad_norm": 0.2254636585712433,
      "learning_rate": 4.2948946804712603e-05,
      "loss": 0.0014,
      "step": 1290
    },
    {
      "epoch": 0.42608980662078005,
      "grad_norm": 0.001579787814989686,
      "learning_rate": 4.2859692966797575e-05,
      "loss": 0.001,
      "step": 1300
    },
    {
      "epoch": 0.429367420517863,
      "grad_norm": 0.033066850155591965,
      "learning_rate": 4.277043912888255e-05,
      "loss": 0.0018,
      "step": 1310
    },
    {
      "epoch": 0.4326450344149459,
      "grad_norm": 0.0696709081530571,
      "learning_rate": 4.268118529096751e-05,
      "loss": 0.0013,
      "step": 1320
    },
    {
      "epoch": 0.4359226483120288,
      "grad_norm": 0.25148582458496094,
      "learning_rate": 4.2591931453052485e-05,
      "loss": 0.0014,
      "step": 1330
    },
    {
      "epoch": 0.4392002622091118,
      "grad_norm": 0.021155858412384987,
      "learning_rate": 4.250267761513746e-05,
      "loss": 0.0006,
      "step": 1340
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 0.001137710059992969,
      "learning_rate": 4.241342377722242e-05,
      "loss": 0.0012,
      "step": 1350
    },
    {
      "epoch": 0.44575549000327763,
      "grad_norm": 0.038123536854982376,
      "learning_rate": 4.232416993930739e-05,
      "loss": 0.0014,
      "step": 1360
    },
    {
      "epoch": 0.44903310390036055,
      "grad_norm": 0.04324469342827797,
      "learning_rate": 4.2234916101392366e-05,
      "loss": 0.0012,
      "step": 1370
    },
    {
      "epoch": 0.4523107177974435,
      "grad_norm": 0.01762046292424202,
      "learning_rate": 4.214566226347733e-05,
      "loss": 0.0012,
      "step": 1380
    },
    {
      "epoch": 0.4555883316945264,
      "grad_norm": 0.09304724633693695,
      "learning_rate": 4.20564084255623e-05,
      "loss": 0.0017,
      "step": 1390
    },
    {
      "epoch": 0.4588659455916093,
      "grad_norm": 0.0024271500296890736,
      "learning_rate": 4.1967154587647275e-05,
      "loss": 0.0008,
      "step": 1400
    },
    {
      "epoch": 0.46214355948869223,
      "grad_norm": 0.12252651900053024,
      "learning_rate": 4.187790074973224e-05,
      "loss": 0.0007,
      "step": 1410
    },
    {
      "epoch": 0.46542117338577516,
      "grad_norm": 0.001097221509553492,
      "learning_rate": 4.1788646911817206e-05,
      "loss": 0.0011,
      "step": 1420
    },
    {
      "epoch": 0.4686987872828581,
      "grad_norm": 0.037632055580616,
      "learning_rate": 4.1699393073902185e-05,
      "loss": 0.0013,
      "step": 1430
    },
    {
      "epoch": 0.471976401179941,
      "grad_norm": 0.012933673337101936,
      "learning_rate": 4.161013923598715e-05,
      "loss": 0.0012,
      "step": 1440
    },
    {
      "epoch": 0.4752540150770239,
      "grad_norm": 0.0007563857361674309,
      "learning_rate": 4.1520885398072115e-05,
      "loss": 0.0014,
      "step": 1450
    },
    {
      "epoch": 0.47853162897410684,
      "grad_norm": 0.001619859365746379,
      "learning_rate": 4.1431631560157094e-05,
      "loss": 0.0008,
      "step": 1460
    },
    {
      "epoch": 0.48180924287118976,
      "grad_norm": 0.12069997936487198,
      "learning_rate": 4.134237772224206e-05,
      "loss": 0.0009,
      "step": 1470
    },
    {
      "epoch": 0.4850868567682727,
      "grad_norm": 0.00483898539096117,
      "learning_rate": 4.1253123884327025e-05,
      "loss": 0.0014,
      "step": 1480
    },
    {
      "epoch": 0.4883644706653556,
      "grad_norm": 0.03244451805949211,
      "learning_rate": 4.1163870046412e-05,
      "loss": 0.0011,
      "step": 1490
    },
    {
      "epoch": 0.4916420845624385,
      "grad_norm": 0.10896145552396774,
      "learning_rate": 4.107461620849697e-05,
      "loss": 0.0015,
      "step": 1500
    },
    {
      "epoch": 0.4949196984595215,
      "grad_norm": 0.005038543604314327,
      "learning_rate": 4.0985362370581934e-05,
      "loss": 0.0007,
      "step": 1510
    },
    {
      "epoch": 0.4981973123566044,
      "grad_norm": 0.0013649985194206238,
      "learning_rate": 4.0896108532666906e-05,
      "loss": 0.0011,
      "step": 1520
    },
    {
      "epoch": 0.5014749262536873,
      "grad_norm": 0.04145023599267006,
      "learning_rate": 4.080685469475188e-05,
      "loss": 0.0013,
      "step": 1530
    },
    {
      "epoch": 0.5047525401507702,
      "grad_norm": 0.007115598767995834,
      "learning_rate": 4.071760085683684e-05,
      "loss": 0.001,
      "step": 1540
    },
    {
      "epoch": 0.5080301540478531,
      "grad_norm": 0.002393439644947648,
      "learning_rate": 4.0628347018921815e-05,
      "loss": 0.0005,
      "step": 1550
    },
    {
      "epoch": 0.511307767944936,
      "grad_norm": 0.1754211187362671,
      "learning_rate": 4.053909318100679e-05,
      "loss": 0.0008,
      "step": 1560
    },
    {
      "epoch": 0.514585381842019,
      "grad_norm": 0.05826142430305481,
      "learning_rate": 4.044983934309175e-05,
      "loss": 0.001,
      "step": 1570
    },
    {
      "epoch": 0.5178629957391019,
      "grad_norm": 0.043509989976882935,
      "learning_rate": 4.0360585505176725e-05,
      "loss": 0.0009,
      "step": 1580
    },
    {
      "epoch": 0.5211406096361848,
      "grad_norm": 0.0006880889995954931,
      "learning_rate": 4.02713316672617e-05,
      "loss": 0.0007,
      "step": 1590
    },
    {
      "epoch": 0.5244182235332678,
      "grad_norm": 0.0026587063912302256,
      "learning_rate": 4.018207782934666e-05,
      "loss": 0.0007,
      "step": 1600
    },
    {
      "epoch": 0.5276958374303508,
      "grad_norm": 0.05785999447107315,
      "learning_rate": 4.0092823991431634e-05,
      "loss": 0.0007,
      "step": 1610
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 0.0024754751939326525,
      "learning_rate": 4.00035701535166e-05,
      "loss": 0.0006,
      "step": 1620
    },
    {
      "epoch": 0.5342510652245166,
      "grad_norm": 0.0018847135361284018,
      "learning_rate": 3.991431631560157e-05,
      "loss": 0.0005,
      "step": 1630
    },
    {
      "epoch": 0.5375286791215995,
      "grad_norm": 0.0011907716980203986,
      "learning_rate": 3.982506247768654e-05,
      "loss": 0.0008,
      "step": 1640
    },
    {
      "epoch": 0.5408062930186824,
      "grad_norm": 0.0006875699618831277,
      "learning_rate": 3.973580863977151e-05,
      "loss": 0.0007,
      "step": 1650
    },
    {
      "epoch": 0.5440839069157654,
      "grad_norm": 0.008818749338388443,
      "learning_rate": 3.964655480185648e-05,
      "loss": 0.0007,
      "step": 1660
    },
    {
      "epoch": 0.5473615208128483,
      "grad_norm": 0.02572530508041382,
      "learning_rate": 3.955730096394145e-05,
      "loss": 0.0009,
      "step": 1670
    },
    {
      "epoch": 0.5506391347099312,
      "grad_norm": 0.024997137486934662,
      "learning_rate": 3.946804712602642e-05,
      "loss": 0.002,
      "step": 1680
    },
    {
      "epoch": 0.5539167486070141,
      "grad_norm": 0.06022762879729271,
      "learning_rate": 3.937879328811139e-05,
      "loss": 0.0011,
      "step": 1690
    },
    {
      "epoch": 0.557194362504097,
      "grad_norm": 0.023609906435012817,
      "learning_rate": 3.928953945019636e-05,
      "loss": 0.0005,
      "step": 1700
    },
    {
      "epoch": 0.56047197640118,
      "grad_norm": 0.027414094656705856,
      "learning_rate": 3.920028561228133e-05,
      "loss": 0.0008,
      "step": 1710
    },
    {
      "epoch": 0.5637495902982629,
      "grad_norm": 0.0726107582449913,
      "learning_rate": 3.91110317743663e-05,
      "loss": 0.0018,
      "step": 1720
    },
    {
      "epoch": 0.5670272041953458,
      "grad_norm": 0.0004785307392012328,
      "learning_rate": 3.902177793645127e-05,
      "loss": 0.0004,
      "step": 1730
    },
    {
      "epoch": 0.5703048180924287,
      "grad_norm": 0.0015005138702690601,
      "learning_rate": 3.8932524098536237e-05,
      "loss": 0.0003,
      "step": 1740
    },
    {
      "epoch": 0.5735824319895116,
      "grad_norm": 0.0012517723953351378,
      "learning_rate": 3.884327026062121e-05,
      "loss": 0.0006,
      "step": 1750
    },
    {
      "epoch": 0.5768600458865946,
      "grad_norm": 0.0008772817673161626,
      "learning_rate": 3.875401642270618e-05,
      "loss": 0.0005,
      "step": 1760
    },
    {
      "epoch": 0.5801376597836775,
      "grad_norm": 0.000926835578866303,
      "learning_rate": 3.8664762584791146e-05,
      "loss": 0.0005,
      "step": 1770
    },
    {
      "epoch": 0.5834152736807604,
      "grad_norm": 0.004729525186121464,
      "learning_rate": 3.857550874687612e-05,
      "loss": 0.0003,
      "step": 1780
    },
    {
      "epoch": 0.5866928875778433,
      "grad_norm": 0.000915934331715107,
      "learning_rate": 3.848625490896109e-05,
      "loss": 0.0011,
      "step": 1790
    },
    {
      "epoch": 0.5899705014749262,
      "grad_norm": 0.0005337231559678912,
      "learning_rate": 3.8397001071046055e-05,
      "loss": 0.001,
      "step": 1800
    },
    {
      "epoch": 0.5932481153720092,
      "grad_norm": 0.20170092582702637,
      "learning_rate": 3.830774723313103e-05,
      "loss": 0.001,
      "step": 1810
    },
    {
      "epoch": 0.5965257292690921,
      "grad_norm": 0.06543578952550888,
      "learning_rate": 3.8218493395216e-05,
      "loss": 0.0014,
      "step": 1820
    },
    {
      "epoch": 0.599803343166175,
      "grad_norm": 0.0005879480740986764,
      "learning_rate": 3.8129239557300965e-05,
      "loss": 0.0009,
      "step": 1830
    },
    {
      "epoch": 0.6030809570632579,
      "grad_norm": 0.008834779262542725,
      "learning_rate": 3.8039985719385937e-05,
      "loss": 0.0005,
      "step": 1840
    },
    {
      "epoch": 0.6063585709603408,
      "grad_norm": 0.029518648982048035,
      "learning_rate": 3.79507318814709e-05,
      "loss": 0.0014,
      "step": 1850
    },
    {
      "epoch": 0.6096361848574238,
      "grad_norm": 0.019454479217529297,
      "learning_rate": 3.7861478043555874e-05,
      "loss": 0.0009,
      "step": 1860
    },
    {
      "epoch": 0.6129137987545067,
      "grad_norm": 0.0066071730107069016,
      "learning_rate": 3.7772224205640846e-05,
      "loss": 0.0004,
      "step": 1870
    },
    {
      "epoch": 0.6161914126515896,
      "grad_norm": 0.09196782112121582,
      "learning_rate": 3.768297036772581e-05,
      "loss": 0.0009,
      "step": 1880
    },
    {
      "epoch": 0.6194690265486725,
      "grad_norm": 0.00393595639616251,
      "learning_rate": 3.759371652981078e-05,
      "loss": 0.0003,
      "step": 1890
    },
    {
      "epoch": 0.6227466404457555,
      "grad_norm": 0.0002917716628871858,
      "learning_rate": 3.7504462691895755e-05,
      "loss": 0.0003,
      "step": 1900
    },
    {
      "epoch": 0.6260242543428384,
      "grad_norm": 0.0009684821125119925,
      "learning_rate": 3.741520885398072e-05,
      "loss": 0.0005,
      "step": 1910
    },
    {
      "epoch": 0.6293018682399213,
      "grad_norm": 0.025693261995911598,
      "learning_rate": 3.732595501606569e-05,
      "loss": 0.0006,
      "step": 1920
    },
    {
      "epoch": 0.6325794821370042,
      "grad_norm": 0.03133809193968773,
      "learning_rate": 3.7236701178150665e-05,
      "loss": 0.0003,
      "step": 1930
    },
    {
      "epoch": 0.6358570960340871,
      "grad_norm": 0.00052161596249789,
      "learning_rate": 3.714744734023563e-05,
      "loss": 0.0002,
      "step": 1940
    },
    {
      "epoch": 0.63913470993117,
      "grad_norm": 0.012813436798751354,
      "learning_rate": 3.70581935023206e-05,
      "loss": 0.0004,
      "step": 1950
    },
    {
      "epoch": 0.6424123238282531,
      "grad_norm": 0.0002167417260352522,
      "learning_rate": 3.6968939664405574e-05,
      "loss": 0.0009,
      "step": 1960
    },
    {
      "epoch": 0.645689937725336,
      "grad_norm": 0.004051949828863144,
      "learning_rate": 3.687968582649054e-05,
      "loss": 0.0012,
      "step": 1970
    },
    {
      "epoch": 0.6489675516224189,
      "grad_norm": 0.0016144374385476112,
      "learning_rate": 3.6790431988575504e-05,
      "loss": 0.0009,
      "step": 1980
    },
    {
      "epoch": 0.6522451655195018,
      "grad_norm": 0.01459396630525589,
      "learning_rate": 3.670117815066048e-05,
      "loss": 0.0004,
      "step": 1990
    },
    {
      "epoch": 0.6555227794165848,
      "grad_norm": 0.09672824293375015,
      "learning_rate": 3.661192431274545e-05,
      "loss": 0.0008,
      "step": 2000
    },
    {
      "epoch": 0.6588003933136677,
      "grad_norm": 0.03792881965637207,
      "learning_rate": 3.652267047483042e-05,
      "loss": 0.0011,
      "step": 2010
    },
    {
      "epoch": 0.6620780072107506,
      "grad_norm": 0.0011289194226264954,
      "learning_rate": 3.643341663691539e-05,
      "loss": 0.0006,
      "step": 2020
    },
    {
      "epoch": 0.6653556211078335,
      "grad_norm": 0.08431334793567657,
      "learning_rate": 3.634416279900036e-05,
      "loss": 0.0002,
      "step": 2030
    },
    {
      "epoch": 0.6686332350049164,
      "grad_norm": 0.45686134696006775,
      "learning_rate": 3.625490896108533e-05,
      "loss": 0.0009,
      "step": 2040
    },
    {
      "epoch": 0.6719108489019994,
      "grad_norm": 0.0017042806139215827,
      "learning_rate": 3.61656551231703e-05,
      "loss": 0.0006,
      "step": 2050
    },
    {
      "epoch": 0.6751884627990823,
      "grad_norm": 0.00031492271227762103,
      "learning_rate": 3.607640128525527e-05,
      "loss": 0.0002,
      "step": 2060
    },
    {
      "epoch": 0.6784660766961652,
      "grad_norm": 0.002387432847172022,
      "learning_rate": 3.598714744734024e-05,
      "loss": 0.0003,
      "step": 2070
    },
    {
      "epoch": 0.6817436905932481,
      "grad_norm": 0.14859817922115326,
      "learning_rate": 3.589789360942521e-05,
      "loss": 0.0009,
      "step": 2080
    },
    {
      "epoch": 0.685021304490331,
      "grad_norm": 0.0003020054427906871,
      "learning_rate": 3.5808639771510176e-05,
      "loss": 0.0005,
      "step": 2090
    },
    {
      "epoch": 0.688298918387414,
      "grad_norm": 0.01775096170604229,
      "learning_rate": 3.571938593359515e-05,
      "loss": 0.0002,
      "step": 2100
    },
    {
      "epoch": 0.6915765322844969,
      "grad_norm": 0.0002973761293105781,
      "learning_rate": 3.5630132095680114e-05,
      "loss": 0.0003,
      "step": 2110
    },
    {
      "epoch": 0.6948541461815798,
      "grad_norm": 0.0026514821220189333,
      "learning_rate": 3.5540878257765086e-05,
      "loss": 0.0005,
      "step": 2120
    },
    {
      "epoch": 0.6981317600786627,
      "grad_norm": 0.00022006385552231222,
      "learning_rate": 3.545162441985006e-05,
      "loss": 0.0002,
      "step": 2130
    },
    {
      "epoch": 0.7014093739757457,
      "grad_norm": 0.004658695310354233,
      "learning_rate": 3.536237058193502e-05,
      "loss": 0.0009,
      "step": 2140
    },
    {
      "epoch": 0.7046869878728286,
      "grad_norm": 0.034726791083812714,
      "learning_rate": 3.5273116744019995e-05,
      "loss": 0.0006,
      "step": 2150
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 0.007854659110307693,
      "learning_rate": 3.518386290610497e-05,
      "loss": 0.0006,
      "step": 2160
    },
    {
      "epoch": 0.7112422156669944,
      "grad_norm": 0.5271909236907959,
      "learning_rate": 3.509460906818993e-05,
      "loss": 0.0013,
      "step": 2170
    },
    {
      "epoch": 0.7145198295640773,
      "grad_norm": 0.00038451768341474235,
      "learning_rate": 3.5005355230274904e-05,
      "loss": 0.0003,
      "step": 2180
    },
    {
      "epoch": 0.7177974434611603,
      "grad_norm": 0.09853971749544144,
      "learning_rate": 3.4916101392359876e-05,
      "loss": 0.0005,
      "step": 2190
    },
    {
      "epoch": 0.7210750573582432,
      "grad_norm": 0.07389166951179504,
      "learning_rate": 3.482684755444484e-05,
      "loss": 0.0005,
      "step": 2200
    },
    {
      "epoch": 0.7243526712553261,
      "grad_norm": 0.011348595842719078,
      "learning_rate": 3.4737593716529814e-05,
      "loss": 0.0001,
      "step": 2210
    },
    {
      "epoch": 0.727630285152409,
      "grad_norm": 0.04735153913497925,
      "learning_rate": 3.4648339878614786e-05,
      "loss": 0.0006,
      "step": 2220
    },
    {
      "epoch": 0.7309078990494919,
      "grad_norm": 0.001559373107738793,
      "learning_rate": 3.455908604069975e-05,
      "loss": 0.0009,
      "step": 2230
    },
    {
      "epoch": 0.7341855129465749,
      "grad_norm": 0.0012589787365868688,
      "learning_rate": 3.4469832202784716e-05,
      "loss": 0.0002,
      "step": 2240
    },
    {
      "epoch": 0.7374631268436578,
      "grad_norm": 0.08245319873094559,
      "learning_rate": 3.4380578364869695e-05,
      "loss": 0.0003,
      "step": 2250
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.01979033462703228,
      "learning_rate": 3.429132452695466e-05,
      "loss": 0.0011,
      "step": 2260
    },
    {
      "epoch": 0.7440183546378236,
      "grad_norm": 0.0005653550615534186,
      "learning_rate": 3.4202070689039626e-05,
      "loss": 0.0006,
      "step": 2270
    },
    {
      "epoch": 0.7472959685349065,
      "grad_norm": 0.0008551689679734409,
      "learning_rate": 3.4112816851124604e-05,
      "loss": 0.0002,
      "step": 2280
    },
    {
      "epoch": 0.7505735824319895,
      "grad_norm": 0.00013960528303869069,
      "learning_rate": 3.402356301320957e-05,
      "loss": 0.001,
      "step": 2290
    },
    {
      "epoch": 0.7538511963290724,
      "grad_norm": 0.09163299202919006,
      "learning_rate": 3.3934309175294535e-05,
      "loss": 0.0006,
      "step": 2300
    },
    {
      "epoch": 0.7571288102261554,
      "grad_norm": 0.0008383505628444254,
      "learning_rate": 3.3845055337379514e-05,
      "loss": 0.0003,
      "step": 2310
    },
    {
      "epoch": 0.7604064241232383,
      "grad_norm": 0.0005463375709950924,
      "learning_rate": 3.375580149946448e-05,
      "loss": 0.0001,
      "step": 2320
    },
    {
      "epoch": 0.7636840380203213,
      "grad_norm": 0.00027224322548136115,
      "learning_rate": 3.3666547661549444e-05,
      "loss": 0.0007,
      "step": 2330
    },
    {
      "epoch": 0.7669616519174042,
      "grad_norm": 0.005404433701187372,
      "learning_rate": 3.357729382363442e-05,
      "loss": 0.0007,
      "step": 2340
    },
    {
      "epoch": 0.7702392658144871,
      "grad_norm": 0.0051411110907793045,
      "learning_rate": 3.348803998571939e-05,
      "loss": 0.0005,
      "step": 2350
    },
    {
      "epoch": 0.77351687971157,
      "grad_norm": 0.0002768657577689737,
      "learning_rate": 3.3398786147804354e-05,
      "loss": 0.0008,
      "step": 2360
    },
    {
      "epoch": 0.7767944936086529,
      "grad_norm": 0.07372277975082397,
      "learning_rate": 3.3309532309889326e-05,
      "loss": 0.0005,
      "step": 2370
    },
    {
      "epoch": 0.7800721075057359,
      "grad_norm": 0.00041698713903315365,
      "learning_rate": 3.32202784719743e-05,
      "loss": 0.0002,
      "step": 2380
    },
    {
      "epoch": 0.7833497214028188,
      "grad_norm": 0.0009617528412491083,
      "learning_rate": 3.313102463405926e-05,
      "loss": 0.0007,
      "step": 2390
    },
    {
      "epoch": 0.7866273352999017,
      "grad_norm": 0.023258130997419357,
      "learning_rate": 3.3041770796144235e-05,
      "loss": 0.0008,
      "step": 2400
    },
    {
      "epoch": 0.7899049491969846,
      "grad_norm": 0.02116200514137745,
      "learning_rate": 3.295251695822921e-05,
      "loss": 0.0005,
      "step": 2410
    },
    {
      "epoch": 0.7931825630940675,
      "grad_norm": 0.00034685462014749646,
      "learning_rate": 3.286326312031417e-05,
      "loss": 0.0006,
      "step": 2420
    },
    {
      "epoch": 0.7964601769911505,
      "grad_norm": 0.0005339502240531147,
      "learning_rate": 3.2774009282399144e-05,
      "loss": 0.0007,
      "step": 2430
    },
    {
      "epoch": 0.7997377908882334,
      "grad_norm": 0.00014813878806307912,
      "learning_rate": 3.2684755444484116e-05,
      "loss": 0.0005,
      "step": 2440
    },
    {
      "epoch": 0.8030154047853163,
      "grad_norm": 0.0019274832447990775,
      "learning_rate": 3.259550160656908e-05,
      "loss": 0.0004,
      "step": 2450
    },
    {
      "epoch": 0.8062930186823992,
      "grad_norm": 0.00024463236331939697,
      "learning_rate": 3.2506247768654054e-05,
      "loss": 0.0002,
      "step": 2460
    },
    {
      "epoch": 0.8095706325794821,
      "grad_norm": 0.01776239648461342,
      "learning_rate": 3.2416993930739026e-05,
      "loss": 0.0002,
      "step": 2470
    },
    {
      "epoch": 0.8128482464765651,
      "grad_norm": 0.21203745901584625,
      "learning_rate": 3.232774009282399e-05,
      "loss": 0.0002,
      "step": 2480
    },
    {
      "epoch": 0.816125860373648,
      "grad_norm": 0.0006585558876395226,
      "learning_rate": 3.223848625490896e-05,
      "loss": 0.0006,
      "step": 2490
    },
    {
      "epoch": 0.8194034742707309,
      "grad_norm": 0.008228834718465805,
      "learning_rate": 3.214923241699393e-05,
      "loss": 0.0004,
      "step": 2500
    },
    {
      "epoch": 0.8226810881678138,
      "grad_norm": 0.029420794919133186,
      "learning_rate": 3.20599785790789e-05,
      "loss": 0.0006,
      "step": 2510
    },
    {
      "epoch": 0.8259587020648967,
      "grad_norm": 0.027224162593483925,
      "learning_rate": 3.197072474116387e-05,
      "loss": 0.0003,
      "step": 2520
    },
    {
      "epoch": 0.8292363159619797,
      "grad_norm": 0.0032474917825311422,
      "learning_rate": 3.188147090324884e-05,
      "loss": 0.0001,
      "step": 2530
    },
    {
      "epoch": 0.8325139298590626,
      "grad_norm": 0.011353058740496635,
      "learning_rate": 3.179221706533381e-05,
      "loss": 0.0003,
      "step": 2540
    },
    {
      "epoch": 0.8357915437561455,
      "grad_norm": 0.015497428365051746,
      "learning_rate": 3.170296322741878e-05,
      "loss": 0.0009,
      "step": 2550
    },
    {
      "epoch": 0.8390691576532284,
      "grad_norm": 0.00034234035410918295,
      "learning_rate": 3.161370938950375e-05,
      "loss": 0.0006,
      "step": 2560
    },
    {
      "epoch": 0.8423467715503113,
      "grad_norm": 0.032260384410619736,
      "learning_rate": 3.152445555158872e-05,
      "loss": 0.0006,
      "step": 2570
    },
    {
      "epoch": 0.8456243854473943,
      "grad_norm": 0.014571224339306355,
      "learning_rate": 3.143520171367369e-05,
      "loss": 0.0004,
      "step": 2580
    },
    {
      "epoch": 0.8489019993444772,
      "grad_norm": 0.046529583632946014,
      "learning_rate": 3.1345947875758656e-05,
      "loss": 0.0005,
      "step": 2590
    },
    {
      "epoch": 0.8521796132415601,
      "grad_norm": 0.06706830114126205,
      "learning_rate": 3.125669403784363e-05,
      "loss": 0.0004,
      "step": 2600
    },
    {
      "epoch": 0.855457227138643,
      "grad_norm": 0.004919835366308689,
      "learning_rate": 3.11674401999286e-05,
      "loss": 0.0003,
      "step": 2610
    },
    {
      "epoch": 0.858734841035726,
      "grad_norm": 0.01184083428233862,
      "learning_rate": 3.1078186362013566e-05,
      "loss": 0.0003,
      "step": 2620
    },
    {
      "epoch": 0.8620124549328089,
      "grad_norm": 0.009076669812202454,
      "learning_rate": 3.098893252409854e-05,
      "loss": 0.0003,
      "step": 2630
    },
    {
      "epoch": 0.8652900688298918,
      "grad_norm": 0.001328670303337276,
      "learning_rate": 3.089967868618351e-05,
      "loss": 0.0004,
      "step": 2640
    },
    {
      "epoch": 0.8685676827269747,
      "grad_norm": 0.053468868136405945,
      "learning_rate": 3.0810424848268475e-05,
      "loss": 0.0004,
      "step": 2650
    },
    {
      "epoch": 0.8718452966240576,
      "grad_norm": 0.0003915239649359137,
      "learning_rate": 3.072117101035345e-05,
      "loss": 0.0004,
      "step": 2660
    },
    {
      "epoch": 0.8751229105211407,
      "grad_norm": 0.013752909377217293,
      "learning_rate": 3.063191717243842e-05,
      "loss": 0.0002,
      "step": 2670
    },
    {
      "epoch": 0.8784005244182236,
      "grad_norm": 0.1773991584777832,
      "learning_rate": 3.0542663334523384e-05,
      "loss": 0.0004,
      "step": 2680
    },
    {
      "epoch": 0.8816781383153065,
      "grad_norm": 0.02715504728257656,
      "learning_rate": 3.0453409496608353e-05,
      "loss": 0.0003,
      "step": 2690
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 0.006070252042263746,
      "learning_rate": 3.0364155658693328e-05,
      "loss": 0.0004,
      "step": 2700
    },
    {
      "epoch": 0.8882333661094723,
      "grad_norm": 0.0004184998688288033,
      "learning_rate": 3.0274901820778297e-05,
      "loss": 0.0003,
      "step": 2710
    },
    {
      "epoch": 0.8915109800065553,
      "grad_norm": 0.00021727556304540485,
      "learning_rate": 3.0185647982863262e-05,
      "loss": 0.0004,
      "step": 2720
    },
    {
      "epoch": 0.8947885939036382,
      "grad_norm": 0.00511471601203084,
      "learning_rate": 3.0096394144948238e-05,
      "loss": 0.0003,
      "step": 2730
    },
    {
      "epoch": 0.8980662078007211,
      "grad_norm": 0.04151361435651779,
      "learning_rate": 3.0007140307033206e-05,
      "loss": 0.0004,
      "step": 2740
    },
    {
      "epoch": 0.901343821697804,
      "grad_norm": 0.02076287567615509,
      "learning_rate": 2.991788646911817e-05,
      "loss": 0.0007,
      "step": 2750
    },
    {
      "epoch": 0.904621435594887,
      "grad_norm": 0.008856385946273804,
      "learning_rate": 2.982863263120314e-05,
      "loss": 0.0005,
      "step": 2760
    },
    {
      "epoch": 0.9078990494919699,
      "grad_norm": 0.0014731044648215175,
      "learning_rate": 2.9739378793288116e-05,
      "loss": 0.0001,
      "step": 2770
    },
    {
      "epoch": 0.9111766633890528,
      "grad_norm": 0.00038431116263382137,
      "learning_rate": 2.965012495537308e-05,
      "loss": 0.0001,
      "step": 2780
    },
    {
      "epoch": 0.9144542772861357,
      "grad_norm": 0.03662523627281189,
      "learning_rate": 2.956087111745805e-05,
      "loss": 0.0007,
      "step": 2790
    },
    {
      "epoch": 0.9177318911832186,
      "grad_norm": 0.0010396315483376384,
      "learning_rate": 2.9471617279543025e-05,
      "loss": 0.0002,
      "step": 2800
    },
    {
      "epoch": 0.9210095050803015,
      "grad_norm": 0.004825926385819912,
      "learning_rate": 2.938236344162799e-05,
      "loss": 0.0009,
      "step": 2810
    },
    {
      "epoch": 0.9242871189773845,
      "grad_norm": 0.0002080159174511209,
      "learning_rate": 2.929310960371296e-05,
      "loss": 0.0001,
      "step": 2820
    },
    {
      "epoch": 0.9275647328744674,
      "grad_norm": 0.04488193243741989,
      "learning_rate": 2.9203855765797934e-05,
      "loss": 0.0002,
      "step": 2830
    },
    {
      "epoch": 0.9308423467715503,
      "grad_norm": 0.01196594163775444,
      "learning_rate": 2.91146019278829e-05,
      "loss": 0.0003,
      "step": 2840
    },
    {
      "epoch": 0.9341199606686332,
      "grad_norm": 0.003906480502337217,
      "learning_rate": 2.9025348089967868e-05,
      "loss": 0.0001,
      "step": 2850
    },
    {
      "epoch": 0.9373975745657162,
      "grad_norm": 0.0005624145269393921,
      "learning_rate": 2.8936094252052844e-05,
      "loss": 0.0002,
      "step": 2860
    },
    {
      "epoch": 0.9406751884627991,
      "grad_norm": 0.028537247329950333,
      "learning_rate": 2.884684041413781e-05,
      "loss": 0.0002,
      "step": 2870
    },
    {
      "epoch": 0.943952802359882,
      "grad_norm": 0.0006135540897957981,
      "learning_rate": 2.8757586576222777e-05,
      "loss": 0.0002,
      "step": 2880
    },
    {
      "epoch": 0.9472304162569649,
      "grad_norm": 0.13223963975906372,
      "learning_rate": 2.8668332738307746e-05,
      "loss": 0.0015,
      "step": 2890
    },
    {
      "epoch": 0.9505080301540478,
      "grad_norm": 0.0002341476792935282,
      "learning_rate": 2.8579078900392718e-05,
      "loss": 0.0001,
      "step": 2900
    },
    {
      "epoch": 0.9537856440511308,
      "grad_norm": 0.0001617960078874603,
      "learning_rate": 2.8489825062477687e-05,
      "loss": 0.0005,
      "step": 2910
    },
    {
      "epoch": 0.9570632579482137,
      "grad_norm": 0.00020042876712977886,
      "learning_rate": 2.8400571224562655e-05,
      "loss": 0.0002,
      "step": 2920
    },
    {
      "epoch": 0.9603408718452966,
      "grad_norm": 0.00759570999071002,
      "learning_rate": 2.8311317386647627e-05,
      "loss": 0.0003,
      "step": 2930
    },
    {
      "epoch": 0.9636184857423795,
      "grad_norm": 0.0003967022930737585,
      "learning_rate": 2.8222063548732596e-05,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 0.9668960996394624,
      "grad_norm": 0.02082151547074318,
      "learning_rate": 2.8132809710817565e-05,
      "loss": 0.0004,
      "step": 2950
    },
    {
      "epoch": 0.9701737135365454,
      "grad_norm": 0.002903678687289357,
      "learning_rate": 2.8043555872902537e-05,
      "loss": 0.0007,
      "step": 2960
    },
    {
      "epoch": 0.9734513274336283,
      "grad_norm": 0.0004131697060074657,
      "learning_rate": 2.7954302034987505e-05,
      "loss": 0.0005,
      "step": 2970
    },
    {
      "epoch": 0.9767289413307112,
      "grad_norm": 0.00031013539410196245,
      "learning_rate": 2.7865048197072474e-05,
      "loss": 0.0007,
      "step": 2980
    },
    {
      "epoch": 0.9800065552277941,
      "grad_norm": 0.04974120482802391,
      "learning_rate": 2.7775794359157446e-05,
      "loss": 0.0004,
      "step": 2990
    },
    {
      "epoch": 0.983284169124877,
      "grad_norm": 0.00048714299919083714,
      "learning_rate": 2.7686540521242415e-05,
      "loss": 0.0003,
      "step": 3000
    },
    {
      "epoch": 0.98656178302196,
      "grad_norm": 0.00013160306843928993,
      "learning_rate": 2.7597286683327383e-05,
      "loss": 0.0003,
      "step": 3010
    },
    {
      "epoch": 0.989839396919043,
      "grad_norm": 0.009777014143764973,
      "learning_rate": 2.7508032845412352e-05,
      "loss": 0.0009,
      "step": 3020
    },
    {
      "epoch": 0.9931170108161259,
      "grad_norm": 0.0007001423509791493,
      "learning_rate": 2.7418779007497324e-05,
      "loss": 0.0005,
      "step": 3030
    },
    {
      "epoch": 0.9963946247132088,
      "grad_norm": 0.027288148179650307,
      "learning_rate": 2.7329525169582293e-05,
      "loss": 0.0006,
      "step": 3040
    },
    {
      "epoch": 0.9996722386102918,
      "grad_norm": 0.046421587467193604,
      "learning_rate": 2.724027133166726e-05,
      "loss": 0.0002,
      "step": 3050
    },
    {
      "epoch": 1.0029498525073746,
      "grad_norm": 0.0004942714003846049,
      "learning_rate": 2.7151017493752233e-05,
      "loss": 0.0001,
      "step": 3060
    },
    {
      "epoch": 1.0062274664044575,
      "grad_norm": 0.0002013557532336563,
      "learning_rate": 2.7061763655837202e-05,
      "loss": 0.0006,
      "step": 3070
    },
    {
      "epoch": 1.0095050803015404,
      "grad_norm": 0.00018440623534843326,
      "learning_rate": 2.697250981792217e-05,
      "loss": 0.0002,
      "step": 3080
    },
    {
      "epoch": 1.0127826941986233,
      "grad_norm": 0.0010700224665924907,
      "learning_rate": 2.6883255980007143e-05,
      "loss": 0.0005,
      "step": 3090
    },
    {
      "epoch": 1.0160603080957062,
      "grad_norm": 0.0008928806055337191,
      "learning_rate": 2.679400214209211e-05,
      "loss": 0.0008,
      "step": 3100
    },
    {
      "epoch": 1.0193379219927892,
      "grad_norm": 0.0008429185836575925,
      "learning_rate": 2.670474830417708e-05,
      "loss": 0.0004,
      "step": 3110
    },
    {
      "epoch": 1.022615535889872,
      "grad_norm": 0.006455819122493267,
      "learning_rate": 2.6615494466262052e-05,
      "loss": 0.0006,
      "step": 3120
    },
    {
      "epoch": 1.025893149786955,
      "grad_norm": 0.0029820813797414303,
      "learning_rate": 2.652624062834702e-05,
      "loss": 0.0002,
      "step": 3130
    },
    {
      "epoch": 1.029170763684038,
      "grad_norm": 0.00023877753119450063,
      "learning_rate": 2.643698679043199e-05,
      "loss": 0.0002,
      "step": 3140
    },
    {
      "epoch": 1.0324483775811208,
      "grad_norm": 0.00012004331074422225,
      "learning_rate": 2.6347732952516958e-05,
      "loss": 0.0003,
      "step": 3150
    },
    {
      "epoch": 1.0357259914782038,
      "grad_norm": 0.022072574123740196,
      "learning_rate": 2.625847911460193e-05,
      "loss": 0.0005,
      "step": 3160
    },
    {
      "epoch": 1.0390036053752867,
      "grad_norm": 0.041589394211769104,
      "learning_rate": 2.61692252766869e-05,
      "loss": 0.0001,
      "step": 3170
    },
    {
      "epoch": 1.0422812192723696,
      "grad_norm": 0.0003244645777158439,
      "learning_rate": 2.6079971438771867e-05,
      "loss": 0.0002,
      "step": 3180
    },
    {
      "epoch": 1.0455588331694528,
      "grad_norm": 0.0004357983998488635,
      "learning_rate": 2.599071760085684e-05,
      "loss": 0.0003,
      "step": 3190
    },
    {
      "epoch": 1.0488364470665354,
      "grad_norm": 0.0007599074160680175,
      "learning_rate": 2.5901463762941808e-05,
      "loss": 0.0009,
      "step": 3200
    },
    {
      "epoch": 1.0521140609636186,
      "grad_norm": 0.00046128075337037444,
      "learning_rate": 2.5812209925026777e-05,
      "loss": 0.0001,
      "step": 3210
    },
    {
      "epoch": 1.0553916748607015,
      "grad_norm": 0.00418210169300437,
      "learning_rate": 2.572295608711175e-05,
      "loss": 0.0002,
      "step": 3220
    },
    {
      "epoch": 1.0586692887577844,
      "grad_norm": 0.01164498645812273,
      "learning_rate": 2.5633702249196717e-05,
      "loss": 0.0002,
      "step": 3230
    },
    {
      "epoch": 1.0619469026548674,
      "grad_norm": 0.08902805298566818,
      "learning_rate": 2.5544448411281686e-05,
      "loss": 0.0002,
      "step": 3240
    },
    {
      "epoch": 1.0652245165519503,
      "grad_norm": 0.02943822555243969,
      "learning_rate": 2.5455194573366658e-05,
      "loss": 0.0005,
      "step": 3250
    },
    {
      "epoch": 1.0685021304490332,
      "grad_norm": 0.0031920578330755234,
      "learning_rate": 2.5365940735451627e-05,
      "loss": 0.0006,
      "step": 3260
    },
    {
      "epoch": 1.0717797443461161,
      "grad_norm": 0.0024765697307884693,
      "learning_rate": 2.5276686897536595e-05,
      "loss": 0.0002,
      "step": 3270
    },
    {
      "epoch": 1.075057358243199,
      "grad_norm": 0.00030739017529413104,
      "learning_rate": 2.5187433059621564e-05,
      "loss": 0.0004,
      "step": 3280
    },
    {
      "epoch": 1.078334972140282,
      "grad_norm": 0.007280615624040365,
      "learning_rate": 2.5098179221706536e-05,
      "loss": 0.0006,
      "step": 3290
    },
    {
      "epoch": 1.0816125860373649,
      "grad_norm": 0.00024972163373604417,
      "learning_rate": 2.5008925383791505e-05,
      "loss": 0.0002,
      "step": 3300
    },
    {
      "epoch": 1.0848901999344478,
      "grad_norm": 0.00021950872906018049,
      "learning_rate": 2.4919671545876473e-05,
      "loss": 0.0002,
      "step": 3310
    },
    {
      "epoch": 1.0881678138315307,
      "grad_norm": 0.048049017786979675,
      "learning_rate": 2.4830417707961442e-05,
      "loss": 0.0006,
      "step": 3320
    },
    {
      "epoch": 1.0914454277286136,
      "grad_norm": 0.00544348731637001,
      "learning_rate": 2.4741163870046414e-05,
      "loss": 0.0001,
      "step": 3330
    },
    {
      "epoch": 1.0947230416256966,
      "grad_norm": 0.00011002218525391072,
      "learning_rate": 2.4651910032131383e-05,
      "loss": 0.0002,
      "step": 3340
    },
    {
      "epoch": 1.0980006555227795,
      "grad_norm": 0.008750769309699535,
      "learning_rate": 2.456265619421635e-05,
      "loss": 0.0002,
      "step": 3350
    },
    {
      "epoch": 1.1012782694198624,
      "grad_norm": 0.010870149359107018,
      "learning_rate": 2.4473402356301323e-05,
      "loss": 0.0004,
      "step": 3360
    },
    {
      "epoch": 1.1045558833169453,
      "grad_norm": 0.002485886448994279,
      "learning_rate": 2.4384148518386292e-05,
      "loss": 0.0001,
      "step": 3370
    },
    {
      "epoch": 1.1078334972140282,
      "grad_norm": 0.0002239783207187429,
      "learning_rate": 2.429489468047126e-05,
      "loss": 0.0002,
      "step": 3380
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.061609577387571335,
      "learning_rate": 2.4205640842556233e-05,
      "loss": 0.0001,
      "step": 3390
    },
    {
      "epoch": 1.114388725008194,
      "grad_norm": 0.00019823577895294875,
      "learning_rate": 2.41163870046412e-05,
      "loss": 0.0003,
      "step": 3400
    },
    {
      "epoch": 1.117666338905277,
      "grad_norm": 0.00010581463720882311,
      "learning_rate": 2.402713316672617e-05,
      "loss": 0.0004,
      "step": 3410
    },
    {
      "epoch": 1.12094395280236,
      "grad_norm": 0.0002909265167545527,
      "learning_rate": 2.3937879328811142e-05,
      "loss": 0.0004,
      "step": 3420
    },
    {
      "epoch": 1.1242215666994428,
      "grad_norm": 0.00027200524345971644,
      "learning_rate": 2.384862549089611e-05,
      "loss": 0.0002,
      "step": 3430
    },
    {
      "epoch": 1.1274991805965258,
      "grad_norm": 0.00011334161536069587,
      "learning_rate": 2.375937165298108e-05,
      "loss": 0.0002,
      "step": 3440
    },
    {
      "epoch": 1.1307767944936087,
      "grad_norm": 0.0001764322369126603,
      "learning_rate": 2.3670117815066048e-05,
      "loss": 0.0003,
      "step": 3450
    },
    {
      "epoch": 1.1340544083906916,
      "grad_norm": 0.002228308469057083,
      "learning_rate": 2.358086397715102e-05,
      "loss": 0.0003,
      "step": 3460
    },
    {
      "epoch": 1.1373320222877745,
      "grad_norm": 0.00042115969699807465,
      "learning_rate": 2.349161013923599e-05,
      "loss": 0.0002,
      "step": 3470
    },
    {
      "epoch": 1.1406096361848574,
      "grad_norm": 0.03904009982943535,
      "learning_rate": 2.3402356301320957e-05,
      "loss": 0.0003,
      "step": 3480
    },
    {
      "epoch": 1.1438872500819404,
      "grad_norm": 0.011280273087322712,
      "learning_rate": 2.331310246340593e-05,
      "loss": 0.0003,
      "step": 3490
    },
    {
      "epoch": 1.1471648639790233,
      "grad_norm": 0.18903225660324097,
      "learning_rate": 2.3223848625490895e-05,
      "loss": 0.0005,
      "step": 3500
    },
    {
      "epoch": 1.1504424778761062,
      "grad_norm": 0.005129349883645773,
      "learning_rate": 2.3134594787575867e-05,
      "loss": 0.0004,
      "step": 3510
    },
    {
      "epoch": 1.1537200917731891,
      "grad_norm": 0.004672515671700239,
      "learning_rate": 2.304534094966084e-05,
      "loss": 0.0002,
      "step": 3520
    },
    {
      "epoch": 1.156997705670272,
      "grad_norm": 0.0038171743508428335,
      "learning_rate": 2.2956087111745804e-05,
      "loss": 0.0001,
      "step": 3530
    },
    {
      "epoch": 1.160275319567355,
      "grad_norm": 0.00014018880028743297,
      "learning_rate": 2.2866833273830776e-05,
      "loss": 0.0002,
      "step": 3540
    },
    {
      "epoch": 1.1635529334644379,
      "grad_norm": 0.004423190839588642,
      "learning_rate": 2.2777579435915748e-05,
      "loss": 0.0004,
      "step": 3550
    },
    {
      "epoch": 1.1668305473615208,
      "grad_norm": 0.02660129778087139,
      "learning_rate": 2.2688325598000713e-05,
      "loss": 0.0005,
      "step": 3560
    },
    {
      "epoch": 1.1701081612586037,
      "grad_norm": 0.00018209895642939955,
      "learning_rate": 2.2599071760085685e-05,
      "loss": 0.0001,
      "step": 3570
    },
    {
      "epoch": 1.1733857751556866,
      "grad_norm": 0.019670825451612473,
      "learning_rate": 2.2509817922170654e-05,
      "loss": 0.0001,
      "step": 3580
    },
    {
      "epoch": 1.1766633890527696,
      "grad_norm": 0.0063790129497647285,
      "learning_rate": 2.2420564084255623e-05,
      "loss": 0.0002,
      "step": 3590
    },
    {
      "epoch": 1.1799410029498525,
      "grad_norm": 0.0004095878393854946,
      "learning_rate": 2.2331310246340595e-05,
      "loss": 0.0001,
      "step": 3600
    },
    {
      "epoch": 1.1832186168469354,
      "grad_norm": 0.00010771603410830721,
      "learning_rate": 2.2242056408425563e-05,
      "loss": 0.0003,
      "step": 3610
    },
    {
      "epoch": 1.1864962307440183,
      "grad_norm": 9.351363405585289e-05,
      "learning_rate": 2.2152802570510532e-05,
      "loss": 0.0002,
      "step": 3620
    },
    {
      "epoch": 1.1897738446411013,
      "grad_norm": 0.0031166214030236006,
      "learning_rate": 2.20635487325955e-05,
      "loss": 0.0004,
      "step": 3630
    },
    {
      "epoch": 1.1930514585381842,
      "grad_norm": 0.017447220161557198,
      "learning_rate": 2.1974294894680473e-05,
      "loss": 0.0003,
      "step": 3640
    },
    {
      "epoch": 1.196329072435267,
      "grad_norm": 0.0008819742361083627,
      "learning_rate": 2.1885041056765445e-05,
      "loss": 0.0002,
      "step": 3650
    },
    {
      "epoch": 1.19960668633235,
      "grad_norm": 0.011098284274339676,
      "learning_rate": 2.179578721885041e-05,
      "loss": 0.0002,
      "step": 3660
    },
    {
      "epoch": 1.202884300229433,
      "grad_norm": 0.0026476129423826933,
      "learning_rate": 2.1706533380935382e-05,
      "loss": 0.0005,
      "step": 3670
    },
    {
      "epoch": 1.2061619141265159,
      "grad_norm": 0.00462688785046339,
      "learning_rate": 2.1617279543020354e-05,
      "loss": 0.0002,
      "step": 3680
    },
    {
      "epoch": 1.2094395280235988,
      "grad_norm": 0.0094102518633008,
      "learning_rate": 2.152802570510532e-05,
      "loss": 0.0002,
      "step": 3690
    },
    {
      "epoch": 1.2127171419206817,
      "grad_norm": 0.002057560719549656,
      "learning_rate": 2.143877186719029e-05,
      "loss": 0.0001,
      "step": 3700
    },
    {
      "epoch": 1.2159947558177646,
      "grad_norm": 0.00020628009224310517,
      "learning_rate": 2.134951802927526e-05,
      "loss": 0.0001,
      "step": 3710
    },
    {
      "epoch": 1.2192723697148475,
      "grad_norm": 0.002081948332488537,
      "learning_rate": 2.126026419136023e-05,
      "loss": 0.0001,
      "step": 3720
    },
    {
      "epoch": 1.2225499836119305,
      "grad_norm": 0.026041297242045403,
      "learning_rate": 2.11710103534452e-05,
      "loss": 0.0003,
      "step": 3730
    },
    {
      "epoch": 1.2258275975090134,
      "grad_norm": 0.0004597669467329979,
      "learning_rate": 2.108175651553017e-05,
      "loss": 0.0005,
      "step": 3740
    },
    {
      "epoch": 1.2291052114060963,
      "grad_norm": 0.010332990437746048,
      "learning_rate": 2.0992502677615138e-05,
      "loss": 0.0001,
      "step": 3750
    },
    {
      "epoch": 1.2323828253031792,
      "grad_norm": 0.005891244858503342,
      "learning_rate": 2.0903248839700106e-05,
      "loss": 0.0002,
      "step": 3760
    },
    {
      "epoch": 1.2356604392002621,
      "grad_norm": 0.008660415187478065,
      "learning_rate": 2.081399500178508e-05,
      "loss": 0.0002,
      "step": 3770
    },
    {
      "epoch": 1.238938053097345,
      "grad_norm": 0.0002007226285059005,
      "learning_rate": 2.0724741163870047e-05,
      "loss": 0.0009,
      "step": 3780
    },
    {
      "epoch": 1.242215666994428,
      "grad_norm": 0.004335502162575722,
      "learning_rate": 2.0635487325955016e-05,
      "loss": 0.0001,
      "step": 3790
    },
    {
      "epoch": 1.245493280891511,
      "grad_norm": 0.0005272378912195563,
      "learning_rate": 2.0546233488039988e-05,
      "loss": 0.0002,
      "step": 3800
    },
    {
      "epoch": 1.2487708947885938,
      "grad_norm": 0.00011870484740938991,
      "learning_rate": 2.0456979650124956e-05,
      "loss": 0.0001,
      "step": 3810
    },
    {
      "epoch": 1.252048508685677,
      "grad_norm": 0.021373266354203224,
      "learning_rate": 2.0367725812209925e-05,
      "loss": 0.0002,
      "step": 3820
    },
    {
      "epoch": 1.2553261225827597,
      "grad_norm": 0.007146812975406647,
      "learning_rate": 2.0278471974294897e-05,
      "loss": 0.0004,
      "step": 3830
    },
    {
      "epoch": 1.2586037364798428,
      "grad_norm": 0.00013424560893326998,
      "learning_rate": 2.0189218136379866e-05,
      "loss": 0.0001,
      "step": 3840
    },
    {
      "epoch": 1.2618813503769255,
      "grad_norm": 0.003237113356590271,
      "learning_rate": 2.0099964298464834e-05,
      "loss": 0.0003,
      "step": 3850
    },
    {
      "epoch": 1.2651589642740086,
      "grad_norm": 0.00018493813695386052,
      "learning_rate": 2.0010710460549806e-05,
      "loss": 0.0003,
      "step": 3860
    },
    {
      "epoch": 1.2684365781710913,
      "grad_norm": 0.000130380954942666,
      "learning_rate": 1.9921456622634775e-05,
      "loss": 0.0001,
      "step": 3870
    },
    {
      "epoch": 1.2717141920681745,
      "grad_norm": 0.0027069305069744587,
      "learning_rate": 1.9832202784719744e-05,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 1.2749918059652572,
      "grad_norm": 7.288582128239796e-05,
      "learning_rate": 1.9742948946804712e-05,
      "loss": 0.0001,
      "step": 3890
    },
    {
      "epoch": 1.2782694198623403,
      "grad_norm": 0.002378013450652361,
      "learning_rate": 1.9653695108889684e-05,
      "loss": 0.0002,
      "step": 3900
    },
    {
      "epoch": 1.281547033759423,
      "grad_norm": 0.014524313621222973,
      "learning_rate": 1.9564441270974653e-05,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 1.2848246476565062,
      "grad_norm": 0.0011860172962769866,
      "learning_rate": 1.9475187433059622e-05,
      "loss": 0.0002,
      "step": 3920
    },
    {
      "epoch": 1.2881022615535889,
      "grad_norm": 0.13220250606536865,
      "learning_rate": 1.9385933595144594e-05,
      "loss": 0.0003,
      "step": 3930
    },
    {
      "epoch": 1.291379875450672,
      "grad_norm": 0.004110631998628378,
      "learning_rate": 1.929667975722956e-05,
      "loss": 0.0002,
      "step": 3940
    },
    {
      "epoch": 1.2946574893477547,
      "grad_norm": 0.000262769142864272,
      "learning_rate": 1.920742591931453e-05,
      "loss": 0.0001,
      "step": 3950
    },
    {
      "epoch": 1.2979351032448379,
      "grad_norm": 0.00023265107301995158,
      "learning_rate": 1.9118172081399503e-05,
      "loss": 0.0007,
      "step": 3960
    },
    {
      "epoch": 1.3012127171419205,
      "grad_norm": 9.731412137625739e-05,
      "learning_rate": 1.902891824348447e-05,
      "loss": 0.0001,
      "step": 3970
    },
    {
      "epoch": 1.3044903310390037,
      "grad_norm": 0.0001325752673437819,
      "learning_rate": 1.893966440556944e-05,
      "loss": 0.0002,
      "step": 3980
    },
    {
      "epoch": 1.3077679449360864,
      "grad_norm": 6.68141947244294e-05,
      "learning_rate": 1.8850410567654412e-05,
      "loss": 0.0002,
      "step": 3990
    },
    {
      "epoch": 1.3110455588331695,
      "grad_norm": 0.0001822115882532671,
      "learning_rate": 1.8761156729739378e-05,
      "loss": 0.0001,
      "step": 4000
    },
    {
      "epoch": 1.3143231727302525,
      "grad_norm": 0.0013332582311704755,
      "learning_rate": 1.867190289182435e-05,
      "loss": 0.0004,
      "step": 4010
    },
    {
      "epoch": 1.3176007866273354,
      "grad_norm": 0.30205830931663513,
      "learning_rate": 1.858264905390932e-05,
      "loss": 0.0005,
      "step": 4020
    },
    {
      "epoch": 1.3208784005244183,
      "grad_norm": 0.014251497574150562,
      "learning_rate": 1.8493395215994287e-05,
      "loss": 0.0001,
      "step": 4030
    },
    {
      "epoch": 1.3241560144215012,
      "grad_norm": 0.0004337468708399683,
      "learning_rate": 1.840414137807926e-05,
      "loss": 0.0001,
      "step": 4040
    },
    {
      "epoch": 1.3274336283185841,
      "grad_norm": 0.00031321035930886865,
      "learning_rate": 1.8314887540164228e-05,
      "loss": 0.0002,
      "step": 4050
    },
    {
      "epoch": 1.330711242215667,
      "grad_norm": 0.0002644613559823483,
      "learning_rate": 1.8225633702249196e-05,
      "loss": 0.0002,
      "step": 4060
    },
    {
      "epoch": 1.33398885611275,
      "grad_norm": 0.00268083275295794,
      "learning_rate": 1.8136379864334165e-05,
      "loss": 0.0001,
      "step": 4070
    },
    {
      "epoch": 1.337266470009833,
      "grad_norm": 0.0972909927368164,
      "learning_rate": 1.8047126026419137e-05,
      "loss": 0.0004,
      "step": 4080
    },
    {
      "epoch": 1.3405440839069158,
      "grad_norm": 0.0009397963876836002,
      "learning_rate": 1.7957872188504106e-05,
      "loss": 0.0001,
      "step": 4090
    },
    {
      "epoch": 1.3438216978039987,
      "grad_norm": 0.0007937355549074709,
      "learning_rate": 1.7868618350589074e-05,
      "loss": 0.0001,
      "step": 4100
    },
    {
      "epoch": 1.3470993117010817,
      "grad_norm": 0.00015488284407183528,
      "learning_rate": 1.7779364512674046e-05,
      "loss": 0.0001,
      "step": 4110
    },
    {
      "epoch": 1.3503769255981646,
      "grad_norm": 0.00010575340274954215,
      "learning_rate": 1.769011067475902e-05,
      "loss": 0.0001,
      "step": 4120
    },
    {
      "epoch": 1.3536545394952475,
      "grad_norm": 0.004725542385131121,
      "learning_rate": 1.7600856836843984e-05,
      "loss": 0.0001,
      "step": 4130
    },
    {
      "epoch": 1.3569321533923304,
      "grad_norm": 0.00585908442735672,
      "learning_rate": 1.7511602998928956e-05,
      "loss": 0.0001,
      "step": 4140
    },
    {
      "epoch": 1.3602097672894133,
      "grad_norm": 0.011035623960196972,
      "learning_rate": 1.7422349161013924e-05,
      "loss": 0.0001,
      "step": 4150
    },
    {
      "epoch": 1.3634873811864963,
      "grad_norm": 0.00012404649169184268,
      "learning_rate": 1.7333095323098893e-05,
      "loss": 0.0001,
      "step": 4160
    },
    {
      "epoch": 1.3667649950835792,
      "grad_norm": 0.006240976043045521,
      "learning_rate": 1.7243841485183865e-05,
      "loss": 0.0001,
      "step": 4170
    },
    {
      "epoch": 1.370042608980662,
      "grad_norm": 0.0114818150177598,
      "learning_rate": 1.7154587647268834e-05,
      "loss": 0.0002,
      "step": 4180
    },
    {
      "epoch": 1.373320222877745,
      "grad_norm": 0.014850006438791752,
      "learning_rate": 1.7065333809353802e-05,
      "loss": 0.0002,
      "step": 4190
    },
    {
      "epoch": 1.376597836774828,
      "grad_norm": 0.0035678388085216284,
      "learning_rate": 1.697607997143877e-05,
      "loss": 0.0002,
      "step": 4200
    },
    {
      "epoch": 1.3798754506719109,
      "grad_norm": 0.014799266122281551,
      "learning_rate": 1.6886826133523743e-05,
      "loss": 0.0003,
      "step": 4210
    },
    {
      "epoch": 1.3831530645689938,
      "grad_norm": 0.0022609273437410593,
      "learning_rate": 1.679757229560871e-05,
      "loss": 0.0001,
      "step": 4220
    },
    {
      "epoch": 1.3864306784660767,
      "grad_norm": 0.15924935042858124,
      "learning_rate": 1.670831845769368e-05,
      "loss": 0.0008,
      "step": 4230
    },
    {
      "epoch": 1.3897082923631596,
      "grad_norm": 0.011296319775283337,
      "learning_rate": 1.6619064619778652e-05,
      "loss": 0.0003,
      "step": 4240
    },
    {
      "epoch": 1.3929859062602425,
      "grad_norm": 0.0062566474080085754,
      "learning_rate": 1.652981078186362e-05,
      "loss": 0.0003,
      "step": 4250
    },
    {
      "epoch": 1.3962635201573255,
      "grad_norm": 0.00010502131044631824,
      "learning_rate": 1.644055694394859e-05,
      "loss": 0.0001,
      "step": 4260
    },
    {
      "epoch": 1.3995411340544084,
      "grad_norm": 0.012708851136267185,
      "learning_rate": 1.635130310603356e-05,
      "loss": 0.0001,
      "step": 4270
    },
    {
      "epoch": 1.4028187479514913,
      "grad_norm": 0.0013032216811552644,
      "learning_rate": 1.626204926811853e-05,
      "loss": 0.0001,
      "step": 4280
    },
    {
      "epoch": 1.4060963618485742,
      "grad_norm": 0.000849408155772835,
      "learning_rate": 1.61727954302035e-05,
      "loss": 0.0,
      "step": 4290
    },
    {
      "epoch": 1.4093739757456571,
      "grad_norm": 0.001509624533355236,
      "learning_rate": 1.608354159228847e-05,
      "loss": 0.0003,
      "step": 4300
    },
    {
      "epoch": 1.41265158964274,
      "grad_norm": 0.004848470911383629,
      "learning_rate": 1.599428775437344e-05,
      "loss": 0.0,
      "step": 4310
    },
    {
      "epoch": 1.415929203539823,
      "grad_norm": 0.00015916772827040404,
      "learning_rate": 1.5905033916458408e-05,
      "loss": 0.0002,
      "step": 4320
    },
    {
      "epoch": 1.419206817436906,
      "grad_norm": 0.0003341001574881375,
      "learning_rate": 1.5815780078543377e-05,
      "loss": 0.0005,
      "step": 4330
    },
    {
      "epoch": 1.4224844313339888,
      "grad_norm": 0.0012032013619318604,
      "learning_rate": 1.572652624062835e-05,
      "loss": 0.0002,
      "step": 4340
    },
    {
      "epoch": 1.4257620452310718,
      "grad_norm": 0.0312863253057003,
      "learning_rate": 1.5637272402713318e-05,
      "loss": 0.0004,
      "step": 4350
    },
    {
      "epoch": 1.4290396591281547,
      "grad_norm": 0.003937062341719866,
      "learning_rate": 1.5548018564798286e-05,
      "loss": 0.0001,
      "step": 4360
    },
    {
      "epoch": 1.4323172730252376,
      "grad_norm": 0.03177790343761444,
      "learning_rate": 1.5458764726883258e-05,
      "loss": 0.0002,
      "step": 4370
    },
    {
      "epoch": 1.4355948869223205,
      "grad_norm": 0.00015066062042023987,
      "learning_rate": 1.5369510888968227e-05,
      "loss": 0.0001,
      "step": 4380
    },
    {
      "epoch": 1.4388725008194034,
      "grad_norm": 0.0002129501081071794,
      "learning_rate": 1.5280257051053196e-05,
      "loss": 0.0001,
      "step": 4390
    },
    {
      "epoch": 1.4421501147164864,
      "grad_norm": 0.001072955783456564,
      "learning_rate": 1.5191003213138166e-05,
      "loss": 0.0002,
      "step": 4400
    },
    {
      "epoch": 1.4454277286135693,
      "grad_norm": 7.185305730672553e-05,
      "learning_rate": 1.5101749375223135e-05,
      "loss": 0.0001,
      "step": 4410
    },
    {
      "epoch": 1.4487053425106522,
      "grad_norm": 0.0035483010578900576,
      "learning_rate": 1.5012495537308105e-05,
      "loss": 0.0002,
      "step": 4420
    },
    {
      "epoch": 1.4519829564077351,
      "grad_norm": 0.00018096283019986004,
      "learning_rate": 1.4923241699393075e-05,
      "loss": 0.0002,
      "step": 4430
    },
    {
      "epoch": 1.455260570304818,
      "grad_norm": 0.00013362779282033443,
      "learning_rate": 1.4833987861478044e-05,
      "loss": 0.0002,
      "step": 4440
    },
    {
      "epoch": 1.458538184201901,
      "grad_norm": 0.004279256798326969,
      "learning_rate": 1.4744734023563014e-05,
      "loss": 0.0001,
      "step": 4450
    },
    {
      "epoch": 1.4618157980989839,
      "grad_norm": 0.0004658288380596787,
      "learning_rate": 1.4655480185647983e-05,
      "loss": 0.0001,
      "step": 4460
    },
    {
      "epoch": 1.4650934119960668,
      "grad_norm": 0.0002685172366909683,
      "learning_rate": 1.4566226347732953e-05,
      "loss": 0.0005,
      "step": 4470
    },
    {
      "epoch": 1.4683710258931497,
      "grad_norm": 0.00047962815733626485,
      "learning_rate": 1.4476972509817924e-05,
      "loss": 0.0003,
      "step": 4480
    },
    {
      "epoch": 1.4716486397902326,
      "grad_norm": 0.008239524438977242,
      "learning_rate": 1.4387718671902892e-05,
      "loss": 0.0001,
      "step": 4490
    },
    {
      "epoch": 1.4749262536873156,
      "grad_norm": 0.004390337038785219,
      "learning_rate": 1.4298464833987863e-05,
      "loss": 0.0002,
      "step": 4500
    },
    {
      "epoch": 1.4782038675843985,
      "grad_norm": 0.00012347732263151556,
      "learning_rate": 1.4209210996072833e-05,
      "loss": 0.0003,
      "step": 4510
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 9.618582407711074e-05,
      "learning_rate": 1.4119957158157802e-05,
      "loss": 0.0001,
      "step": 4520
    },
    {
      "epoch": 1.4847590953785645,
      "grad_norm": 0.0015811009798198938,
      "learning_rate": 1.4030703320242772e-05,
      "loss": 0.0001,
      "step": 4530
    },
    {
      "epoch": 1.4880367092756472,
      "grad_norm": 0.002811526646837592,
      "learning_rate": 1.394144948232774e-05,
      "loss": 0.0001,
      "step": 4540
    },
    {
      "epoch": 1.4913143231727304,
      "grad_norm": 0.0024363279808312654,
      "learning_rate": 1.3852195644412711e-05,
      "loss": 0.0001,
      "step": 4550
    },
    {
      "epoch": 1.494591937069813,
      "grad_norm": 0.0013532469747588038,
      "learning_rate": 1.3762941806497681e-05,
      "loss": 0.0001,
      "step": 4560
    },
    {
      "epoch": 1.4978695509668962,
      "grad_norm": 0.0009585748775862157,
      "learning_rate": 1.367368796858265e-05,
      "loss": 0.0001,
      "step": 4570
    },
    {
      "epoch": 1.501147164863979,
      "grad_norm": 0.00012107919610571116,
      "learning_rate": 1.358443413066762e-05,
      "loss": 0.0006,
      "step": 4580
    },
    {
      "epoch": 1.504424778761062,
      "grad_norm": 0.0001263115555047989,
      "learning_rate": 1.3495180292752587e-05,
      "loss": 0.0003,
      "step": 4590
    },
    {
      "epoch": 1.5077023926581448,
      "grad_norm": 0.0008774398593232036,
      "learning_rate": 1.340592645483756e-05,
      "loss": 0.0007,
      "step": 4600
    },
    {
      "epoch": 1.510980006555228,
      "grad_norm": 0.00020923685224261135,
      "learning_rate": 1.331667261692253e-05,
      "loss": 0.0001,
      "step": 4610
    },
    {
      "epoch": 1.5142576204523106,
      "grad_norm": 8.840422378852963e-05,
      "learning_rate": 1.3227418779007496e-05,
      "loss": 0.0001,
      "step": 4620
    },
    {
      "epoch": 1.5175352343493937,
      "grad_norm": 0.000164632176165469,
      "learning_rate": 1.3138164941092469e-05,
      "loss": 0.0002,
      "step": 4630
    },
    {
      "epoch": 1.5208128482464764,
      "grad_norm": 0.05332878604531288,
      "learning_rate": 1.3048911103177439e-05,
      "loss": 0.0005,
      "step": 4640
    },
    {
      "epoch": 1.5240904621435596,
      "grad_norm": 0.009059264324605465,
      "learning_rate": 1.2959657265262406e-05,
      "loss": 0.0002,
      "step": 4650
    },
    {
      "epoch": 1.5273680760406423,
      "grad_norm": 0.00030802161199972034,
      "learning_rate": 1.2870403427347378e-05,
      "loss": 0.0001,
      "step": 4660
    },
    {
      "epoch": 1.5306456899377254,
      "grad_norm": 0.014713007025420666,
      "learning_rate": 1.2781149589432345e-05,
      "loss": 0.0002,
      "step": 4670
    },
    {
      "epoch": 1.5339233038348081,
      "grad_norm": 0.00014748424291610718,
      "learning_rate": 1.2691895751517315e-05,
      "loss": 0.0004,
      "step": 4680
    },
    {
      "epoch": 1.5372009177318913,
      "grad_norm": 0.00018412389908917248,
      "learning_rate": 1.2602641913602287e-05,
      "loss": 0.0005,
      "step": 4690
    },
    {
      "epoch": 1.540478531628974,
      "grad_norm": 0.020731870085000992,
      "learning_rate": 1.2513388075687254e-05,
      "loss": 0.0002,
      "step": 4700
    },
    {
      "epoch": 1.543756145526057,
      "grad_norm": 0.00010139605728909373,
      "learning_rate": 1.2424134237772224e-05,
      "loss": 0.0002,
      "step": 4710
    },
    {
      "epoch": 1.5470337594231398,
      "grad_norm": 0.0001622818090254441,
      "learning_rate": 1.2334880399857195e-05,
      "loss": 0.0002,
      "step": 4720
    },
    {
      "epoch": 1.550311373320223,
      "grad_norm": 0.00021085978369228542,
      "learning_rate": 1.2245626561942163e-05,
      "loss": 0.0001,
      "step": 4730
    },
    {
      "epoch": 1.5535889872173057,
      "grad_norm": 0.0002204173943027854,
      "learning_rate": 1.2156372724027134e-05,
      "loss": 0.0001,
      "step": 4740
    },
    {
      "epoch": 1.5568666011143888,
      "grad_norm": 0.007801414001733065,
      "learning_rate": 1.2067118886112104e-05,
      "loss": 0.0005,
      "step": 4750
    },
    {
      "epoch": 1.5601442150114715,
      "grad_norm": 7.019467739155516e-05,
      "learning_rate": 1.1977865048197073e-05,
      "loss": 0.0001,
      "step": 4760
    },
    {
      "epoch": 1.5634218289085546,
      "grad_norm": 0.0001549232838442549,
      "learning_rate": 1.1888611210282043e-05,
      "loss": 0.0001,
      "step": 4770
    },
    {
      "epoch": 1.5666994428056373,
      "grad_norm": 0.027091989293694496,
      "learning_rate": 1.1799357372367012e-05,
      "loss": 0.0002,
      "step": 4780
    },
    {
      "epoch": 1.5699770567027205,
      "grad_norm": 0.00016581523232162,
      "learning_rate": 1.1710103534451982e-05,
      "loss": 0.0001,
      "step": 4790
    },
    {
      "epoch": 1.5732546705998034,
      "grad_norm": 0.0001587194565217942,
      "learning_rate": 1.1620849696536952e-05,
      "loss": 0.0004,
      "step": 4800
    },
    {
      "epoch": 1.5765322844968863,
      "grad_norm": 0.030649274587631226,
      "learning_rate": 1.1531595858621921e-05,
      "loss": 0.0002,
      "step": 4810
    },
    {
      "epoch": 1.5798098983939692,
      "grad_norm": 0.011533583514392376,
      "learning_rate": 1.1442342020706891e-05,
      "loss": 0.0002,
      "step": 4820
    },
    {
      "epoch": 1.5830875122910522,
      "grad_norm": 0.004313576966524124,
      "learning_rate": 1.135308818279186e-05,
      "loss": 0.0,
      "step": 4830
    },
    {
      "epoch": 1.586365126188135,
      "grad_norm": 0.04940524324774742,
      "learning_rate": 1.126383434487683e-05,
      "loss": 0.0003,
      "step": 4840
    },
    {
      "epoch": 1.589642740085218,
      "grad_norm": 0.026331188157200813,
      "learning_rate": 1.11745805069618e-05,
      "loss": 0.0003,
      "step": 4850
    },
    {
      "epoch": 1.592920353982301,
      "grad_norm": 0.009679666720330715,
      "learning_rate": 1.108532666904677e-05,
      "loss": 0.0003,
      "step": 4860
    },
    {
      "epoch": 1.5961979678793838,
      "grad_norm": 0.017177840694785118,
      "learning_rate": 1.0996072831131738e-05,
      "loss": 0.0003,
      "step": 4870
    },
    {
      "epoch": 1.5994755817764668,
      "grad_norm": 0.002001284621655941,
      "learning_rate": 1.090681899321671e-05,
      "loss": 0.0001,
      "step": 4880
    },
    {
      "epoch": 1.6027531956735497,
      "grad_norm": 0.037986766546964645,
      "learning_rate": 1.0817565155301679e-05,
      "loss": 0.0005,
      "step": 4890
    },
    {
      "epoch": 1.6060308095706326,
      "grad_norm": 0.00027262591174803674,
      "learning_rate": 1.0728311317386647e-05,
      "loss": 0.0002,
      "step": 4900
    },
    {
      "epoch": 1.6093084234677155,
      "grad_norm": 0.013281558640301228,
      "learning_rate": 1.0639057479471618e-05,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 1.6125860373647984,
      "grad_norm": 9.994767606258392e-05,
      "learning_rate": 1.0549803641556586e-05,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 1.6158636512618814,
      "grad_norm": 0.00029085009009577334,
      "learning_rate": 1.0460549803641557e-05,
      "loss": 0.0002,
      "step": 4930
    },
    {
      "epoch": 1.6191412651589643,
      "grad_norm": 0.013910346664488316,
      "learning_rate": 1.0371295965726527e-05,
      "loss": 0.0002,
      "step": 4940
    },
    {
      "epoch": 1.6224188790560472,
      "grad_norm": 0.007293348666280508,
      "learning_rate": 1.0282042127811496e-05,
      "loss": 0.0001,
      "step": 4950
    },
    {
      "epoch": 1.6256964929531301,
      "grad_norm": 6.225298420758918e-05,
      "learning_rate": 1.0192788289896466e-05,
      "loss": 0.0001,
      "step": 4960
    },
    {
      "epoch": 1.628974106850213,
      "grad_norm": 0.0001198045865749009,
      "learning_rate": 1.0103534451981436e-05,
      "loss": 0.0002,
      "step": 4970
    },
    {
      "epoch": 1.632251720747296,
      "grad_norm": 0.001928929123096168,
      "learning_rate": 1.0014280614066405e-05,
      "loss": 0.0005,
      "step": 4980
    },
    {
      "epoch": 1.6355293346443789,
      "grad_norm": 0.0028051745612174273,
      "learning_rate": 9.925026776151375e-06,
      "loss": 0.0001,
      "step": 4990
    },
    {
      "epoch": 1.6388069485414618,
      "grad_norm": 0.010012814775109291,
      "learning_rate": 9.835772938236344e-06,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 1.6420845624385447,
      "grad_norm": 0.006593744736164808,
      "learning_rate": 9.746519100321314e-06,
      "loss": 0.0002,
      "step": 5010
    },
    {
      "epoch": 1.6453621763356276,
      "grad_norm": 0.0010033446596935391,
      "learning_rate": 9.657265262406285e-06,
      "loss": 0.0011,
      "step": 5020
    },
    {
      "epoch": 1.6486397902327106,
      "grad_norm": 0.000112434099719394,
      "learning_rate": 9.568011424491253e-06,
      "loss": 0.0001,
      "step": 5030
    },
    {
      "epoch": 1.6519174041297935,
      "grad_norm": 0.0019315523095428944,
      "learning_rate": 9.478757586576224e-06,
      "loss": 0.0003,
      "step": 5040
    },
    {
      "epoch": 1.6551950180268764,
      "grad_norm": 0.0732104703783989,
      "learning_rate": 9.389503748661192e-06,
      "loss": 0.0003,
      "step": 5050
    },
    {
      "epoch": 1.6584726319239593,
      "grad_norm": 7.938020280562341e-05,
      "learning_rate": 9.300249910746163e-06,
      "loss": 0.0002,
      "step": 5060
    },
    {
      "epoch": 1.6617502458210422,
      "grad_norm": 0.0010450717527419329,
      "learning_rate": 9.210996072831133e-06,
      "loss": 0.0002,
      "step": 5070
    },
    {
      "epoch": 1.6650278597181252,
      "grad_norm": 0.0025573098100721836,
      "learning_rate": 9.121742234916102e-06,
      "loss": 0.0002,
      "step": 5080
    },
    {
      "epoch": 1.668305473615208,
      "grad_norm": 0.0034931274130940437,
      "learning_rate": 9.03248839700107e-06,
      "loss": 0.0,
      "step": 5090
    },
    {
      "epoch": 1.671583087512291,
      "grad_norm": 0.017960714176297188,
      "learning_rate": 8.943234559086042e-06,
      "loss": 0.0004,
      "step": 5100
    },
    {
      "epoch": 1.674860701409374,
      "grad_norm": 9.500299347564578e-05,
      "learning_rate": 8.853980721171011e-06,
      "loss": 0.0001,
      "step": 5110
    },
    {
      "epoch": 1.6781383153064569,
      "grad_norm": 0.03816334158182144,
      "learning_rate": 8.76472688325598e-06,
      "loss": 0.0006,
      "step": 5120
    },
    {
      "epoch": 1.6814159292035398,
      "grad_norm": 0.00013341117301024497,
      "learning_rate": 8.67547304534095e-06,
      "loss": 0.0002,
      "step": 5130
    },
    {
      "epoch": 1.6846935431006227,
      "grad_norm": 0.0004510414437390864,
      "learning_rate": 8.58621920742592e-06,
      "loss": 0.0001,
      "step": 5140
    },
    {
      "epoch": 1.6879711569977056,
      "grad_norm": 0.00023680935555603355,
      "learning_rate": 8.496965369510889e-06,
      "loss": 0.0005,
      "step": 5150
    },
    {
      "epoch": 1.6912487708947888,
      "grad_norm": 0.012182760052382946,
      "learning_rate": 8.40771153159586e-06,
      "loss": 0.0001,
      "step": 5160
    },
    {
      "epoch": 1.6945263847918715,
      "grad_norm": 0.003766715293750167,
      "learning_rate": 8.318457693680828e-06,
      "loss": 0.0001,
      "step": 5170
    },
    {
      "epoch": 1.6978039986889546,
      "grad_norm": 0.6115763187408447,
      "learning_rate": 8.229203855765798e-06,
      "loss": 0.0003,
      "step": 5180
    },
    {
      "epoch": 1.7010816125860373,
      "grad_norm": 0.00012958754086866975,
      "learning_rate": 8.139950017850769e-06,
      "loss": 0.0002,
      "step": 5190
    },
    {
      "epoch": 1.7043592264831204,
      "grad_norm": 0.011267575435340405,
      "learning_rate": 8.050696179935737e-06,
      "loss": 0.0004,
      "step": 5200
    },
    {
      "epoch": 1.7076368403802031,
      "grad_norm": 0.00018372858176007867,
      "learning_rate": 7.961442342020708e-06,
      "loss": 0.0002,
      "step": 5210
    },
    {
      "epoch": 1.7109144542772863,
      "grad_norm": 0.00014187001215759665,
      "learning_rate": 7.872188504105676e-06,
      "loss": 0.0003,
      "step": 5220
    },
    {
      "epoch": 1.714192068174369,
      "grad_norm": 6.853944069007412e-05,
      "learning_rate": 7.782934666190647e-06,
      "loss": 0.0004,
      "step": 5230
    },
    {
      "epoch": 1.7174696820714521,
      "grad_norm": 0.0011743683135136962,
      "learning_rate": 7.693680828275617e-06,
      "loss": 0.0004,
      "step": 5240
    },
    {
      "epoch": 1.7207472959685348,
      "grad_norm": 0.011254635639488697,
      "learning_rate": 7.604426990360586e-06,
      "loss": 0.0002,
      "step": 5250
    },
    {
      "epoch": 1.724024909865618,
      "grad_norm": 0.000504828232806176,
      "learning_rate": 7.515173152445555e-06,
      "loss": 0.0002,
      "step": 5260
    },
    {
      "epoch": 1.7273025237627007,
      "grad_norm": 0.00021190008556004614,
      "learning_rate": 7.425919314530526e-06,
      "loss": 0.0002,
      "step": 5270
    },
    {
      "epoch": 1.7305801376597838,
      "grad_norm": 0.0023841573856770992,
      "learning_rate": 7.336665476615495e-06,
      "loss": 0.0002,
      "step": 5280
    },
    {
      "epoch": 1.7338577515568665,
      "grad_norm": 0.0026777898892760277,
      "learning_rate": 7.247411638700464e-06,
      "loss": 0.0001,
      "step": 5290
    },
    {
      "epoch": 1.7371353654539496,
      "grad_norm": 0.00010058021871373057,
      "learning_rate": 7.158157800785434e-06,
      "loss": 0.0002,
      "step": 5300
    },
    {
      "epoch": 1.7404129793510323,
      "grad_norm": 0.00010995005868608132,
      "learning_rate": 7.068903962870403e-06,
      "loss": 0.0001,
      "step": 5310
    },
    {
      "epoch": 1.7436905932481155,
      "grad_norm": 0.005595546215772629,
      "learning_rate": 6.979650124955374e-06,
      "loss": 0.0001,
      "step": 5320
    },
    {
      "epoch": 1.7469682071451982,
      "grad_norm": 0.005335961002856493,
      "learning_rate": 6.890396287040343e-06,
      "loss": 0.0001,
      "step": 5330
    },
    {
      "epoch": 1.7502458210422813,
      "grad_norm": 0.007352293003350496,
      "learning_rate": 6.801142449125313e-06,
      "loss": 0.0001,
      "step": 5340
    },
    {
      "epoch": 1.753523434939364,
      "grad_norm": 0.00023030003649182618,
      "learning_rate": 6.711888611210282e-06,
      "loss": 0.0004,
      "step": 5350
    },
    {
      "epoch": 1.7568010488364472,
      "grad_norm": 5.1026916480623186e-05,
      "learning_rate": 6.6226347732952526e-06,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 1.7600786627335299,
      "grad_norm": 0.00024078354181256145,
      "learning_rate": 6.533380935380222e-06,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 1.763356276630613,
      "grad_norm": 0.014652315527200699,
      "learning_rate": 6.4441270974651915e-06,
      "loss": 0.0004,
      "step": 5380
    },
    {
      "epoch": 1.7666338905276957,
      "grad_norm": 0.0023990545887500048,
      "learning_rate": 6.35487325955016e-06,
      "loss": 0.0001,
      "step": 5390
    },
    {
      "epoch": 1.7699115044247788,
      "grad_norm": 0.0021250108256936073,
      "learning_rate": 6.26561942163513e-06,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 1.7731891183218615,
      "grad_norm": 0.00014956184895709157,
      "learning_rate": 6.1763655837201e-06,
      "loss": 0.0002,
      "step": 5410
    },
    {
      "epoch": 1.7764667322189447,
      "grad_norm": 9.619368211133406e-05,
      "learning_rate": 6.08711174580507e-06,
      "loss": 0.0006,
      "step": 5420
    },
    {
      "epoch": 1.7797443461160274,
      "grad_norm": 0.024807242676615715,
      "learning_rate": 5.997857907890039e-06,
      "loss": 0.0001,
      "step": 5430
    },
    {
      "epoch": 1.7830219600131105,
      "grad_norm": 0.0001992539328057319,
      "learning_rate": 5.908604069975009e-06,
      "loss": 0.0001,
      "step": 5440
    },
    {
      "epoch": 1.7862995739101932,
      "grad_norm": 0.0017526495503261685,
      "learning_rate": 5.819350232059979e-06,
      "loss": 0.0004,
      "step": 5450
    },
    {
      "epoch": 1.7895771878072764,
      "grad_norm": 0.000866241694893688,
      "learning_rate": 5.730096394144948e-06,
      "loss": 0.0002,
      "step": 5460
    },
    {
      "epoch": 1.792854801704359,
      "grad_norm": 0.00013940705684944987,
      "learning_rate": 5.640842556229918e-06,
      "loss": 0.0002,
      "step": 5470
    },
    {
      "epoch": 1.7961324156014422,
      "grad_norm": 0.00014639580331277102,
      "learning_rate": 5.551588718314888e-06,
      "loss": 0.0001,
      "step": 5480
    },
    {
      "epoch": 1.799410029498525,
      "grad_norm": 0.026025189086794853,
      "learning_rate": 5.462334880399858e-06,
      "loss": 0.0001,
      "step": 5490
    },
    {
      "epoch": 1.802687643395608,
      "grad_norm": 0.0067788660526275635,
      "learning_rate": 5.373081042484827e-06,
      "loss": 0.0002,
      "step": 5500
    },
    {
      "epoch": 1.805965257292691,
      "grad_norm": 0.013585777021944523,
      "learning_rate": 5.283827204569797e-06,
      "loss": 0.0001,
      "step": 5510
    },
    {
      "epoch": 1.809242871189774,
      "grad_norm": 0.019395191222429276,
      "learning_rate": 5.194573366654766e-06,
      "loss": 0.0002,
      "step": 5520
    },
    {
      "epoch": 1.8125204850868568,
      "grad_norm": 0.018433451652526855,
      "learning_rate": 5.1053195287397365e-06,
      "loss": 0.0001,
      "step": 5530
    },
    {
      "epoch": 1.8157980989839397,
      "grad_norm": 0.001431845361366868,
      "learning_rate": 5.016065690824705e-06,
      "loss": 0.0001,
      "step": 5540
    },
    {
      "epoch": 1.8190757128810227,
      "grad_norm": 9.668424900155514e-05,
      "learning_rate": 4.9268118529096755e-06,
      "loss": 0.0003,
      "step": 5550
    },
    {
      "epoch": 1.8223533267781056,
      "grad_norm": 0.0008568287594243884,
      "learning_rate": 4.837558014994645e-06,
      "loss": 0.0,
      "step": 5560
    },
    {
      "epoch": 1.8256309406751885,
      "grad_norm": 6.602056964766234e-05,
      "learning_rate": 4.7483041770796145e-06,
      "loss": 0.0006,
      "step": 5570
    },
    {
      "epoch": 1.8289085545722714,
      "grad_norm": 0.005609539803117514,
      "learning_rate": 4.659050339164584e-06,
      "loss": 0.0001,
      "step": 5580
    },
    {
      "epoch": 1.8321861684693543,
      "grad_norm": 0.0001429234689567238,
      "learning_rate": 4.569796501249554e-06,
      "loss": 0.0001,
      "step": 5590
    },
    {
      "epoch": 1.8354637823664373,
      "grad_norm": 9.295923518948257e-05,
      "learning_rate": 4.480542663334524e-06,
      "loss": 0.0001,
      "step": 5600
    },
    {
      "epoch": 1.8387413962635202,
      "grad_norm": 0.016299216076731682,
      "learning_rate": 4.391288825419493e-06,
      "loss": 0.0003,
      "step": 5610
    },
    {
      "epoch": 1.842019010160603,
      "grad_norm": 0.00021489291975740343,
      "learning_rate": 4.302034987504463e-06,
      "loss": 0.0001,
      "step": 5620
    },
    {
      "epoch": 1.845296624057686,
      "grad_norm": 4.835479558096267e-05,
      "learning_rate": 4.212781149589433e-06,
      "loss": 0.0,
      "step": 5630
    },
    {
      "epoch": 1.848574237954769,
      "grad_norm": 0.013665101490914822,
      "learning_rate": 4.123527311674403e-06,
      "loss": 0.0001,
      "step": 5640
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.003069413360208273,
      "learning_rate": 4.034273473759371e-06,
      "loss": 0.0001,
      "step": 5650
    },
    {
      "epoch": 1.8551294657489348,
      "grad_norm": 0.013485769741237164,
      "learning_rate": 3.945019635844342e-06,
      "loss": 0.0001,
      "step": 5660
    },
    {
      "epoch": 1.8584070796460177,
      "grad_norm": 0.12738865613937378,
      "learning_rate": 3.855765797929311e-06,
      "loss": 0.0002,
      "step": 5670
    },
    {
      "epoch": 1.8616846935431006,
      "grad_norm": 0.00025988047127611935,
      "learning_rate": 3.766511960014281e-06,
      "loss": 0.0002,
      "step": 5680
    },
    {
      "epoch": 1.8649623074401835,
      "grad_norm": 0.00014310375263448805,
      "learning_rate": 3.67725812209925e-06,
      "loss": 0.0001,
      "step": 5690
    },
    {
      "epoch": 1.8682399213372665,
      "grad_norm": 0.00826332625001669,
      "learning_rate": 3.5880042841842204e-06,
      "loss": 0.0001,
      "step": 5700
    },
    {
      "epoch": 1.8715175352343494,
      "grad_norm": 0.0047348071821033955,
      "learning_rate": 3.4987504462691895e-06,
      "loss": 0.0001,
      "step": 5710
    },
    {
      "epoch": 1.8747951491314323,
      "grad_norm": 0.0007122753304429352,
      "learning_rate": 3.40949660835416e-06,
      "loss": 0.0002,
      "step": 5720
    },
    {
      "epoch": 1.8780727630285152,
      "grad_norm": 0.0015873960219323635,
      "learning_rate": 3.320242770439129e-06,
      "loss": 0.0002,
      "step": 5730
    },
    {
      "epoch": 1.8813503769255981,
      "grad_norm": 0.003368374891579151,
      "learning_rate": 3.230988932524099e-06,
      "loss": 0.0001,
      "step": 5740
    },
    {
      "epoch": 1.884627990822681,
      "grad_norm": 0.11184847354888916,
      "learning_rate": 3.1417350946090683e-06,
      "loss": 0.0003,
      "step": 5750
    },
    {
      "epoch": 1.887905604719764,
      "grad_norm": 0.0020109054166823626,
      "learning_rate": 3.052481256694038e-06,
      "loss": 0.0003,
      "step": 5760
    },
    {
      "epoch": 1.891183218616847,
      "grad_norm": 0.15330824255943298,
      "learning_rate": 2.9632274187790077e-06,
      "loss": 0.0004,
      "step": 5770
    },
    {
      "epoch": 1.8944608325139298,
      "grad_norm": 0.00011256367724854499,
      "learning_rate": 2.8739735808639772e-06,
      "loss": 0.0001,
      "step": 5780
    },
    {
      "epoch": 1.8977384464110127,
      "grad_norm": 0.011992181651294231,
      "learning_rate": 2.784719742948947e-06,
      "loss": 0.0002,
      "step": 5790
    },
    {
      "epoch": 1.9010160603080957,
      "grad_norm": 0.02408311329782009,
      "learning_rate": 2.6954659050339166e-06,
      "loss": 0.0002,
      "step": 5800
    },
    {
      "epoch": 1.9042936742051786,
      "grad_norm": 5.0917315093101934e-05,
      "learning_rate": 2.6062120671188865e-06,
      "loss": 0.0001,
      "step": 5810
    },
    {
      "epoch": 1.9075712881022615,
      "grad_norm": 6.223122181836516e-05,
      "learning_rate": 2.516958229203856e-06,
      "loss": 0.0001,
      "step": 5820
    },
    {
      "epoch": 1.9108489019993444,
      "grad_norm": 0.040033984929323196,
      "learning_rate": 2.4277043912888255e-06,
      "loss": 0.0001,
      "step": 5830
    },
    {
      "epoch": 1.9141265158964273,
      "grad_norm": 9.70463443081826e-05,
      "learning_rate": 2.338450553373795e-06,
      "loss": 0.0001,
      "step": 5840
    },
    {
      "epoch": 1.9174041297935103,
      "grad_norm": 0.00030341121600940824,
      "learning_rate": 2.249196715458765e-06,
      "loss": 0.0001,
      "step": 5850
    },
    {
      "epoch": 1.9206817436905932,
      "grad_norm": 0.006604882888495922,
      "learning_rate": 2.1599428775437344e-06,
      "loss": 0.0002,
      "step": 5860
    },
    {
      "epoch": 1.9239593575876763,
      "grad_norm": 6.199729250511155e-05,
      "learning_rate": 2.070689039628704e-06,
      "loss": 0.0001,
      "step": 5870
    },
    {
      "epoch": 1.927236971484759,
      "grad_norm": 0.0012321009999141097,
      "learning_rate": 1.981435201713674e-06,
      "loss": 0.0,
      "step": 5880
    },
    {
      "epoch": 1.9305145853818422,
      "grad_norm": 6.55465992167592e-05,
      "learning_rate": 1.8921813637986436e-06,
      "loss": 0.0001,
      "step": 5890
    },
    {
      "epoch": 1.9337921992789249,
      "grad_norm": 6.878253043396398e-05,
      "learning_rate": 1.802927525883613e-06,
      "loss": 0.0001,
      "step": 5900
    },
    {
      "epoch": 1.937069813176008,
      "grad_norm": 0.009546663612127304,
      "learning_rate": 1.7136736879685828e-06,
      "loss": 0.0001,
      "step": 5910
    },
    {
      "epoch": 1.9403474270730907,
      "grad_norm": 0.00012875576794613153,
      "learning_rate": 1.6244198500535525e-06,
      "loss": 0.0,
      "step": 5920
    },
    {
      "epoch": 1.9436250409701739,
      "grad_norm": 0.00015398468531202525,
      "learning_rate": 1.535166012138522e-06,
      "loss": 0.0003,
      "step": 5930
    },
    {
      "epoch": 1.9469026548672566,
      "grad_norm": 9.175353625323623e-05,
      "learning_rate": 1.4459121742234917e-06,
      "loss": 0.0001,
      "step": 5940
    },
    {
      "epoch": 1.9501802687643397,
      "grad_norm": 0.002084800973534584,
      "learning_rate": 1.3566583363084614e-06,
      "loss": 0.0002,
      "step": 5950
    },
    {
      "epoch": 1.9534578826614224,
      "grad_norm": 0.00026041679666377604,
      "learning_rate": 1.267404498393431e-06,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 1.9567354965585055,
      "grad_norm": 0.006223292089998722,
      "learning_rate": 1.1781506604784008e-06,
      "loss": 0.0004,
      "step": 5970
    },
    {
      "epoch": 1.9600131104555882,
      "grad_norm": 0.006486451253294945,
      "learning_rate": 1.0888968225633703e-06,
      "loss": 0.0001,
      "step": 5980
    },
    {
      "epoch": 1.9632907243526714,
      "grad_norm": 0.0008565342286601663,
      "learning_rate": 9.9964298464834e-07,
      "loss": 0.0001,
      "step": 5990
    },
    {
      "epoch": 1.966568338249754,
      "grad_norm": 0.00011511848424561322,
      "learning_rate": 9.103891467333096e-07,
      "loss": 0.0001,
      "step": 6000
    },
    {
      "epoch": 1.9698459521468372,
      "grad_norm": 8.594115206506103e-05,
      "learning_rate": 8.211353088182793e-07,
      "loss": 0.0003,
      "step": 6010
    },
    {
      "epoch": 1.97312356604392,
      "grad_norm": 0.0012198137119412422,
      "learning_rate": 7.318814709032489e-07,
      "loss": 0.0002,
      "step": 6020
    },
    {
      "epoch": 1.976401179941003,
      "grad_norm": 9.588342072675005e-05,
      "learning_rate": 6.426276329882185e-07,
      "loss": 0.0001,
      "step": 6030
    },
    {
      "epoch": 1.9796787938380858,
      "grad_norm": 0.00029302522307261825,
      "learning_rate": 5.533737950731882e-07,
      "loss": 0.0001,
      "step": 6040
    },
    {
      "epoch": 1.982956407735169,
      "grad_norm": 0.0009530148236081004,
      "learning_rate": 4.641199571581579e-07,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 1.9862340216322516,
      "grad_norm": 6.166068487800658e-05,
      "learning_rate": 3.7486611924312744e-07,
      "loss": 0.0002,
      "step": 6060
    },
    {
      "epoch": 1.9895116355293347,
      "grad_norm": 0.001285041100345552,
      "learning_rate": 2.8561228132809714e-07,
      "loss": 0.0001,
      "step": 6070
    },
    {
      "epoch": 1.9927892494264174,
      "grad_norm": 0.006509426515549421,
      "learning_rate": 1.9635844341306677e-07,
      "loss": 0.0003,
      "step": 6080
    },
    {
      "epoch": 1.9960668633235006,
      "grad_norm": 0.0013948815176263452,
      "learning_rate": 1.0710460549803642e-07,
      "loss": 0.0002,
      "step": 6090
    },
    {
      "epoch": 1.9993444772205833,
      "grad_norm": 0.2031426578760147,
      "learning_rate": 1.785076758300607e-08,
      "loss": 0.0001,
      "step": 6100
    }
  ],
  "logging_steps": 10,
  "max_steps": 6102,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3302881323122688.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
